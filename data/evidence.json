[
  {
    "providerId": "anthropic",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Constitutional training data with filtered corpora designed to reduce harmful content and improve model alignment",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "policy",
        "lastVerified": "2025-11-07",
        "sourceHash": "23959d6f10e51cbe0c5820afc87dced47c4cf6f1dfb962444a7c25ce96314a64",
        "relevantSection": "Safety and Security Standards"
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Specific filtering methods not detailed"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Part of Constitutional AI framework",
    "id": "ev-anthropic-0002"
  },
  {
    "providerId": "anthropic",
    "techniqueId": "tech-constitutional-ai",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Self-critique training using constitutional principles for helpful, harmless, honest behavior with scalable oversight",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2212.08073",
        "documentType": "research-paper",
        "lastVerified": "2025-11-07",
        "sourceHash": "9a456a07ad346e3372f9867d346f69f5b0f68b4c65f060aca0b8a13fa9d98e83",
        "relevantSection": "Section 3: Constitutional AI"
      }
    ],
    "implementationDate": "2022-12-15",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "evaluationMetrics": [
      {
        "metric": "human_preference_rate",
        "value": 76,
        "unit": "percent",
        "benchmarkContext": {
          "name": "Constitutional AI Eval",
          "version": "v1",
          "url": "https://arxiv.org/abs/2212.08073"
        }
      }
    ],
    "knownLimitations": [
      "May be overly conservative",
      "Principles require careful design"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Core safety innovation from Anthropic",
    "id": "ev-anthropic-0003"
  },
  {
    "providerId": "anthropic",
    "techniqueId": "tech-rlhf",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Constitutional AI approach combining self-critique with RLHF for scalable oversight and preference learning",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2212.08073",
        "documentType": "research-paper",
        "lastVerified": "2025-11-07",
        "sourceHash": "9a456a07ad346e3372f9867d346f69f5b0f68b4c65f060aca0b8a13fa9d98e83",
        "relevantSection": "Section 4: Training Process"
      }
    ],
    "implementationDate": "2022-12-15",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Subject to annotator biases",
      "Computationally expensive"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Combined with Constitutional AI for enhanced safety",
    "id": "ev-anthropic-0004"
  },
  {
    "providerId": "google",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Multi-lingual safety filtering and bias detection in training data preparation for Gemini models",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "58970ed07e88c7589d177ebc63b136d9e5510d41a934a55f445d89a179b476d5",
        "relevantSection": "Training Data Safety"
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Specific methods not detailed"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "EU AI Act"
    ],
    "notes": "Focus on multilingual safety",
    "id": "ev-google-0005"
  },
  {
    "providerId": "google",
    "techniqueId": "tech-rlhf",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "B",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "RLHF with adversarial safety tuning datasets and Sparrow-style critiquing methodology",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2209.14375",
        "documentType": "research-paper",
        "lastVerified": "2025-11-07",
        "sourceHash": "e7df8fc1e41dfc3b47a781958fc53e6467f3b0ba3b0c10db5040f7924097709a",
        "relevantSection": "Section 3: Training Sparrow"
      }
    ],
    "implementationDate": "2022-09-29",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Limited to English initially"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Based on Sparrow research",
    "id": "ev-google-0006"
  },
  {
    "providerId": "meta",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Open training with safety benchmarks and Llama Guard integration for content filtering",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-11-07",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": "Section 4: Safety"
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Community-dependent verification"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Open source approach enables community verification",
    "id": "ev-meta-0007"
  },
  {
    "providerId": "meta",
    "techniqueId": "tech-rlhf",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Two-phase RLHF with community-driven safety feedback and open source evaluation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-11-07",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": "Section 3.3: Fine-tuning"
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Resource intensive",
      "Community feedback quality varies"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Two-phase approach with safety-specific rewards",
    "id": "ev-meta-0008"
  },
  {
    "providerId": "meta",
    "techniqueId": "tech-input-classification",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Llama Guard as separate safety classifier for input content with open source implementation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "research-paper",
        "lastVerified": "2025-11-07",
        "sourceHash": "2a2fc9dc3f45e7eba9ebddd08a49d1a6b3f3195d574e7690eac49310b4c7b95d",
        "relevantSection": "Section 2: Llama Guard"
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Requires separate model inference"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Open source safety classifier",
    "id": "ev-meta-0009"
  },
  {
    "providerId": "amazon",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "B",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Advanced PII detection and redaction through Bedrock Guardrails with enterprise-grade protection",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails-sensitive-filters.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "2e1b15bc85fc8b37e81960cb9f302cc4c3e1a235df00a026518e0bc7efdb33fd",
        "relevantSection": "Sensitive Information Filters"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Language support varies",
      "Context-dependent PII challenging"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "HIPAA",
      "PCI-DSS"
    ],
    "notes": "Enterprise-grade PII protection",
    "id": "ev-amazon-0010"
  },
  {
    "providerId": "amazon",
    "techniqueId": "tech-input-classification",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Bedrock Guardrails input classification with customizable policies and enterprise integration",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": "Content Filters"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Requires configuration",
      "May have false positives"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Highly configurable for enterprise needs",
    "id": "ev-amazon-0011"
  },
  {
    "providerId": "amazon",
    "techniqueId": "tech-output-filtering",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Bedrock Guardrails output filtering with hallucination detection and content policy enforcement",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": "Output Moderation"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "May alter outputs",
      "Hallucination detection has limits"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Includes hallucination detection",
    "id": "ev-amazon-0012"
  },
  {
    "providerId": "anthropic",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "External red team engagement as part of responsible scaling policy and AI Safety Level assessments",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "policy",
        "lastVerified": "2025-11-07",
        "sourceHash": "d108fca75ed6855f9cb25bff6e68fd23d84b031adbe4145e2ed204fcf85dbbdf",
        "relevantSection": "AI Safety Levels"
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Specific findings not always public"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Part of ASL framework",
    "id": "ev-anthropic-0013"
  },
  {
    "providerId": "anthropic",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Responsible scaling policy and constitutional AI research provide comprehensive safety framework documentation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "policy",
        "lastVerified": "2025-11-07",
        "sourceHash": "13492a45ecb47f55949160a0bff37447d2bb1f9f97e06e5080342e6fb102b0f4",
        "relevantSection": "Full Document"
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P12M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Industry-leading transparency",
    "id": "ev-anthropic-0014"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-csam-detection",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Automated detection and removal of child sexual abuse material using specialized classifiers during pre-training data preparation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://openai.com/policies/usage-policies",
        "documentType": "policy",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "Prohibited Usage"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Detection rates not disclosed"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "NCMEC"
    ],
    "notes": "Part of comprehensive content filtering",
    "id": "ev-openai-0003"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-copyright-filtering",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Fingerprinting system to remove opted-out images from training data, building on DALL-E 3 opt-out mechanism",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-07",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Section 2.1"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Only for opted-out content"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "DMCA"
    ],
    "notes": "Extends DALL-E 3 opt-out system",
    "id": "ev-openai-0004"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-bias-detection-training",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Advanced data filtering processes to reduce biased content, though specific bias detection methods not fully detailed",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-07",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Safety Evaluations"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Specific methods not disclosed"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0005"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Advanced data filtering processes to reduce personal information from training data using automated detection systems",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-07",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Data Processing"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Cannot catch all PII"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "GDPR",
      "CCPA"
    ],
    "notes": "",
    "id": "ev-openai-0006"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-adversarial-training",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Red team data integration and adversarial testing during training, though specific methods not detailed",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-07",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Red Teaming"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Methods not fully disclosed"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0007"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-red-team-data",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "100+ external red teamers across 45 languages and 29 countries, data integrated into training process",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-07",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "External Red Teaming"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Extensive red team network",
    "id": "ev-openai-0008"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-input-classification",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Layered policy engine with system prompt \u2192 model \u2192 content filter pipeline, including specialized voice classifiers",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-07",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Safety Pipeline"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Multi-layer approach",
    "id": "ev-openai-0009"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-output-filtering",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Multi-stage content filtering with moderation API applied to both text and audio outputs",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-07",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Output Moderation"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Includes audio moderation",
    "id": "ev-openai-0010"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "System prompt protections and multi-layer filtering, though specific prompt injection defenses not detailed",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-07",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Safety Mitigations"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Specific defenses not disclosed"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0011"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Real-time monitoring and enforcement with product-level mitigations including streaming audio analysis",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-07",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Real-time Voice"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Includes voice monitoring",
    "id": "ev-openai-0012"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-contextual-safety",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Context-aware safety evaluation, particularly for voice interactions, though implementation not detailed",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-07",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Voice Safety"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Implementation details limited"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0013"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Comprehensive safety pipeline spanning pre-training, post-training, product development, and policy enforcement",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-07",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Safety Architecture"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "End-to-end approach",
    "id": "ev-openai-0014"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "PII detection capabilities integrated into content filtering systems for personal information protection",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://openai.com/policies/usage-policies",
        "documentType": "policy",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "Privacy"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Details not specified"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "GDPR",
      "CCPA"
    ],
    "notes": "",
    "id": "ev-openai-0015"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Usage policies and moderation tools provided to users, with transparency reports and configurable settings",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://openai.com/policies/usage-policies",
        "documentType": "policy",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "Usage Policies"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Limited configurability"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0016"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-audit-logging",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Usage monitoring and incident reporting systems for tracking and analyzing safety incidents",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-07",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Monitoring"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "SOC2"
    ],
    "notes": "",
    "id": "ev-openai-0017"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Preparedness Framework with pre-defined capability thresholds and deployment decisions based on risk assessments",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/openai-preparedness-framework-beta.pdf",
        "documentType": "policy",
        "lastVerified": "2025-11-07",
        "sourceHash": "c84e3a59c7dab251e45434e0b0d3e8abadcea7293f995cf92d32269e7d290398",
        "relevantSection": "Full Document"
      }
    ],
    "implementationDate": "2023-10-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Industry-leading framework",
    "id": "ev-openai-0018"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-safety-advisory",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Safety Advisory Group providing independent oversight and recommendations on deployment decisions",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-07",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Governance"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P12M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0019"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-incident-reporting",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": true
    },
    "summary": "Systematic incident reporting and analysis with internal tracking and external disclosure mechanisms",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-07",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Incident Response"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0020"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": true
    },
    "summary": "Comprehensive usage monitoring with analytics for detecting patterns of misuse and safety incidents",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-07",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Usage Analytics"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0021"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Compliance with voluntary White House commitments and development of internal governance frameworks",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://openai.com/index/our-approach-to-ai-safety",
        "documentType": "blog-post",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "Commitments"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "White House Commitments"
    ],
    "notes": "",
    "id": "ev-openai-0022"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Collaboration with academic institutions and independent research organizations for safety evaluation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-07",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "External Collaboration"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P12M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0023"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-model-cards",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Technical documentation including model architecture, training methodology, and safety evaluation results",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-07",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Full Document"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P12M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Comprehensive system card",
    "id": "ev-openai-0024"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Regular publication of safety research, evaluation methodologies, and lessons learned from deployment",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://openai.com/research",
        "documentType": "research-paper",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "Safety Research"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P12M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0025"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Comprehensive usage policies, terms of service, and compliance documentation publicly available",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://openai.com/policies",
        "documentType": "policy",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "All Policies"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0026"
  },
  {
    "providerId": "google",
    "techniqueId": "tech-watermarking",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": true
    },
    "summary": "SynthID watermarking technology for AI-generated image and audio content identification",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/science/synthid/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "07c69aa54725338795b1dac7086b614550a3ea0838edf7d3165a9519e9b55a78",
        "relevantSection": "Technology Overview"
      }
    ],
    "implementationDate": "2023-08-29",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Limited to certain content types"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Industry-leading watermarking",
    "id": "ev-google-0003"
  },
  {
    "providerId": "google",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "EU AI Act compliance measures with transparency registers and regulatory reporting mechanisms",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://blog.google/technology/ai/google-ai-act-preparation/",
        "documentType": "blog-post",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "Compliance Measures"
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "EU AI Act"
    ],
    "notes": "Proactive compliance",
    "id": "ev-google-0004"
  },
  {
    "providerId": "google",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Multi-stage safety layers including toxicity detection, policy checks, and SynthID watermarking",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "58970ed07e88c7589d177ebc63b136d9e5510d41a934a55f445d89a179b476d5",
        "relevantSection": "Safety Architecture"
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-google-0005"
  },
  {
    "providerId": "google",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Academic partnerships for AI safety research and independent evaluation of safety measures",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/research/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "b27b55e27af430ca4a0f90232b4e47817dfaa3f98f318c770b5a7783c249c3dc",
        "relevantSection": "Collaborations"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P12M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-google-0006"
  },
  {
    "providerId": "meta",
    "techniqueId": "tech-output-filtering",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Llama Guard output filtering with contextual moderation and open source validation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "research-paper",
        "lastVerified": "2025-11-07",
        "sourceHash": "4c00022da242508aaacc90536eeb4383a01fc5d453ede3bb639717172d3d947c",
        "relevantSection": "Output Moderation"
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Requires separate inference"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Open source implementation",
    "id": "ev-meta-0004"
  },
  {
    "providerId": "meta",
    "techniqueId": "tech-bias-detection-training",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "B",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Bias detection and mitigation with community-driven evaluation and open source validation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-11-07",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": "Section 5.2: Bias Evaluation"
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Community-dependent validation"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-meta-0005"
  },
  {
    "id": "ev-openai-0027",
    "providerId": "openai",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Systematic evaluation protocols for dangerous capabilities including cybersecurity, CBRN, persuasion, and autonomy",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-07",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-openai-0028",
    "providerId": "openai",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Systematic red team exercises across multiple phases with diverse expert networks and real-world testing scenarios",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-07",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-openai-0031",
    "providerId": "openai",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Detailed system cards providing comprehensive safety evaluations, methodologies, and results for each model release",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-07",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-anthropic-0005",
    "providerId": "anthropic",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Personal information filtering as part of constitutional training data preparation",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/claude-3-model-card",
        "documentType": "system-card",
        "lastVerified": "2025-11-07",
        "sourceHash": "88ae851f53c3034d436816164ce49a876b333fa9b550fb7ef29838182b59ba7d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-03-04",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0006",
    "providerId": "anthropic",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Compliance with emerging AI regulations and industry standards through responsible scaling policy",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "8468ed4a605bc5aa8b960cdeb426c5863b9703ee999337129b2819a3e3b92641",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0009",
    "providerId": "anthropic",
    "techniqueId": "tech-safety-reward-modeling",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Safety considerations integrated into reward modeling as part of constitutional AI framework",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2212.08073",
        "documentType": "research-paper",
        "lastVerified": "2025-11-07",
        "sourceHash": "9a456a07ad346e3372f9867d346f69f5b0f68b4c65f060aca0b8a13fa9d98e83",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2022-12-15",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0010",
    "providerId": "anthropic",
    "techniqueId": "tech-adversarial-training",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Adversarial testing integrated into constitutional AI training process for robustness",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2212.08073",
        "documentType": "research-paper",
        "lastVerified": "2025-11-07",
        "sourceHash": "9a456a07ad346e3372f9867d346f69f5b0f68b4c65f060aca0b8a13fa9d98e83",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2022-12-15",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBC"
  },
  {
    "id": "ev-anthropic-0011",
    "providerId": "anthropic",
    "techniqueId": "tech-red-team-data",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Red team exercises and data integration as part of responsible scaling policy and safety evaluation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "efb18fc4dbe6997c9fb0c5dd5e48f813845f9062c25b05b213205ca174a72397",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-anthropic-0012",
    "providerId": "anthropic",
    "techniqueId": "tech-input-classification",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Content classification systems for input filtering, though specific implementation details not public",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/claude-3-model-card",
        "documentType": "system-card",
        "lastVerified": "2025-11-07",
        "sourceHash": "88ae851f53c3034d436816164ce49a876b333fa9b550fb7ef29838182b59ba7d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-03-04",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0015",
    "providerId": "anthropic",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Safety monitoring systems in place, though specific real-time implementation details not disclosed",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/claude-3-model-card",
        "documentType": "system-card",
        "lastVerified": "2025-11-07",
        "sourceHash": "88ae851f53c3034d436816164ce49a876b333fa9b550fb7ef29838182b59ba7d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-03-04",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0016",
    "providerId": "anthropic",
    "techniqueId": "tech-contextual-safety",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Constitutional AI enables sophisticated contextual safety assessment through principle-based reasoning",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2212.08073",
        "documentType": "research-paper",
        "lastVerified": "2025-11-07",
        "sourceHash": "9a456a07ad346e3372f9867d346f69f5b0f68b4c65f060aca0b8a13fa9d98e83",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2022-12-15",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-anthropic-0017",
    "providerId": "anthropic",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive safety pipeline including constitutional training, RLHF, and responsible scaling evaluation",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "802855fd522de1a772b63fc9f1c3d1bbbda0da9f1ff117c4082138d058b9c1ff",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-anthropic-0018",
    "providerId": "anthropic",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "PII protection mechanisms integrated into constitutional AI framework",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/claude-3-model-card",
        "documentType": "system-card",
        "lastVerified": "2025-11-07",
        "sourceHash": "88ae851f53c3034d436816164ce49a876b333fa9b550fb7ef29838182b59ba7d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-03-04",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0019",
    "providerId": "anthropic",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Constitutional principles provide framework for configurable safety responses",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2212.08073",
        "documentType": "research-paper",
        "lastVerified": "2025-11-07",
        "sourceHash": "9a456a07ad346e3372f9867d346f69f5b0f68b4c65f060aca0b8a13fa9d98e83",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2022-12-15",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0020",
    "providerId": "anthropic",
    "techniqueId": "tech-audit-logging",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Audit and monitoring capabilities as part of responsible scaling policy framework",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "e45ad7ceab7a77dceb5c703033a5fee529ffbc217bff00d68fe08808645d8c37",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0021",
    "providerId": "anthropic",
    "techniqueId": "tech-watermarking",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "B",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Research into watermarking techniques for AI-generated content detection and provenance",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "5dee63602f34e44792faf1044f86a2038f6df7d26d9a09ae2f60e23eeb701ada",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MRC"
  },
  {
    "id": "ev-anthropic-0023",
    "providerId": "anthropic",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "AI Safety Level (ASL) framework with clear classifications and deployment thresholds",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "58784caf140003646eb026b11821c8b071a180791246494ec1fc0d29279270e1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-anthropic-0024",
    "providerId": "anthropic",
    "techniqueId": "tech-safety-advisory",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Independent safety advisory structure as part of responsible scaling policy governance",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "c468809678d49ab0f3790ee410af4efa879caed8880ab79ba0f17c90345b5add",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-anthropic-0025",
    "providerId": "anthropic",
    "techniqueId": "tech-incident-reporting",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Incident reporting and analysis systems integrated into responsible scaling framework",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "4438a27dcb51c244db88b859564f768b9d85a03be8375cb73ce5aabfc6fda9bb",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-anthropic-0026",
    "providerId": "anthropic",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Usage monitoring capabilities for safety assessment and responsible scaling decisions",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "a88033bc00cca4931b1e205cfed6566945c43ebef1e03bd3b0a9bd9065c86e1f",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0027",
    "providerId": "anthropic",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Systematic capability evaluation protocols as part of ASL framework and responsible scaling",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "a9c79a1c20e955159cb987cb34d9e20bd039e761bf816344dfa02eae510f8c2c",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-anthropic-0028",
    "providerId": "anthropic",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive red team exercises for capability assessment and safety evaluation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "66fcb05e85b5b1857ada43f66fb51053e83439d433c1179490e2fcbb49f2c760",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-anthropic-0029",
    "providerId": "anthropic",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Proactive regulatory compliance through responsible scaling policy and industry engagement",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "3802fc644e413527ceaa347837d9f23971777b935cae205e5fda579d2fe0c451",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-anthropic-0030",
    "providerId": "anthropic",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Academic collaborations for safety research and constitutional AI development",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/research",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "6bbc97de2432ab562ae9f4c1f5dd2fb8d76f45ce80f8d257596fecb0e68b5edf",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-anthropic-0032",
    "providerId": "anthropic",
    "techniqueId": "tech-model-cards",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Model cards available for Claude models with technical specifications and safety information",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/claude-3-model-card",
        "documentType": "system-card",
        "lastVerified": "2025-11-07",
        "sourceHash": "88ae851f53c3034d436816164ce49a876b333fa9b550fb7ef29838182b59ba7d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-03-04",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-anthropic-0033",
    "providerId": "anthropic",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Extensive publication of constitutional AI research and safety methodologies",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/research",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "8a68d7eebf43b429d72c4dc9144aa3215cb472ae60a7a3692a2463c8fea01990",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-anthropic-0034",
    "providerId": "anthropic",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive policy documentation including responsible scaling policy and usage guidelines",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "8629154ff6d80f5e5ab04dbecda6548a18dcfe810589201d48422793592c1739",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-google-0002",
    "providerId": "google",
    "techniqueId": "tech-csam-detection",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "CSAM detection and removal systems implemented as part of standard content filtering pipeline",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "58970ed07e88c7589d177ebc63b136d9e5510d41a934a55f445d89a179b476d5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0008",
    "providerId": "google",
    "techniqueId": "tech-constitutional-ai",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "B",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Research into constitutional AI principles and self-critique mechanisms for Gemini safety",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "58970ed07e88c7589d177ebc63b136d9e5510d41a934a55f445d89a179b476d5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MRC"
  },
  {
    "id": "ev-google-0009",
    "providerId": "google",
    "techniqueId": "tech-safety-reward-modeling",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Safety considerations integrated into reward modeling for Gemini training optimization",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "58970ed07e88c7589d177ebc63b136d9e5510d41a934a55f445d89a179b476d5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0010",
    "providerId": "google",
    "techniqueId": "tech-adversarial-training",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Adversarial safety tuning datasets used in RLHF process for robustness improvement",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2209.14375",
        "documentType": "research-paper",
        "lastVerified": "2025-11-07",
        "sourceHash": "e7df8fc1e41dfc3b47a781958fc53e6467f3b0ba3b0c10db5040f7924097709a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2022-09-29",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBC"
  },
  {
    "id": "ev-google-0011",
    "providerId": "google",
    "techniqueId": "tech-red-team-data",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Red team exercises and data integration for Gemini safety evaluation and improvement",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "58970ed07e88c7589d177ebc63b136d9e5510d41a934a55f445d89a179b476d5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0012",
    "providerId": "google",
    "techniqueId": "tech-input-classification",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Multi-stage safety layer including toxicity and content classification for input processing",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "58970ed07e88c7589d177ebc63b136d9e5510d41a934a55f445d89a179b476d5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0013",
    "providerId": "google",
    "techniqueId": "tech-output-filtering",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Output content filtering with toxicity classifiers and safety policy enforcement",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "58970ed07e88c7589d177ebc63b136d9e5510d41a934a55f445d89a179b476d5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0014",
    "providerId": "google",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic prompt injection protection through input filtering and safety classifiers",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "58970ed07e88c7589d177ebc63b136d9e5510d41a934a55f445d89a179b476d5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBC"
  },
  {
    "id": "ev-google-0015",
    "providerId": "google",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Real-time safety monitoring capabilities integrated into Gemini deployment infrastructure",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "58970ed07e88c7589d177ebc63b136d9e5510d41a934a55f445d89a179b476d5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0016",
    "providerId": "google",
    "techniqueId": "tech-contextual-safety",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Contextual safety assessment capabilities, though specific implementation details not disclosed",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "58970ed07e88c7589d177ebc63b136d9e5510d41a934a55f445d89a179b476d5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBC"
  },
  {
    "id": "ev-google-0018",
    "providerId": "google",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "PII detection and redaction capabilities integrated into safety pipeline",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "58970ed07e88c7589d177ebc63b136d9e5510d41a934a55f445d89a179b476d5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0019",
    "providerId": "google",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Configurable safety policies and content filtering options for different deployment contexts",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "58970ed07e88c7589d177ebc63b136d9e5510d41a934a55f445d89a179b476d5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0020",
    "providerId": "google",
    "techniqueId": "tech-audit-logging",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Audit logging capabilities for safety incident tracking and regulatory compliance",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://blog.google/technology/ai/google-ai-act-preparation/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0022",
    "providerId": "google",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "External red team engagement for Gemini safety evaluation and testing",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "58970ed07e88c7589d177ebc63b136d9e5510d41a934a55f445d89a179b476d5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0023",
    "providerId": "google",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Internal safety classification system for model capabilities and deployment decisions",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "58970ed07e88c7589d177ebc63b136d9e5510d41a934a55f445d89a179b476d5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0024",
    "providerId": "google",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Capability evaluation protocols for dangerous capabilities and safety assessment",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "58970ed07e88c7589d177ebc63b136d9e5510d41a934a55f445d89a179b476d5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0025",
    "providerId": "google",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Red team exercises for capability discovery and safety evaluation across multiple domains",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "58970ed07e88c7589d177ebc63b136d9e5510d41a934a55f445d89a179b476d5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0026",
    "providerId": "google",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive regulatory compliance frameworks including EU AI Act preparation and transparency measures",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://blog.google/technology/ai/google-ai-act-preparation/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-google-0028",
    "providerId": "google",
    "techniqueId": "tech-model-cards",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Model cards and technical documentation for Gemini models with safety information",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/gemini/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "cf27825724e735d3bebfa4ef990e003a5b9f33f521afaa0c1bda4741e2aff988",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-meta-0002",
    "providerId": "meta",
    "techniqueId": "tech-csam-detection",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "CSAM detection and removal processes integrated into training data preparation",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "b203252808bf055f23f9197e16372f3dc67dc4e1cb4bc2849fb05cb68db8dcfb",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0003",
    "providerId": "meta",
    "techniqueId": "tech-copyright-filtering",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Copyright filtering mechanisms for training data with open source transparency",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-11-07",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0006",
    "providerId": "meta",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic regulatory compliance measures with limited international regulatory integration",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "8bd1cee7a68362753ea632d3918eef8760ee512fc3decb423bb8ec9672041c68",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPC"
  },
  {
    "id": "ev-meta-0010",
    "providerId": "meta",
    "techniqueId": "tech-community-feedback",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community-driven safety feedback with open source evaluation harness and academic partnerships",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "3a23ea1d2ec17d14d3676129dffebdc51d7cd81326dbab5920e1b776b6826c2e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPV"
  },
  {
    "id": "ev-meta-0013",
    "providerId": "meta",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic prompt injection protection through Llama Guard classification and community testing",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "3e333e951ff0d49a9d9688d0baa4ccdc199c2ca19b385e6c8040837863d0551b",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBC"
  },
  {
    "id": "ev-meta-0014",
    "providerId": "meta",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Real-time safety monitoring capabilities through Llama Guard integration",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "db25339f623dd867b6532af2aa8d0cfbff9c4f4744122ae6da02d8ec4349a49a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0015",
    "providerId": "meta",
    "techniqueId": "tech-contextual-safety",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Contextual moderation capabilities through Llama Guard classification system",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "ad9d060f58d9e0e969714992d57602f4770097f5682792656957e898539d4197",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBC"
  },
  {
    "id": "ev-meta-0016",
    "providerId": "meta",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Multi-stage safety pipeline with Llama Guard integration and community validation",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-11-07",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0017",
    "providerId": "meta",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "PII detection capabilities integrated into Llama Guard classification system",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "a8889eede8187a8e28d75a2ac2743f0c364a6b770c53a1e5364bb8ec4d53c8a9",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0018",
    "providerId": "meta",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Configurable safety policies through open source Llama Guard implementation",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "2c20ca139674384b3e27fdbd908c363fe069a33e759e5d085fea2d898bc6584b",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0019",
    "providerId": "meta",
    "techniqueId": "tech-audit-logging",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic audit logging capabilities with open source transparency and community oversight",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "3c182d56c79f8afe8f5bae3cce0314181a56ff84e0ba66e7ba5f43dc5f890a2f",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0020",
    "providerId": "meta",
    "techniqueId": "tech-opensource-tools",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive open source safety tools including Llama Guard and evaluation frameworks",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://github.com/meta-llama",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "8e4e5fc7d775a3d8cb76978dc53f88c0078fa4151c5633ebb3fb149e5e37b6ad",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-meta-0021",
    "providerId": "meta",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community-driven red team networks with academic partnerships and open evaluation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-11-07",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBV"
  },
  {
    "id": "ev-meta-0022",
    "providerId": "meta",
    "techniqueId": "tech-responsible-release",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Responsible release checklist with community evaluation and academic partnership validation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "09c3e859896994314314898d48fd3fd6c6fe8fc6b09d02c9f8691dcf07569188",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-meta-0023",
    "providerId": "meta",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Extensive academic partnerships for safety evaluation and community-driven research",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "29396f64273c990552aa0faced44ed097d244b05c6a96a8b3cb48c28656b85c2",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-meta-0024",
    "providerId": "meta",
    "techniqueId": "tech-safety-benchmarks",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Open safety benchmarks and evaluation metrics with community validation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-11-07",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-meta-0025",
    "providerId": "meta",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community-driven capability evaluation protocols with open source validation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-11-07",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBV"
  },
  {
    "id": "ev-meta-0026",
    "providerId": "meta",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community-driven red team exercises with academic partnerships and open evaluation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-11-07",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBV"
  },
  {
    "id": "ev-meta-0027",
    "providerId": "meta",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic regulatory compliance frameworks with open source transparency",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "5114ae9d7fb963ffaba1c06f23212e43f0a22a2a0c6c5ead3c1be36a84bfab0d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0028",
    "providerId": "meta",
    "techniqueId": "tech-community-governance",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Community governance model with open source development and academic oversight",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "ef86396c7ea62ee31bfb94ebae8779081acf8007a564f04f10fff3bfeeebd663",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-meta-0029",
    "providerId": "meta",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Open safety documentation with research papers and community evaluation results",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-11-07",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-meta-0030",
    "providerId": "meta",
    "techniqueId": "tech-model-cards",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Open model cards and technical specifications with community validation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "dcbaa351d7607bd7ddaa35f8b0540af5afd79b42c6e3593a281893eca11e2712",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-meta-0031",
    "providerId": "meta",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Extensive safety research publications with peer review and community validation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "914ddb40258aac698fd3a1069c76035c61fa9110c581d0d6069d5976d3f5513b",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-meta-0032",
    "providerId": "meta",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Open policy and compliance documentation with community feedback integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "842513493c8a8e4926ca0e6c84bebadaa98d8e670a534e53410a8e785bb63d78",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-meta-0033",
    "providerId": "meta",
    "techniqueId": "tech-community-evaluation",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Open community evaluation frameworks with academic partnerships and peer review",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "394d630249e517c347fcd58e080f7748683745ed5d0907a50e7d3907fa96d7bb",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0001",
    "providerId": "amazon",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [
      "titan-express"
    ],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise-focused training data curation with customer data isolation and basic filtering",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "9efac3b7025e270277bf5a83d228de2c4326c5ee8216f5180b5c243d3582a659",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-amazon-0002",
    "providerId": "amazon",
    "techniqueId": "tech-csam-detection",
    "modelIds": [
      "titan-express"
    ],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Standard CSAM detection integrated into Bedrock platform with enterprise compliance",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-amazon-0003",
    "providerId": "amazon",
    "techniqueId": "tech-copyright-filtering",
    "modelIds": [
      "titan-express"
    ],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic copyright filtering with enterprise compliance and customer-configurable policies",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-amazon-0004",
    "providerId": "amazon",
    "techniqueId": "tech-bias-detection-training",
    "modelIds": [
      "titan-express"
    ],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited bias detection capabilities with enterprise compliance focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-amazon-0006",
    "providerId": "amazon",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise regulatory compliance frameworks with industry-specific guardrails",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://aws.amazon.com/compliance/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "e45b0e11b1d3785451e1d263cff9582f8acdb45d98b03ed078b225fc77d94461",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0007",
    "providerId": "amazon",
    "techniqueId": "tech-rlhf",
    "modelIds": [
      "titan-express"
    ],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic RLHF with customer fine-tuning options and domain-specific safety optimization",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "9efac3b7025e270277bf5a83d228de2c4326c5ee8216f5180b5c243d3582a659",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-amazon-0008",
    "providerId": "amazon",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Customer fine-tuning options with domain-specific safety configurations and enterprise controls",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/custom-models.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "301087a714a78598071f99b28724305dd5e13615552c20cd0db8eebd52422e32",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0013",
    "providerId": "amazon",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Multi-stage safety pipeline with Bedrock Guardrails and AWS security integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0014",
    "providerId": "amazon",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "titan-express"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Advanced PII detection and redaction with enterprise-grade sensitive information filters",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails-sensitive-filters.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "2e1b15bc85fc8b37e81960cb9f302cc4c3e1a235df00a026518e0bc7efdb33fd",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0015",
    "providerId": "amazon",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [
      "titan-express"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Highly configurable safety policies through Bedrock Guardrails with customer customization",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0016",
    "providerId": "amazon",
    "techniqueId": "tech-audit-logging",
    "modelIds": [
      "titan-express"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive audit logging through AWS CloudTrail with enterprise compliance tracking",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/logging-monitoring.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "e287c7b44ce23e4a471bebf2532b8c016fe17840bd35f1c048360118f99a599e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0017",
    "providerId": "amazon",
    "techniqueId": "tech-enterprise-integration",
    "modelIds": [
      "titan-express"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Deep enterprise security integration with AWS IAM, VPC, and compliance frameworks",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/security.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "3e82ddd78f2de438f7b597e4418a6287c23eff16d0bb89d37d7138cf6c11c247",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0018",
    "providerId": "amazon",
    "techniqueId": "tech-sovereignty-options",
    "modelIds": [
      "titan-express"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Data sovereignty options with AWS regions and customer-controlled encryption keys",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://aws.amazon.com/compliance/data-privacy/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "a7f2d272398c8b33a69c7389af9572a1342f7fefd73561b413dce1edc5206f2c",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0019",
    "providerId": "amazon",
    "techniqueId": "tech-incident-reporting",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise incident reporting through AWS support and compliance frameworks",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/logging-monitoring.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "e287c7b44ce23e4a471bebf2532b8c016fe17840bd35f1c048360118f99a599e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0020",
    "providerId": "amazon",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "titan-express"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive usage monitoring through AWS CloudWatch with enterprise analytics",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/logging-monitoring.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "e287c7b44ce23e4a471bebf2532b8c016fe17840bd35f1c048360118f99a599e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0021",
    "providerId": "amazon",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise regulatory compliance with AWS compliance certifications and industry standards",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://aws.amazon.com/compliance/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "5158b94c37917baccd2a7c6170b5d89664cec5c0bd96afb05ea2d5d73ca8cbef",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0022",
    "providerId": "amazon",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise-focused safety documentation with AWS service documentation and compliance guides",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0023",
    "providerId": "amazon",
    "techniqueId": "tech-model-cards",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "AWS AI Service Cards with model specifications and enterprise integration documentation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://aws.amazon.com/machine-learning/ai-service-cards/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0024",
    "providerId": "amazon",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Comprehensive enterprise policy and compliance documentation with AWS security frameworks",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://aws.amazon.com/compliance/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "98476c66bda75d013d4c4eb4f50c95cc3801f62c33e3ef5c970019681476c730",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0001",
    "providerId": "cohere",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise document focus with bias metrics during training for business use cases",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "8db8482bc861b1d6b0359cfe8b1c499d8fdcdfb54f0fc48469527731e3fd9735",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0002",
    "providerId": "cohere",
    "techniqueId": "tech-csam-detection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic CSAM detection as part of enterprise content filtering systems",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "8db8482bc861b1d6b0359cfe8b1c499d8fdcdfb54f0fc48469527731e3fd9735",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0003",
    "providerId": "cohere",
    "techniqueId": "tech-copyright-filtering",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Copyright filtering mechanisms for enterprise compliance and content policies",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "8db8482bc861b1d6b0359cfe8b1c499d8fdcdfb54f0fc48469527731e3fd9735",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-cohere-0004",
    "providerId": "cohere",
    "techniqueId": "tech-bias-detection-training",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Bias metrics published during training with focus on enterprise fairness requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "8db8482bc861b1d6b0359cfe8b1c499d8fdcdfb54f0fc48469527731e3fd9735",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0005",
    "providerId": "cohere",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic PII reduction capabilities for enterprise data protection requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "8db8482bc861b1d6b0359cfe8b1c499d8fdcdfb54f0fc48469527731e3fd9735",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0006",
    "providerId": "cohere",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise compliance filtering with focus on business regulatory requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "8db8482bc861b1d6b0359cfe8b1c499d8fdcdfb54f0fc48469527731e3fd9735",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0007",
    "providerId": "cohere",
    "techniqueId": "tech-rlhf",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "RLHF for business use cases with enterprise-focused training optimization",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "8db8482bc861b1d6b0359cfe8b1c499d8fdcdfb54f0fc48469527731e3fd9735",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0008",
    "providerId": "cohere",
    "techniqueId": "tech-community-feedback",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited community feedback integration focused on enterprise customer requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "8db8482bc861b1d6b0359cfe8b1c499d8fdcdfb54f0fc48469527731e3fd9735",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0009",
    "providerId": "cohere",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Domain-specific fine-tuning for enterprise safety requirements and business use cases",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/fine-tuning",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "04ddefe872ed7b5349fc117413229ca0158201d73cb7eafb54eaec9552ea80f7",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0010",
    "providerId": "cohere",
    "techniqueId": "tech-input-classification",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic input content classification with dual safety modes (strict/contextual)",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "8db8482bc861b1d6b0359cfe8b1c499d8fdcdfb54f0fc48469527731e3fd9735",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0011",
    "providerId": "cohere",
    "techniqueId": "tech-output-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Output filtering through dual safety modes with enterprise logging capabilities",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "8db8482bc861b1d6b0359cfe8b1c499d8fdcdfb54f0fc48469527731e3fd9735",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0012",
    "providerId": "cohere",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic prompt injection protection through safety mode filtering",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "8db8482bc861b1d6b0359cfe8b1c499d8fdcdfb54f0fc48469527731e3fd9735",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0013",
    "providerId": "cohere",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited real-time monitoring capabilities through safety mode enforcement",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "8db8482bc861b1d6b0359cfe8b1c499d8fdcdfb54f0fc48469527731e3fd9735",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0014",
    "providerId": "cohere",
    "techniqueId": "tech-contextual-safety",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Contextual safety assessment through CONTEXTUAL safety mode allowing nuanced moderation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "8db8482bc861b1d6b0359cfe8b1c499d8fdcdfb54f0fc48469527731e3fd9735",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0015",
    "providerId": "cohere",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic multi-stage pipeline with dual safety modes and enterprise integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "8db8482bc861b1d6b0359cfe8b1c499d8fdcdfb54f0fc48469527731e3fd9735",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0016",
    "providerId": "cohere",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Configurable safety policies through STRICT and CONTEXTUAL mode selection",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "8db8482bc861b1d6b0359cfe8b1c499d8fdcdfb54f0fc48469527731e3fd9735",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0017",
    "providerId": "cohere",
    "techniqueId": "tech-audit-logging",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise audit logging for disallowed prompts and safety mode enforcement",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "8db8482bc861b1d6b0359cfe8b1c499d8fdcdfb54f0fc48469527731e3fd9735",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0018",
    "providerId": "cohere",
    "techniqueId": "tech-enterprise-integration",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise security integration with on-premises deployment options",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cohere.com/enterprise",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0019",
    "providerId": "cohere",
    "techniqueId": "tech-sovereignty-options",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "On-premises deployment options for data sovereignty and enterprise control",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cohere.com/enterprise",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0020",
    "providerId": "cohere",
    "techniqueId": "tech-incident-reporting",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic incident reporting through enterprise support channels",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "8db8482bc861b1d6b0359cfe8b1c499d8fdcdfb54f0fc48469527731e3fd9735",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0021",
    "providerId": "cohere",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Usage monitoring and analytics for enterprise safety and compliance tracking",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "8db8482bc861b1d6b0359cfe8b1c499d8fdcdfb54f0fc48469527731e3fd9735",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0022",
    "providerId": "cohere",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise regulatory compliance frameworks with industry-specific requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cohere.com/enterprise",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0023",
    "providerId": "cohere",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited academic partnerships with focus on enterprise applications",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cohere.com/research",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "fde6b5d4ffc3c9b8bb1f5e275f0fb2af20249c2c3106afa5a052ec2b99a549df",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0024",
    "providerId": "cohere",
    "techniqueId": "tech-community-governance",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited community governance with enterprise customer feedback integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "8db8482bc861b1d6b0359cfe8b1c499d8fdcdfb54f0fc48469527731e3fd9735",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0025",
    "providerId": "cohere",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic safety documentation focused on safety modes and enterprise implementation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "8db8482bc861b1d6b0359cfe8b1c499d8fdcdfb54f0fc48469527731e3fd9735",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0026",
    "providerId": "cohere",
    "techniqueId": "tech-model-cards",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited model cards and technical specifications with enterprise focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "50721d24bcc0f963aada071fef9de88b750e06c8e770c5bfa757f4ec6879dde8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0027",
    "providerId": "cohere",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited safety research publications with focus on enterprise applications",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cohere.com/research",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "fde6b5d4ffc3c9b8bb1f5e275f0fb2af20249c2c3106afa5a052ec2b99a549df",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0028",
    "providerId": "cohere",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise policy and compliance documentation with safety mode implementation guides",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "8db8482bc861b1d6b0359cfe8b1c499d8fdcdfb54f0fc48469527731e3fd9735",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-mistral-0001",
    "providerId": "mistral",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Lightweight filtering with community-driven approach and European data focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "fcfa9299bfe3ae28409bc121f4e2e5c3b9ae7018df6157e8d62266c98f456d9b",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0002",
    "providerId": "mistral",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "European AI sovereignty focus with EU regulatory compliance measures",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "fcfa9299bfe3ae28409bc121f4e2e5c3b9ae7018df6157e8d62266c98f456d9b",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-mistral-0003",
    "providerId": "mistral",
    "techniqueId": "tech-rlhf",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Minimal RLHF implementation with community feedback integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "fcfa9299bfe3ae28409bc121f4e2e5c3b9ae7018df6157e8d62266c98f456d9b",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0004",
    "providerId": "mistral",
    "techniqueId": "tech-community-feedback",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community feedback integration for model improvement and safety enhancement",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "fcfa9299bfe3ae28409bc121f4e2e5c3b9ae7018df6157e8d62266c98f456d9b",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0005",
    "providerId": "mistral",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Domain-specific fine-tuning capabilities with European regulatory focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.mistral.ai/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "4f6396e971f8b841dd60e3837702470e50e75adef5bf4f9aa8ba9403efef96c2",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-mistral-0006",
    "providerId": "mistral",
    "techniqueId": "tech-input-classification",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Moderation API for input content classification with lightweight approach",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "fcfa9299bfe3ae28409bc121f4e2e5c3b9ae7018df6157e8d62266c98f456d9b",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0007",
    "providerId": "mistral",
    "techniqueId": "tech-output-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Content classification and filtering through Moderation API",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "fcfa9299bfe3ae28409bc121f4e2e5c3b9ae7018df6157e8d62266c98f456d9b",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0008",
    "providerId": "mistral",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic prompt injection protection through content classification",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "fcfa9299bfe3ae28409bc121f4e2e5c3b9ae7018df6157e8d62266c98f456d9b",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0009",
    "providerId": "mistral",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Lightweight safety pipeline with moderation API and content classification",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "fcfa9299bfe3ae28409bc121f4e2e5c3b9ae7018df6157e8d62266c98f456d9b",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0010",
    "providerId": "mistral",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic configurable policies through moderation API categories",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "fcfa9299bfe3ae28409bc121f4e2e5c3b9ae7018df6157e8d62266c98f456d9b",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0011",
    "providerId": "mistral",
    "techniqueId": "tech-community-governance",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community governance model with European AI sovereignty principles",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "fcfa9299bfe3ae28409bc121f4e2e5c3b9ae7018df6157e8d62266c98f456d9b",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0012",
    "providerId": "mistral",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "EU-focused regulatory compliance with European AI sovereignty emphasis",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "fcfa9299bfe3ae28409bc121f4e2e5c3b9ae7018df6157e8d62266c98f456d9b",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-mistral-0013",
    "providerId": "mistral",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited academic partnerships with European research institutions",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/research",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0014",
    "providerId": "mistral",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic safety documentation with moderation API specifications",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "fcfa9299bfe3ae28409bc121f4e2e5c3b9ae7018df6157e8d62266c98f456d9b",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0015",
    "providerId": "mistral",
    "techniqueId": "tech-model-cards",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited model cards and technical documentation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.mistral.ai/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "4f6396e971f8b841dd60e3837702470e50e75adef5bf4f9aa8ba9403efef96c2",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0016",
    "providerId": "mistral",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Minimal safety research publications with focus on efficiency",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/research",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0017",
    "providerId": "mistral",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic policy documentation with EU regulatory compliance focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-11-07",
        "sourceHash": "fcfa9299bfe3ae28409bc121f4e2e5c3b9ae7018df6157e8d62266c98f456d9b",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0001",
    "providerId": "baidu",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Chinese regulatory compliance with government-approved content filtering",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0002",
    "providerId": "baidu",
    "techniqueId": "tech-csam-detection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "CSAM detection in compliance with Chinese internet regulations",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0003",
    "providerId": "baidu",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive Chinese regulatory compliance with government oversight integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-baidu-0004",
    "providerId": "baidu",
    "techniqueId": "tech-rlhf",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "RLHF with alignment to Chinese values and regulatory requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0005",
    "providerId": "baidu",
    "techniqueId": "tech-input-classification",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Real-time censorship and political content filtering for input classification",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0006",
    "providerId": "baidu",
    "techniqueId": "tech-output-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Political content filtering and real-time censorship for output content",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0007",
    "providerId": "baidu",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic prompt injection protection through content filtering and government oversight",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0008",
    "providerId": "baidu",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Real-time monitoring with government oversight and regulatory compliance",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0009",
    "providerId": "baidu",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Multi-stage pipeline with government oversight and political content filtering",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0010",
    "providerId": "baidu",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Government-configured safety policies with Chinese regulatory compliance",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0011",
    "providerId": "baidu",
    "techniqueId": "tech-audit-logging",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Government audit logging and compliance tracking for regulatory oversight",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0012",
    "providerId": "baidu",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Direct government oversight and regulatory compliance with Chinese authorities",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-baidu-0013",
    "providerId": "baidu",
    "techniqueId": "tech-incident-reporting",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Government incident reporting with regulatory compliance tracking",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0014",
    "providerId": "baidu",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Usage monitoring with government oversight and regulatory compliance",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0015",
    "providerId": "baidu",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive Chinese regulatory compliance with government framework integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-baidu-0016",
    "providerId": "baidu",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited academic partnerships with Chinese research institutions",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0017",
    "providerId": "baidu",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited international transparency with Chinese regulatory documentation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0018",
    "providerId": "baidu",
    "techniqueId": "tech-model-cards",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic model cards with Chinese regulatory compliance information",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0019",
    "providerId": "baidu",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited international safety research publications with regulatory focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://research.baidu.com/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "0129a6649f7b95098cc2b812c5293740889775136b8738106035d05363431f8d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0020",
    "providerId": "baidu",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Chinese regulatory documentation with limited international transparency",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0001",
    "providerId": "alibaba",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Commercial focus with regulatory compliance and business-oriented filtering",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "25963cbfed0be36afd93338df0cbfb4860b3705fad492c5b8155a5409b48f325",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0002",
    "providerId": "alibaba",
    "techniqueId": "tech-csam-detection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "CSAM detection for Chinese regulatory compliance and commercial deployment",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "29ad08009b6ca8271589b27774c78441bb07c80ce589274a896717a987f1b9f3",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0003",
    "providerId": "alibaba",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Chinese regulatory compliance with commercial focus and efficiency optimization",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "e563e9df2cd672b2863726d2ed20015762300bd2a05e34e52d83e5794ec12cd4",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0004",
    "providerId": "alibaba",
    "techniqueId": "tech-rlhf",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Business-oriented RLHF with efficiency focus and commercial optimization",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "808bf2dbbf24c9202e24231a1d4f9389ea90db130f3797d4c5ecad5a929ea628",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0005",
    "providerId": "alibaba",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Domain-specific fine-tuning for business process automation and commercial safety",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "7b3f491a4814295733caf0c45da14a750faa732a2afe6c261d379067e4e0189a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0006",
    "providerId": "alibaba",
    "techniqueId": "tech-input-classification",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise content filtering with customer customization for business use cases",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "7fcb7b2ce7250474808040a11e6ff28960b5e18599e4413dd38594356148aa83",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0007",
    "providerId": "alibaba",
    "techniqueId": "tech-output-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Customer-customizable output filtering for enterprise and commercial applications",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "379d5f3579b05e26f4b1945dc943bbcfd021f8599233a606bf4610733626d3f4",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0008",
    "providerId": "alibaba",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic prompt injection protection through enterprise content filtering",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "84c13a6247802cd28a89871d56ab67359ccd6cb77b4fad513b5d87b0b81fd903",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0009",
    "providerId": "alibaba",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Real-time monitoring for commercial applications with business process integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "4dbc6888c1b26fb462953272a5c79bf0bd040ac7dd5cd05a040187681d5c66d4",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0010",
    "providerId": "alibaba",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Multi-stage pipeline with cloud integration and business process automation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "c26b1246dfb3a5c5b0fe4664eb54f98c8335f4fdf2df8ec97a1f737b3a0fd966",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0011",
    "providerId": "alibaba",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic PII detection for enterprise data protection and commercial compliance",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "0313f48d5566b9339972dbc6c3a3c86a09c3068df70616a7ea7d1352189b9489",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0012",
    "providerId": "alibaba",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Customer-configurable safety policies for enterprise deployment and business needs",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "dd56f77801df30ac85a5d17dfcd8a9e5d99a2e04b33f357b1b98ef34d94c6583",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0013",
    "providerId": "alibaba",
    "techniqueId": "tech-audit-logging",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise audit logging for business compliance and commercial accountability",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "d5461d9fca2cb00e5d78260c832cc9c8c6443419d1b2011695f19b28e7c801a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0014",
    "providerId": "alibaba",
    "techniqueId": "tech-enterprise-integration",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Cloud integration with Alibaba Cloud security and business process automation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "00f22e74881b1a107316cd7c9de45b29402477e8fde2f9e3817c485a3a3a7ca4",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0015",
    "providerId": "alibaba",
    "techniqueId": "tech-sovereignty-options",
    "modelIds": [],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Data sovereignty options through Alibaba Cloud with regional deployment flexibility",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "7304f33b5ce938fc309bee372a4e06f92658c211148de4b2c273d065f21ffe0e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-alibaba-0016",
    "providerId": "alibaba",
    "techniqueId": "tech-incident-reporting",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic incident reporting through enterprise support and commercial channels",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "ca33ad708e4b148c0ea977b4ea30050cc699243c0a09af2e28925c4778f2a880",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0017",
    "providerId": "alibaba",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise usage monitoring with business analytics and commercial optimization",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "947d8329c54c3da05000d342bc4192d3303107630e95904e50ece410c0e602a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0018",
    "providerId": "alibaba",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Chinese regulatory compliance frameworks with commercial focus and enterprise requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "134ae81e25fefd45d8cbb4e8376494def77d534e8c25063fb8cff2e4654c93a6",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0019",
    "providerId": "alibaba",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Business documentation with limited research disclosure and commercial focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "6e7bec108589b68de3ddddcec9378d57b6e99aaa6b48c858417d18a6e4286cf9",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0020",
    "providerId": "alibaba",
    "techniqueId": "tech-model-cards",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic model cards with commercial specifications and business application focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "b8481e041b50c1c0563cc2a6cabfb7ca5937302d96c5b06ff7b3b94baf6751ba",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0021",
    "providerId": "alibaba",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Business policy documentation with enterprise compliance and commercial requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-07",
        "sourceHash": "1b91a80bd54cb71d91c3fc554fa029d12c26661404e936ff9c3bdf6df9b40a3d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-x-constitutional-ai-001",
    "providerId": "x",
    "techniqueId": "tech-constitutional-ai",
    "modelIds": [],
    "summary": "Constitutional AI training methodology implemented in Grok-4 to align model behavior with human values and safety principles",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.ai/news/grok-4",
        "documentType": "blog-post",
        "relevantSection": "Training and Safety",
        "lastVerified": "2025-07-24",
        "sourceHash": "c6d3e7bfa462aef2201bdff29ed7472fefb66eed1a8478ae51f05b63a54e3de3"
      }
    ],
    "knownLimitations": [
      "Limited public details on specific constitutional principles",
      "No published effectiveness metrics"
    ],
    "notes": "Grok-4 implements constitutional AI for value alignment",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-realtime-fact-check-002",
    "providerId": "x",
    "techniqueId": "tech-realtime-fact-checking",
    "modelIds": [],
    "summary": "Integration with X platform's real-time information feed to fact-check claims and provide current information verification",
    "rating": "medium-high",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.ai/news/grok-4",
        "documentType": "blog-post",
        "relevantSection": "Real-time Information Access",
        "lastVerified": "2025-07-24",
        "sourceHash": "c6d3e7bfa462aef2201bdff29ed7472fefb66eed1a8478ae51f05b63a54e3de3"
      }
    ],
    "knownLimitations": [
      "Dependent on X platform data quality",
      "May amplify trending misinformation"
    ],
    "notes": "Unique capability leveraging X's real-time data stream",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "premium-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-platform-context-003",
    "providerId": "x",
    "techniqueId": "tech-contextual-safety",
    "modelIds": [],
    "summary": "Safety measures that consider broader X platform context, user interaction history, and social graph for contextual risk assessment",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.com/privacy",
        "documentType": "privacy-policy",
        "relevantSection": "Data Usage for AI Services",
        "lastVerified": "2025-11-07",
        "sourceHash": "55c4c0cf4a39fee24bf9a036776ded16197f013c0003ac7b69b6b67e38589c54"
      }
    ],
    "knownLimitations": [
      "Privacy implications of using social context",
      "Potential for social bias amplification"
    ],
    "notes": "Leverages X platform social context for safety",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-multimodal-safety-004",
    "providerId": "x",
    "techniqueId": "tech-multimodal-safety-alignment",
    "modelIds": [],
    "summary": "Cross-modal safety alignment for Grok-4's multimodal capabilities, ensuring safety across text, image, and audio interactions",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.ai/news/grok-4",
        "documentType": "blog-post",
        "relevantSection": "Multimodal Capabilities",
        "lastVerified": "2025-07-24",
        "sourceHash": "c6d3e7bfa462aef2201bdff29ed7472fefb66eed1a8478ae51f05b63a54e3de3"
      }
    ],
    "knownLimitations": [
      "Cross-modal safety interactions are complex",
      "Limited multimodal safety evaluation data"
    ],
    "notes": "Addresses safety across multiple modalities in Grok-4",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-input-classification-005",
    "providerId": "x",
    "techniqueId": "tech-input-classification",
    "modelIds": [],
    "summary": "Pre-processing classification of user inputs to identify potential safety risks before processing by Grok-4",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://help.x.com/en/rules-and-policies",
        "documentType": "policy-documentation",
        "relevantSection": "Content Moderation",
        "lastVerified": "2025-07-24",
        "sourceHash": "b737b99b7dde781f17abe0db3c6129d63edce718f07dad841b9e15ffd47fef2a"
      }
    ],
    "knownLimitations": [
      "May block benign content",
      "Context-dependent risks challenging to detect"
    ],
    "notes": "Integrated with X platform content moderation",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-output-filtering-006",
    "providerId": "x",
    "techniqueId": "tech-output-filtering",
    "modelIds": [],
    "summary": "Post-generation filtering of Grok-4 outputs for safety violations before presentation to users",
    "rating": "medium-high",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://help.x.com/en/rules-and-policies",
        "documentType": "policy-documentation",
        "relevantSection": "AI Content Guidelines",
        "lastVerified": "2025-07-24",
        "sourceHash": "b737b99b7dde781f17abe0db3c6129d63edce718f07dad841b9e15ffd47fef2a"
      }
    ],
    "knownLimitations": [
      "May alter intended meaning",
      "Can be overly restrictive"
    ],
    "notes": "Aligned with X platform community guidelines",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-realtime-monitoring-007",
    "providerId": "x",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "summary": "Continuous monitoring of Grok-4 interactions for safety violations and emerging risk patterns",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.com/tos",
        "documentType": "terms-of-service",
        "relevantSection": "Monitoring and Enforcement",
        "lastVerified": "2025-11-07",
        "sourceHash": "e282e38865bd17fa637ab3bd8c1ad50ba7d0c43e83a61fb92d83c3bec5d158d9"
      }
    ],
    "knownLimitations": [
      "Latency impact on user experience",
      "May miss contextual nuances"
    ],
    "notes": "Integrated with X platform monitoring infrastructure",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-pii-detection-008",
    "providerId": "x",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [],
    "summary": "Real-time detection and redaction of personally identifiable information in Grok-4 interactions",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.com/privacy",
        "documentType": "privacy-policy",
        "relevantSection": "Personal Information Protection",
        "lastVerified": "2025-11-07",
        "sourceHash": "4a3cdf18caadf56d6d797a6887d8ed7f4b75036bc9c936855db18d3dfbc2516e"
      }
    ],
    "knownLimitations": [
      "Context-dependent PII challenging to detect",
      "May miss novel PII patterns"
    ],
    "notes": "Complies with X platform privacy standards",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "GDPR",
      "CCPA"
    ],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-training-filtering-009",
    "providerId": "x",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [],
    "summary": "Systematic filtering of training data for Grok-4 to remove harmful, biased, or inappropriate content",
    "rating": "medium-low",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.ai/news/grok-4",
        "documentType": "blog-post",
        "relevantSection": "Data and Training",
        "lastVerified": "2025-07-24",
        "sourceHash": "c6d3e7bfa462aef2201bdff29ed7472fefb66eed1a8478ae51f05b63a54e3de3"
      }
    ],
    "knownLimitations": [
      "Limited transparency on filtering criteria",
      "May introduce demographic biases"
    ],
    "notes": "Standard pre-training data curation practices",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-audit-logging-010",
    "providerId": "x",
    "techniqueId": "tech-audit-logging",
    "modelIds": [],
    "summary": "Comprehensive logging of Grok-4 safety-relevant events and decisions for audit and improvement purposes",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.com/tos",
        "documentType": "terms-of-service",
        "relevantSection": "Data Retention and Logging",
        "lastVerified": "2025-11-07",
        "sourceHash": "836ee3ab1f3e82379113db2aacd3d8d31ee6fc2acea689ca643769f11f182958"
      }
    ],
    "knownLimitations": [
      "Storage and privacy considerations",
      "Log completeness not specified"
    ],
    "notes": "Supports X platform compliance requirements",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "SOC2"
    ],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  }
]