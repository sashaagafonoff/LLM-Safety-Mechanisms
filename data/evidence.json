[
  {
    "providerId": "anthropic",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [
      "model-claude-3-opus",
      "model-claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Constitutional training data with filtered corpora designed to reduce harmful content and improve model alignment",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "policy",
        "lastVerified": "2025-07-10",
        "sourceHash": "828ab119ebb84441747e58f064065331f74d51361307d967b007911d6e0e82ef",
        "relevantSection": "Safety and Security Standards"
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Specific filtering methods not detailed"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Part of Constitutional AI framework",
    "id": "ev-anthropic-0002"
  },
  {
    "providerId": "anthropic",
    "techniqueId": "tech-constitutional-ai",
    "modelIds": [
      "model-claude-3-opus",
      "model-claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Self-critique training using constitutional principles for helpful, harmless, honest behavior with scalable oversight",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2212.08073",
        "documentType": "research-paper",
        "lastVerified": "2025-07-10",
        "sourceHash": "9a456a07ad346e3372f9867d346f69f5b0f68b4c65f060aca0b8a13fa9d98e83",
        "relevantSection": "Section 3: Constitutional AI"
      }
    ],
    "implementationDate": "2022-12-15",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "evaluationMetrics": [
      {
        "metric": "human_preference_rate",
        "value": 76,
        "unit": "percent",
        "benchmarkContext": {
          "name": "Constitutional AI Eval",
          "version": "v1",
          "url": "https://arxiv.org/abs/2212.08073"
        }
      }
    ],
    "knownLimitations": [
      "May be overly conservative",
      "Principles require careful design"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Core safety innovation from Anthropic",
    "id": "ev-anthropic-0003"
  },
  {
    "providerId": "anthropic",
    "techniqueId": "tech-rlhf",
    "modelIds": [
      "model-claude-3-opus",
      "model-claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Constitutional AI approach combining self-critique with RLHF for scalable oversight and preference learning",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2212.08073",
        "documentType": "research-paper",
        "lastVerified": "2025-07-10",
        "sourceHash": "9a456a07ad346e3372f9867d346f69f5b0f68b4c65f060aca0b8a13fa9d98e83",
        "relevantSection": "Section 4: Training Process"
      }
    ],
    "implementationDate": "2022-12-15",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Subject to annotator biases",
      "Computationally expensive"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Combined with Constitutional AI for enhanced safety",
    "id": "ev-anthropic-0004"
  },
  {
    "providerId": "google",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [
      "model-gemini-pro"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Multi-lingual safety filtering and bias detection in training data preparation for Gemini models",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "d8c81b41d5c036bb3d90c206bddf3be84565583da93751b97f4c97c71ff24a9d",
        "relevantSection": "Training Data Safety"
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Specific methods not detailed"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "EU AI Act"
    ],
    "notes": "Focus on multilingual safety",
    "id": "ev-google-0005"
  },
  {
    "providerId": "google",
    "techniqueId": "tech-rlhf",
    "modelIds": [
      "model-gemini-pro"
    ],
    "rating": "medium",
    "severityBand": "B",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "RLHF with adversarial safety tuning datasets and Sparrow-style critiquing methodology",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2209.14375",
        "documentType": "research-paper",
        "lastVerified": "2025-07-10",
        "sourceHash": "e7df8fc1e41dfc3b47a781958fc53e6467f3b0ba3b0c10db5040f7924097709a",
        "relevantSection": "Section 3: Training Sparrow"
      }
    ],
    "implementationDate": "2022-09-29",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Limited to English initially"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Based on Sparrow research",
    "id": "ev-google-0006"
  },
  {
    "providerId": "meta",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [
      "model-llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Open training with safety benchmarks and Llama Guard integration for content filtering",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-07-10",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": "Section 4: Safety"
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Community-dependent verification"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Open source approach enables community verification",
    "id": "ev-meta-0007"
  },
  {
    "providerId": "meta",
    "techniqueId": "tech-rlhf",
    "modelIds": [
      "model-llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Two-phase RLHF with community-driven safety feedback and open source evaluation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-07-10",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": "Section 3.3: Fine-tuning"
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Resource intensive",
      "Community feedback quality varies"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Two-phase approach with safety-specific rewards",
    "id": "ev-meta-0008"
  },
  {
    "providerId": "meta",
    "techniqueId": "tech-input-classification",
    "modelIds": [
      "model-llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Llama Guard as separate safety classifier for input content with open source implementation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "research-paper",
        "lastVerified": "2025-07-10",
        "sourceHash": "eb8c90feb97a4a0065972dfba8ca59964a016d5ee69d088728b086c808c7b98e",
        "relevantSection": "Section 2: Llama Guard"
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Requires separate model inference"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Open source safety classifier",
    "id": "ev-meta-0009"
  },
  {
    "providerId": "amazon",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "model-titan-text-express"
    ],
    "rating": "medium",
    "severityBand": "B",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Advanced PII detection and redaction through Bedrock Guardrails with enterprise-grade protection",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails-sensitive-filters.html",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "78345f7d93b99083e289d59cf56d2c99eddef37d84d5fd7aba8b1337ffa927de",
        "relevantSection": "Sensitive Information Filters"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Language support varies",
      "Context-dependent PII challenging"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "HIPAA",
      "PCI-DSS"
    ],
    "notes": "Enterprise-grade PII protection",
    "id": "ev-amazon-0010"
  },
  {
    "providerId": "amazon",
    "techniqueId": "tech-input-classification",
    "modelIds": [
      "model-titan-text-express"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Bedrock Guardrails input classification with customizable policies and enterprise integration",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "7f13c29cdbbe4fe0a88694014617bb8fb51201e649092549a46395ec2763bb8a",
        "relevantSection": "Content Filters"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Requires configuration",
      "May have false positives"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Highly configurable for enterprise needs",
    "id": "ev-amazon-0011"
  },
  {
    "providerId": "amazon",
    "techniqueId": "tech-output-filtering",
    "modelIds": [
      "model-titan-text-express"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Bedrock Guardrails output filtering with hallucination detection and content policy enforcement",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "7f13c29cdbbe4fe0a88694014617bb8fb51201e649092549a46395ec2763bb8a",
        "relevantSection": "Output Moderation"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "May alter outputs",
      "Hallucination detection has limits"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Includes hallucination detection",
    "id": "ev-amazon-0012"
  },
  {
    "providerId": "anthropic",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "model-claude-3-opus",
      "model-claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "External red team engagement as part of responsible scaling policy and AI Safety Level assessments",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "policy",
        "lastVerified": "2025-07-10",
        "sourceHash": "3404f6aa5bd1a98d847e9c7e9ad6b59bb0818aca577a4fa7fba3624410fa4b58",
        "relevantSection": "AI Safety Levels"
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Specific findings not always public"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Part of ASL framework",
    "id": "ev-anthropic-0013"
  },
  {
    "providerId": "anthropic",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "model-claude-3-opus",
      "model-claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Responsible scaling policy and constitutional AI research provide comprehensive safety framework documentation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "policy",
        "lastVerified": "2025-07-10",
        "sourceHash": "a2de3cf968bd72fb1f045ee4e23c72de4582bc2f9d76b97b100ddd0637f8e774",
        "relevantSection": "Full Document"
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P12M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Industry-leading transparency",
    "id": "ev-anthropic-0014"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-csam-detection",
    "modelIds": [
      "model-gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Automated detection and removal of child sexual abuse material using specialized classifiers during pre-training data preparation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://openai.com/policies/usage-policies",
        "documentType": "policy",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "Prohibited Usage"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Detection rates not disclosed"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "NCMEC"
    ],
    "notes": "Part of comprehensive content filtering",
    "id": "ev-openai-0003"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-copyright-filtering",
    "modelIds": [
      "model-gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Fingerprinting system to remove opted-out images from training data, building on DALL-E 3 opt-out mechanism",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-07-10",
        "sourceHash": "a45484c549cae62741fbe31572831152f20489bded5e3e9a273201e67ae1175e",
        "relevantSection": "Section 2.1"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Only for opted-out content"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "DMCA"
    ],
    "notes": "Extends DALL-E 3 opt-out system",
    "id": "ev-openai-0004"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-bias-detection-training",
    "modelIds": [
      "model-gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Advanced data filtering processes to reduce biased content, though specific bias detection methods not fully detailed",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-07-10",
        "sourceHash": "a45484c549cae62741fbe31572831152f20489bded5e3e9a273201e67ae1175e",
        "relevantSection": "Safety Evaluations"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Specific methods not disclosed"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0005"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "model-gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Advanced data filtering processes to reduce personal information from training data using automated detection systems",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-07-10",
        "sourceHash": "a45484c549cae62741fbe31572831152f20489bded5e3e9a273201e67ae1175e",
        "relevantSection": "Data Processing"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Cannot catch all PII"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "GDPR",
      "CCPA"
    ],
    "notes": "",
    "id": "ev-openai-0006"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-adversarial-training",
    "modelIds": [
      "model-gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Red team data integration and adversarial testing during training, though specific methods not detailed",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-07-10",
        "sourceHash": "a45484c549cae62741fbe31572831152f20489bded5e3e9a273201e67ae1175e",
        "relevantSection": "Red Teaming"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Methods not fully disclosed"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0007"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-red-team-data",
    "modelIds": [
      "model-gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "100+ external red teamers across 45 languages and 29 countries, data integrated into training process",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-07-10",
        "sourceHash": "a45484c549cae62741fbe31572831152f20489bded5e3e9a273201e67ae1175e",
        "relevantSection": "External Red Teaming"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Extensive red team network",
    "id": "ev-openai-0008"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-input-classification",
    "modelIds": [
      "model-gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Layered policy engine with system prompt \u2192 model \u2192 content filter pipeline, including specialized voice classifiers",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-07-10",
        "sourceHash": "a45484c549cae62741fbe31572831152f20489bded5e3e9a273201e67ae1175e",
        "relevantSection": "Safety Pipeline"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Multi-layer approach",
    "id": "ev-openai-0009"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-output-filtering",
    "modelIds": [
      "model-gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Multi-stage content filtering with moderation API applied to both text and audio outputs",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-07-10",
        "sourceHash": "a45484c549cae62741fbe31572831152f20489bded5e3e9a273201e67ae1175e",
        "relevantSection": "Output Moderation"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Includes audio moderation",
    "id": "ev-openai-0010"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [
      "model-gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "System prompt protections and multi-layer filtering, though specific prompt injection defenses not detailed",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-07-10",
        "sourceHash": "a45484c549cae62741fbe31572831152f20489bded5e3e9a273201e67ae1175e",
        "relevantSection": "Safety Mitigations"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Specific defenses not disclosed"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0011"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "model-gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Real-time monitoring and enforcement with product-level mitigations including streaming audio analysis",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-07-10",
        "sourceHash": "a45484c549cae62741fbe31572831152f20489bded5e3e9a273201e67ae1175e",
        "relevantSection": "Real-time Voice"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Includes voice monitoring",
    "id": "ev-openai-0012"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-contextual-safety",
    "modelIds": [
      "model-gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Context-aware safety evaluation, particularly for voice interactions, though implementation not detailed",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-07-10",
        "sourceHash": "a45484c549cae62741fbe31572831152f20489bded5e3e9a273201e67ae1175e",
        "relevantSection": "Voice Safety"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Implementation details limited"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0013"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [
      "model-gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Comprehensive safety pipeline spanning pre-training, post-training, product development, and policy enforcement",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-07-10",
        "sourceHash": "a45484c549cae62741fbe31572831152f20489bded5e3e9a273201e67ae1175e",
        "relevantSection": "Safety Architecture"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "End-to-end approach",
    "id": "ev-openai-0014"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "model-gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "PII detection capabilities integrated into content filtering systems for personal information protection",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://openai.com/policies/usage-policies",
        "documentType": "policy",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "Privacy"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Details not specified"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "GDPR",
      "CCPA"
    ],
    "notes": "",
    "id": "ev-openai-0015"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [
      "model-gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Usage policies and moderation tools provided to users, with transparency reports and configurable settings",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://openai.com/policies/usage-policies",
        "documentType": "policy",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "Usage Policies"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Limited configurability"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0016"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-audit-logging",
    "modelIds": [
      "model-gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Usage monitoring and incident reporting systems for tracking and analyzing safety incidents",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-07-10",
        "sourceHash": "a45484c549cae62741fbe31572831152f20489bded5e3e9a273201e67ae1175e",
        "relevantSection": "Monitoring"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "SOC2"
    ],
    "notes": "",
    "id": "ev-openai-0017"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "model-gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Preparedness Framework with pre-defined capability thresholds and deployment decisions based on risk assessments",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/openai-preparedness-framework-beta.pdf",
        "documentType": "policy",
        "lastVerified": "2025-07-10",
        "sourceHash": "c84e3a59c7dab251e45434e0b0d3e8abadcea7293f995cf92d32269e7d290398",
        "relevantSection": "Full Document"
      }
    ],
    "implementationDate": "2023-10-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Industry-leading framework",
    "id": "ev-openai-0018"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-safety-advisory",
    "modelIds": [
      "model-gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Safety Advisory Group providing independent oversight and recommendations on deployment decisions",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-07-10",
        "sourceHash": "a45484c549cae62741fbe31572831152f20489bded5e3e9a273201e67ae1175e",
        "relevantSection": "Governance"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P12M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0019"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-incident-reporting",
    "modelIds": [
      "model-gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": true
    },
    "summary": "Systematic incident reporting and analysis with internal tracking and external disclosure mechanisms",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-07-10",
        "sourceHash": "a45484c549cae62741fbe31572831152f20489bded5e3e9a273201e67ae1175e",
        "relevantSection": "Incident Response"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0020"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "model-gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": true
    },
    "summary": "Comprehensive usage monitoring with analytics for detecting patterns of misuse and safety incidents",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-07-10",
        "sourceHash": "a45484c549cae62741fbe31572831152f20489bded5e3e9a273201e67ae1175e",
        "relevantSection": "Usage Analytics"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0021"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "model-gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Compliance with voluntary White House commitments and development of internal governance frameworks",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://openai.com/index/our-approach-to-ai-safety",
        "documentType": "blog-post",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "Commitments"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "White House Commitments"
    ],
    "notes": "",
    "id": "ev-openai-0022"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [
      "model-gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Collaboration with academic institutions and independent research organizations for safety evaluation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-07-10",
        "sourceHash": "a45484c549cae62741fbe31572831152f20489bded5e3e9a273201e67ae1175e",
        "relevantSection": "External Collaboration"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P12M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0023"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-model-cards",
    "modelIds": [
      "model-gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Technical documentation including model architecture, training methodology, and safety evaluation results",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-07-10",
        "sourceHash": "a45484c549cae62741fbe31572831152f20489bded5e3e9a273201e67ae1175e",
        "relevantSection": "Full Document"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P12M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Comprehensive system card",
    "id": "ev-openai-0024"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "model-gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Regular publication of safety research, evaluation methodologies, and lessons learned from deployment",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://openai.com/research",
        "documentType": "research-paper",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "Safety Research"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P12M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0025"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [
      "model-gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Comprehensive usage policies, terms of service, and compliance documentation publicly available",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://openai.com/policies",
        "documentType": "policy",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "All Policies"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0026"
  },
  {
    "providerId": "google",
    "techniqueId": "tech-watermarking",
    "modelIds": [
      "model-gemini-pro"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": true
    },
    "summary": "SynthID watermarking technology for AI-generated image and audio content identification",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/science/synthid/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "4f071251e21f57201c19df37e36ec8aaf8abbba1af74e493d1d9278cf82dcdb3",
        "relevantSection": "Technology Overview"
      }
    ],
    "implementationDate": "2023-08-29",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Limited to certain content types"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Industry-leading watermarking",
    "id": "ev-google-0003"
  },
  {
    "providerId": "google",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "model-gemini-pro"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "EU AI Act compliance measures with transparency registers and regulatory reporting mechanisms",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://blog.google/technology/ai/google-ai-act-preparation/",
        "documentType": "blog-post",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "Compliance Measures"
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "EU AI Act"
    ],
    "notes": "Proactive compliance",
    "id": "ev-google-0004"
  },
  {
    "providerId": "google",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [
      "model-gemini-pro"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Multi-stage safety layers including toxicity detection, policy checks, and SynthID watermarking",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "d8c81b41d5c036bb3d90c206bddf3be84565583da93751b97f4c97c71ff24a9d",
        "relevantSection": "Safety Architecture"
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-google-0005"
  },
  {
    "providerId": "google",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [
      "model-gemini-pro"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Academic partnerships for AI safety research and independent evaluation of safety measures",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/research/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "a6810900b6799797a809eb3370bdfc90c812985ea1e5efaceedc59e1c931c3ee",
        "relevantSection": "Collaborations"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P12M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-google-0006"
  },
  {
    "providerId": "meta",
    "techniqueId": "tech-output-filtering",
    "modelIds": [
      "model-llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Llama Guard output filtering with contextual moderation and open source validation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "research-paper",
        "lastVerified": "2025-07-10",
        "sourceHash": "6850c2547c233d23b2c39dea073c272721d80e60fec490b22fe837dd8946d331",
        "relevantSection": "Output Moderation"
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Requires separate inference"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Open source implementation",
    "id": "ev-meta-0004"
  },
  {
    "providerId": "meta",
    "techniqueId": "tech-bias-detection-training",
    "modelIds": [
      "model-llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "B",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Bias detection and mitigation with community-driven evaluation and open source validation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-07-10",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": "Section 5.2: Bias Evaluation"
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Community-dependent validation"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-meta-0005"
  },
  {
    "id": "ev-openai-0027",
    "providerId": "openai",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "model-gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Systematic evaluation protocols for dangerous capabilities including cybersecurity, CBRN, persuasion, and autonomy",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-07-10",
        "sourceHash": "a45484c549cae62741fbe31572831152f20489bded5e3e9a273201e67ae1175e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-openai-0028",
    "providerId": "openai",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "model-gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Systematic red team exercises across multiple phases with diverse expert networks and real-world testing scenarios",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-07-10",
        "sourceHash": "a45484c549cae62741fbe31572831152f20489bded5e3e9a273201e67ae1175e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-openai-0031",
    "providerId": "openai",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "model-gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Detailed system cards providing comprehensive safety evaluations, methodologies, and results for each model release",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-07-10",
        "sourceHash": "a45484c549cae62741fbe31572831152f20489bded5e3e9a273201e67ae1175e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-anthropic-0005",
    "providerId": "anthropic",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "model-claude-3-opus",
      "model-claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Personal information filtering as part of constitutional training data preparation",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/claude-3-model-card",
        "documentType": "system-card",
        "lastVerified": "2025-07-10",
        "sourceHash": "88ae851f53c3034d436816164ce49a876b333fa9b550fb7ef29838182b59ba7d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-03-04",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0006",
    "providerId": "anthropic",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "model-claude-3-opus",
      "model-claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Compliance with emerging AI regulations and industry standards through responsible scaling policy",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "cf7e4cae3e245c60517c1ebc4aa0b0e71a370fd6414a7d9aecca9a115f144b7f",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0009",
    "providerId": "anthropic",
    "techniqueId": "tech-safety-reward-modeling",
    "modelIds": [
      "model-claude-3-opus",
      "model-claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Safety considerations integrated into reward modeling as part of constitutional AI framework",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2212.08073",
        "documentType": "research-paper",
        "lastVerified": "2025-07-10",
        "sourceHash": "9a456a07ad346e3372f9867d346f69f5b0f68b4c65f060aca0b8a13fa9d98e83",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2022-12-15",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0010",
    "providerId": "anthropic",
    "techniqueId": "tech-adversarial-training",
    "modelIds": [
      "model-claude-3-opus",
      "model-claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Adversarial testing integrated into constitutional AI training process for robustness",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2212.08073",
        "documentType": "research-paper",
        "lastVerified": "2025-07-10",
        "sourceHash": "9a456a07ad346e3372f9867d346f69f5b0f68b4c65f060aca0b8a13fa9d98e83",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2022-12-15",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBC"
  },
  {
    "id": "ev-anthropic-0011",
    "providerId": "anthropic",
    "techniqueId": "tech-red-team-data",
    "modelIds": [
      "model-claude-3-opus",
      "model-claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Red team exercises and data integration as part of responsible scaling policy and safety evaluation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "aadb57175df25b1f8abf39a95682d1aa8b407d526bcf75eed064e793fc0d3e3a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-anthropic-0012",
    "providerId": "anthropic",
    "techniqueId": "tech-input-classification",
    "modelIds": [
      "model-claude-3-opus",
      "model-claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Content classification systems for input filtering, though specific implementation details not public",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/claude-3-model-card",
        "documentType": "system-card",
        "lastVerified": "2025-07-10",
        "sourceHash": "88ae851f53c3034d436816164ce49a876b333fa9b550fb7ef29838182b59ba7d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-03-04",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0015",
    "providerId": "anthropic",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "model-claude-3-opus",
      "model-claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Safety monitoring systems in place, though specific real-time implementation details not disclosed",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/claude-3-model-card",
        "documentType": "system-card",
        "lastVerified": "2025-07-10",
        "sourceHash": "88ae851f53c3034d436816164ce49a876b333fa9b550fb7ef29838182b59ba7d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-03-04",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0016",
    "providerId": "anthropic",
    "techniqueId": "tech-contextual-safety",
    "modelIds": [
      "model-claude-3-opus",
      "model-claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Constitutional AI enables sophisticated contextual safety assessment through principle-based reasoning",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2212.08073",
        "documentType": "research-paper",
        "lastVerified": "2025-07-10",
        "sourceHash": "9a456a07ad346e3372f9867d346f69f5b0f68b4c65f060aca0b8a13fa9d98e83",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2022-12-15",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-anthropic-0017",
    "providerId": "anthropic",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [
      "model-claude-3-opus",
      "model-claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive safety pipeline including constitutional training, RLHF, and responsible scaling evaluation",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "079635b1ddacdbeadfa48b4506621c68ca2585acf6e45b856e0ee12fbc844d24",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-anthropic-0018",
    "providerId": "anthropic",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "model-claude-3-opus",
      "model-claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "PII protection mechanisms integrated into constitutional AI framework",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/claude-3-model-card",
        "documentType": "system-card",
        "lastVerified": "2025-07-10",
        "sourceHash": "88ae851f53c3034d436816164ce49a876b333fa9b550fb7ef29838182b59ba7d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-03-04",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0019",
    "providerId": "anthropic",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [
      "model-claude-3-opus",
      "model-claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Constitutional principles provide framework for configurable safety responses",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2212.08073",
        "documentType": "research-paper",
        "lastVerified": "2025-07-10",
        "sourceHash": "9a456a07ad346e3372f9867d346f69f5b0f68b4c65f060aca0b8a13fa9d98e83",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2022-12-15",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0020",
    "providerId": "anthropic",
    "techniqueId": "tech-audit-logging",
    "modelIds": [
      "model-claude-3-opus",
      "model-claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Audit and monitoring capabilities as part of responsible scaling policy framework",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "99e3e9d019534ddc7cd09c2c275fc1e346bd690fb76812bfdcf8c760d17a9ac5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0021",
    "providerId": "anthropic",
    "techniqueId": "tech-watermarking",
    "modelIds": [
      "model-claude-3-opus",
      "model-claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "B",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Research into watermarking techniques for AI-generated content detection and provenance",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "a211231a6ad65944a8e1da03af1d243aaa763f694d60d0814a28dc6b4da5b33c",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MRC"
  },
  {
    "id": "ev-anthropic-0023",
    "providerId": "anthropic",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "model-claude-3-opus",
      "model-claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "AI Safety Level (ASL) framework with clear classifications and deployment thresholds",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "bb8b506a71da3f294fae28d0d069a4ea4d3df2fab05952a465ae077dfe7eaa17",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-anthropic-0024",
    "providerId": "anthropic",
    "techniqueId": "tech-safety-advisory",
    "modelIds": [
      "model-claude-3-opus",
      "model-claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Independent safety advisory structure as part of responsible scaling policy governance",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "00e09395ed56dbcbd76af9daf44fdbd936d00342e6b94a4f326e2dc9484854c1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-anthropic-0025",
    "providerId": "anthropic",
    "techniqueId": "tech-incident-reporting",
    "modelIds": [
      "model-claude-3-opus",
      "model-claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Incident reporting and analysis systems integrated into responsible scaling framework",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "c025aca43e1da49fe330752ec6fca0f8048a87c0c013c694732ee25539d48031",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-anthropic-0026",
    "providerId": "anthropic",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "model-claude-3-opus",
      "model-claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Usage monitoring capabilities for safety assessment and responsible scaling decisions",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "e2e72913ac3656665bd2d2366084d09d3c93a320ac71ca699ae1a8483b0faa2b",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0027",
    "providerId": "anthropic",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "model-claude-3-opus",
      "model-claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Systematic capability evaluation protocols as part of ASL framework and responsible scaling",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "dda75141f2b0104bba6b8242206319fc961ee98be43f0d6b183050f57a6ad27d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-anthropic-0028",
    "providerId": "anthropic",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "model-claude-3-opus",
      "model-claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive red team exercises for capability assessment and safety evaluation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "f3552f4b8b3aee51ed312a3442736bcd68c191af738fc94cd5452641c3a6f387",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-anthropic-0029",
    "providerId": "anthropic",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "model-claude-3-opus",
      "model-claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Proactive regulatory compliance through responsible scaling policy and industry engagement",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "d41b19bd805e8fd19cf40d3281ab98455c8ba86d202e3ce04bb3d70f658a96eb",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-anthropic-0030",
    "providerId": "anthropic",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [
      "model-claude-3-opus",
      "model-claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Academic collaborations for safety research and constitutional AI development",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/research",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "2e5ca6c366086d6b1ae96e10cb7731cd7744c96368bac08fe5182336aebdb578",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-anthropic-0032",
    "providerId": "anthropic",
    "techniqueId": "tech-model-cards",
    "modelIds": [
      "model-claude-3-opus",
      "model-claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Model cards available for Claude models with technical specifications and safety information",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/claude-3-model-card",
        "documentType": "system-card",
        "lastVerified": "2025-07-10",
        "sourceHash": "88ae851f53c3034d436816164ce49a876b333fa9b550fb7ef29838182b59ba7d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-03-04",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-anthropic-0033",
    "providerId": "anthropic",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "model-claude-3-opus",
      "model-claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Extensive publication of constitutional AI research and safety methodologies",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/research",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "ea19b55b7cd52811a9a318e0c046d0ea32abc00be141fa6c5dec2e010e3b0117",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-anthropic-0034",
    "providerId": "anthropic",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [
      "model-claude-3-opus",
      "model-claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive policy documentation including responsible scaling policy and usage guidelines",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "067a8cf2d8500fce7bfc5a598fa29e0f0c7589c6e8d5b1bf5c1bab121b5b13c0",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-google-0002",
    "providerId": "google",
    "techniqueId": "tech-csam-detection",
    "modelIds": [
      "model-gemini-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "CSAM detection and removal systems implemented as part of standard content filtering pipeline",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "d8c81b41d5c036bb3d90c206bddf3be84565583da93751b97f4c97c71ff24a9d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0008",
    "providerId": "google",
    "techniqueId": "tech-constitutional-ai",
    "modelIds": [
      "model-gemini-pro"
    ],
    "rating": "medium",
    "severityBand": "B",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Research into constitutional AI principles and self-critique mechanisms for Gemini safety",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "d8c81b41d5c036bb3d90c206bddf3be84565583da93751b97f4c97c71ff24a9d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MRC"
  },
  {
    "id": "ev-google-0009",
    "providerId": "google",
    "techniqueId": "tech-safety-reward-modeling",
    "modelIds": [
      "model-gemini-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Safety considerations integrated into reward modeling for Gemini training optimization",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "d8c81b41d5c036bb3d90c206bddf3be84565583da93751b97f4c97c71ff24a9d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0010",
    "providerId": "google",
    "techniqueId": "tech-adversarial-training",
    "modelIds": [
      "model-gemini-pro"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Adversarial safety tuning datasets used in RLHF process for robustness improvement",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2209.14375",
        "documentType": "research-paper",
        "lastVerified": "2025-07-10",
        "sourceHash": "e7df8fc1e41dfc3b47a781958fc53e6467f3b0ba3b0c10db5040f7924097709a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2022-09-29",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBC"
  },
  {
    "id": "ev-google-0011",
    "providerId": "google",
    "techniqueId": "tech-red-team-data",
    "modelIds": [
      "model-gemini-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Red team exercises and data integration for Gemini safety evaluation and improvement",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "d8c81b41d5c036bb3d90c206bddf3be84565583da93751b97f4c97c71ff24a9d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0012",
    "providerId": "google",
    "techniqueId": "tech-input-classification",
    "modelIds": [
      "model-gemini-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Multi-stage safety layer including toxicity and content classification for input processing",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "d8c81b41d5c036bb3d90c206bddf3be84565583da93751b97f4c97c71ff24a9d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0013",
    "providerId": "google",
    "techniqueId": "tech-output-filtering",
    "modelIds": [
      "model-gemini-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Output content filtering with toxicity classifiers and safety policy enforcement",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "d8c81b41d5c036bb3d90c206bddf3be84565583da93751b97f4c97c71ff24a9d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0014",
    "providerId": "google",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [
      "model-gemini-pro"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic prompt injection protection through input filtering and safety classifiers",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "d8c81b41d5c036bb3d90c206bddf3be84565583da93751b97f4c97c71ff24a9d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBC"
  },
  {
    "id": "ev-google-0015",
    "providerId": "google",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "model-gemini-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Real-time safety monitoring capabilities integrated into Gemini deployment infrastructure",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "d8c81b41d5c036bb3d90c206bddf3be84565583da93751b97f4c97c71ff24a9d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0016",
    "providerId": "google",
    "techniqueId": "tech-contextual-safety",
    "modelIds": [
      "model-gemini-pro"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Contextual safety assessment capabilities, though specific implementation details not disclosed",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "d8c81b41d5c036bb3d90c206bddf3be84565583da93751b97f4c97c71ff24a9d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBC"
  },
  {
    "id": "ev-google-0018",
    "providerId": "google",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "model-gemini-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "PII detection and redaction capabilities integrated into safety pipeline",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "d8c81b41d5c036bb3d90c206bddf3be84565583da93751b97f4c97c71ff24a9d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0019",
    "providerId": "google",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [
      "model-gemini-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Configurable safety policies and content filtering options for different deployment contexts",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "d8c81b41d5c036bb3d90c206bddf3be84565583da93751b97f4c97c71ff24a9d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0020",
    "providerId": "google",
    "techniqueId": "tech-audit-logging",
    "modelIds": [
      "model-gemini-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Audit logging capabilities for safety incident tracking and regulatory compliance",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://blog.google/technology/ai/google-ai-act-preparation/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0022",
    "providerId": "google",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "model-gemini-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "External red team engagement for Gemini safety evaluation and testing",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "d8c81b41d5c036bb3d90c206bddf3be84565583da93751b97f4c97c71ff24a9d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0023",
    "providerId": "google",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "model-gemini-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Internal safety classification system for model capabilities and deployment decisions",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "d8c81b41d5c036bb3d90c206bddf3be84565583da93751b97f4c97c71ff24a9d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0024",
    "providerId": "google",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "model-gemini-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Capability evaluation protocols for dangerous capabilities and safety assessment",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "d8c81b41d5c036bb3d90c206bddf3be84565583da93751b97f4c97c71ff24a9d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0025",
    "providerId": "google",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "model-gemini-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Red team exercises for capability discovery and safety evaluation across multiple domains",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "d8c81b41d5c036bb3d90c206bddf3be84565583da93751b97f4c97c71ff24a9d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0026",
    "providerId": "google",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "model-gemini-pro"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive regulatory compliance frameworks including EU AI Act preparation and transparency measures",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://blog.google/technology/ai/google-ai-act-preparation/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-google-0028",
    "providerId": "google",
    "techniqueId": "tech-model-cards",
    "modelIds": [
      "model-gemini-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Model cards and technical documentation for Gemini models with safety information",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/gemini/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "92b6792423f2f3855282980fe501528d766707a406dd86acbe372b0c96222bca",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-meta-0002",
    "providerId": "meta",
    "techniqueId": "tech-csam-detection",
    "modelIds": [
      "model-llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "CSAM detection and removal processes integrated into training data preparation",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "2c8a37adc46986f4d6696029e69cf581a9e12580de602e39e67ef39b2e39b636",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0003",
    "providerId": "meta",
    "techniqueId": "tech-copyright-filtering",
    "modelIds": [
      "model-llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Copyright filtering mechanisms for training data with open source transparency",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-07-10",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0006",
    "providerId": "meta",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "model-llama-3-70b"
    ],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic regulatory compliance measures with limited international regulatory integration",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "fd9da5a9d27360ac2cb6a0fab2fd2349e0c6d7d8ce7323a2d1790a8335af657c",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPC"
  },
  {
    "id": "ev-meta-0010",
    "providerId": "meta",
    "techniqueId": "tech-community-feedback",
    "modelIds": [
      "model-llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community-driven safety feedback with open source evaluation harness and academic partnerships",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "5f4635803154a1ef7add7724deb5cbf0f7b5e5b33cb3002e2fbe92ee3ead9f2d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPV"
  },
  {
    "id": "ev-meta-0013",
    "providerId": "meta",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [
      "model-llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic prompt injection protection through Llama Guard classification and community testing",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "475347e1a26654c2c113ad6e308c23d95b07cd6b68fee31f2b75f6709526daeb",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBC"
  },
  {
    "id": "ev-meta-0014",
    "providerId": "meta",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "model-llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Real-time safety monitoring capabilities through Llama Guard integration",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "d9bb188e47adea55e3f2c880b9c870d98e6916c4d635dd619d89b18900b61707",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0015",
    "providerId": "meta",
    "techniqueId": "tech-contextual-safety",
    "modelIds": [
      "model-llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Contextual moderation capabilities through Llama Guard classification system",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0002a83287bfed1a06ed9cb92cc35e882b885103803bbe1f376ee73c8a8af4be",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBC"
  },
  {
    "id": "ev-meta-0016",
    "providerId": "meta",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [
      "model-llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Multi-stage safety pipeline with Llama Guard integration and community validation",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-07-10",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0017",
    "providerId": "meta",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "model-llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "PII detection capabilities integrated into Llama Guard classification system",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "af4c985fa18038e42b02b754ba70e0d18fe6e32a185f07aa81dfca5b480f1f33",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0018",
    "providerId": "meta",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [
      "model-llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Configurable safety policies through open source Llama Guard implementation",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "400854f02824fc602d68c2af055dbb2ed96ed49643a753c6e2e037e5d4d709f1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0019",
    "providerId": "meta",
    "techniqueId": "tech-audit-logging",
    "modelIds": [
      "model-llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic audit logging capabilities with open source transparency and community oversight",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "8992414dd1075f1cd28ecc72a8cf257bd95f30e92b67364c2ddb31e12fb41f3e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0020",
    "providerId": "meta",
    "techniqueId": "tech-opensource-tools",
    "modelIds": [
      "model-llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive open source safety tools including Llama Guard and evaluation frameworks",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://github.com/meta-llama",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "96c58c5632435d4144db3e88c3d46aa7286296f42b5c2de8f33862eba8567420",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-meta-0021",
    "providerId": "meta",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "model-llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community-driven red team networks with academic partnerships and open evaluation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-07-10",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBV"
  },
  {
    "id": "ev-meta-0022",
    "providerId": "meta",
    "techniqueId": "tech-responsible-release",
    "modelIds": [
      "model-llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Responsible release checklist with community evaluation and academic partnership validation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "52189a1c29ec21005579e3e4d14ba9697f68a8a6be7e5d4ab7540290cb99d1fd",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-meta-0023",
    "providerId": "meta",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [
      "model-llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Extensive academic partnerships for safety evaluation and community-driven research",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "73e68f13678539026a59acefebf7fbecf87f4d2cacf6c94e75292b97c67be1e3",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-meta-0024",
    "providerId": "meta",
    "techniqueId": "tech-safety-benchmarks",
    "modelIds": [
      "model-llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Open safety benchmarks and evaluation metrics with community validation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-07-10",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-meta-0025",
    "providerId": "meta",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "model-llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community-driven capability evaluation protocols with open source validation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-07-10",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBV"
  },
  {
    "id": "ev-meta-0026",
    "providerId": "meta",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "model-llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community-driven red team exercises with academic partnerships and open evaluation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-07-10",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBV"
  },
  {
    "id": "ev-meta-0027",
    "providerId": "meta",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "model-llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic regulatory compliance frameworks with open source transparency",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "e9f8d170e93479bef9d83df24ac854b6bba2cd7102fae16ec79bd39c6ec25182",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0028",
    "providerId": "meta",
    "techniqueId": "tech-community-governance",
    "modelIds": [
      "model-llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Community governance model with open source development and academic oversight",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "d7d0beeb79c5d7965c4959fda1cf4867ed2bf27766e249453bde54262284c63a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-meta-0029",
    "providerId": "meta",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "model-llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Open safety documentation with research papers and community evaluation results",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-07-10",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-meta-0030",
    "providerId": "meta",
    "techniqueId": "tech-model-cards",
    "modelIds": [
      "model-llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Open model cards and technical specifications with community validation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "a16cd9ff7e3afc7baf57db0612ecd898a7498daf216d5c632d3d9193366601a5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-meta-0031",
    "providerId": "meta",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "model-llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Extensive safety research publications with peer review and community validation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "b00cec482773fd17d6672114c8284151eeec99bc31be17da27e5258749c62d5e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-meta-0032",
    "providerId": "meta",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [
      "model-llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Open policy and compliance documentation with community feedback integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "ae92c48005db3a69ddb34325709ccecf64313e7e49e23dd9824fa5d1137e57e5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-meta-0033",
    "providerId": "meta",
    "techniqueId": "tech-community-evaluation",
    "modelIds": [
      "model-llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Open community evaluation frameworks with academic partnerships and peer review",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "a67eac29fc255e1c2148707ed8157b3f528491d267996ec95da40d36a66a0506",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0001",
    "providerId": "amazon",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [
      "model-titan-text-express"
    ],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise-focused training data curation with customer data isolation and basic filtering",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "674a1b5e13e37d8fedfedecf001a4d91f05b28cd6281f7aa359517952e354256",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-amazon-0002",
    "providerId": "amazon",
    "techniqueId": "tech-csam-detection",
    "modelIds": [
      "model-titan-text-express"
    ],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Standard CSAM detection integrated into Bedrock platform with enterprise compliance",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "7f13c29cdbbe4fe0a88694014617bb8fb51201e649092549a46395ec2763bb8a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-amazon-0003",
    "providerId": "amazon",
    "techniqueId": "tech-copyright-filtering",
    "modelIds": [
      "model-titan-text-express"
    ],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic copyright filtering with enterprise compliance and customer-configurable policies",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "7f13c29cdbbe4fe0a88694014617bb8fb51201e649092549a46395ec2763bb8a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-amazon-0004",
    "providerId": "amazon",
    "techniqueId": "tech-bias-detection-training",
    "modelIds": [
      "model-titan-text-express"
    ],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited bias detection capabilities with enterprise compliance focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "7f13c29cdbbe4fe0a88694014617bb8fb51201e649092549a46395ec2763bb8a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-amazon-0006",
    "providerId": "amazon",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "model-titan-text-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise regulatory compliance frameworks with industry-specific guardrails",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://aws.amazon.com/compliance/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "ade6486183d8bc8461579083a54e51eccd00689d3a94dca228c125724b1d2834",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0007",
    "providerId": "amazon",
    "techniqueId": "tech-rlhf",
    "modelIds": [
      "model-titan-text-express"
    ],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic RLHF with customer fine-tuning options and domain-specific safety optimization",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "674a1b5e13e37d8fedfedecf001a4d91f05b28cd6281f7aa359517952e354256",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-amazon-0008",
    "providerId": "amazon",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [
      "model-titan-text-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Customer fine-tuning options with domain-specific safety configurations and enterprise controls",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/custom-models.html",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "38e2a93cc6d2a5a0c342236ed8afa0c96591e80fbb83740a70f903abadabde28",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0013",
    "providerId": "amazon",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [
      "model-titan-text-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Multi-stage safety pipeline with Bedrock Guardrails and AWS security integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "7f13c29cdbbe4fe0a88694014617bb8fb51201e649092549a46395ec2763bb8a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0014",
    "providerId": "amazon",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "model-titan-text-express"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Advanced PII detection and redaction with enterprise-grade sensitive information filters",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails-sensitive-filters.html",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "78345f7d93b99083e289d59cf56d2c99eddef37d84d5fd7aba8b1337ffa927de",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0015",
    "providerId": "amazon",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [
      "model-titan-text-express"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Highly configurable safety policies through Bedrock Guardrails with customer customization",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "7f13c29cdbbe4fe0a88694014617bb8fb51201e649092549a46395ec2763bb8a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0016",
    "providerId": "amazon",
    "techniqueId": "tech-audit-logging",
    "modelIds": [
      "model-titan-text-express"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive audit logging through AWS CloudTrail with enterprise compliance tracking",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/logging-monitoring.html",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "e287c7b44ce23e4a471bebf2532b8c016fe17840bd35f1c048360118f99a599e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0017",
    "providerId": "amazon",
    "techniqueId": "tech-enterprise-integration",
    "modelIds": [
      "model-titan-text-express"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Deep enterprise security integration with AWS IAM, VPC, and compliance frameworks",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/security.html",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "3e82ddd78f2de438f7b597e4418a6287c23eff16d0bb89d37d7138cf6c11c247",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0018",
    "providerId": "amazon",
    "techniqueId": "tech-sovereignty-options",
    "modelIds": [
      "model-titan-text-express"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Data sovereignty options with AWS regions and customer-controlled encryption keys",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://aws.amazon.com/compliance/data-privacy/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "bdc3ba1a2ae52668004d7861754a3cd2e72ce08c9b25d7ca2eb998bafa69d230",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0019",
    "providerId": "amazon",
    "techniqueId": "tech-incident-reporting",
    "modelIds": [
      "model-titan-text-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise incident reporting through AWS support and compliance frameworks",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/logging-monitoring.html",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "e287c7b44ce23e4a471bebf2532b8c016fe17840bd35f1c048360118f99a599e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0020",
    "providerId": "amazon",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "model-titan-text-express"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive usage monitoring through AWS CloudWatch with enterprise analytics",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/logging-monitoring.html",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "e287c7b44ce23e4a471bebf2532b8c016fe17840bd35f1c048360118f99a599e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0021",
    "providerId": "amazon",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "model-titan-text-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise regulatory compliance with AWS compliance certifications and industry standards",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://aws.amazon.com/compliance/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "6d06702b178024ebf462ddb2934115720a6946cf49276e55e85a58f0a573ef59",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0022",
    "providerId": "amazon",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "model-titan-text-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise-focused safety documentation with AWS service documentation and compliance guides",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "7f13c29cdbbe4fe0a88694014617bb8fb51201e649092549a46395ec2763bb8a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0023",
    "providerId": "amazon",
    "techniqueId": "tech-model-cards",
    "modelIds": [
      "model-titan-text-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "AWS AI Service Cards with model specifications and enterprise integration documentation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://aws.amazon.com/machine-learning/ai-service-cards/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0024",
    "providerId": "amazon",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [
      "model-titan-text-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Comprehensive enterprise policy and compliance documentation with AWS security frameworks",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://aws.amazon.com/compliance/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "ad7ffcc47d65ee7c5ed29af4c06886beedac970270d1bf97b7581b24b1d72f2b",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0001",
    "providerId": "cohere",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise document focus with bias metrics during training for business use cases",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "3afcafd8def1ad0ce0bf983a23420960605aeea6f100372ebe8a1a267b3de123",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0002",
    "providerId": "cohere",
    "techniqueId": "tech-csam-detection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic CSAM detection as part of enterprise content filtering systems",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "3afcafd8def1ad0ce0bf983a23420960605aeea6f100372ebe8a1a267b3de123",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0003",
    "providerId": "cohere",
    "techniqueId": "tech-copyright-filtering",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Copyright filtering mechanisms for enterprise compliance and content policies",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "3afcafd8def1ad0ce0bf983a23420960605aeea6f100372ebe8a1a267b3de123",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-cohere-0004",
    "providerId": "cohere",
    "techniqueId": "tech-bias-detection-training",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Bias metrics published during training with focus on enterprise fairness requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "3afcafd8def1ad0ce0bf983a23420960605aeea6f100372ebe8a1a267b3de123",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0005",
    "providerId": "cohere",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic PII reduction capabilities for enterprise data protection requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "3afcafd8def1ad0ce0bf983a23420960605aeea6f100372ebe8a1a267b3de123",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0006",
    "providerId": "cohere",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise compliance filtering with focus on business regulatory requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "3afcafd8def1ad0ce0bf983a23420960605aeea6f100372ebe8a1a267b3de123",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0007",
    "providerId": "cohere",
    "techniqueId": "tech-rlhf",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "RLHF for business use cases with enterprise-focused training optimization",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "3afcafd8def1ad0ce0bf983a23420960605aeea6f100372ebe8a1a267b3de123",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0008",
    "providerId": "cohere",
    "techniqueId": "tech-community-feedback",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited community feedback integration focused on enterprise customer requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "3afcafd8def1ad0ce0bf983a23420960605aeea6f100372ebe8a1a267b3de123",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0009",
    "providerId": "cohere",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Domain-specific fine-tuning for enterprise safety requirements and business use cases",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/fine-tuning",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "1e3339e103612d613371df8a2f9e45d9d5a97d2ea07179103f0a809265ae90bb",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0010",
    "providerId": "cohere",
    "techniqueId": "tech-input-classification",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic input content classification with dual safety modes (strict/contextual)",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "3afcafd8def1ad0ce0bf983a23420960605aeea6f100372ebe8a1a267b3de123",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0011",
    "providerId": "cohere",
    "techniqueId": "tech-output-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Output filtering through dual safety modes with enterprise logging capabilities",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "3afcafd8def1ad0ce0bf983a23420960605aeea6f100372ebe8a1a267b3de123",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0012",
    "providerId": "cohere",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic prompt injection protection through safety mode filtering",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "3afcafd8def1ad0ce0bf983a23420960605aeea6f100372ebe8a1a267b3de123",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0013",
    "providerId": "cohere",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited real-time monitoring capabilities through safety mode enforcement",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "3afcafd8def1ad0ce0bf983a23420960605aeea6f100372ebe8a1a267b3de123",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0014",
    "providerId": "cohere",
    "techniqueId": "tech-contextual-safety",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Contextual safety assessment through CONTEXTUAL safety mode allowing nuanced moderation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "3afcafd8def1ad0ce0bf983a23420960605aeea6f100372ebe8a1a267b3de123",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0015",
    "providerId": "cohere",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic multi-stage pipeline with dual safety modes and enterprise integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "3afcafd8def1ad0ce0bf983a23420960605aeea6f100372ebe8a1a267b3de123",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0016",
    "providerId": "cohere",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Configurable safety policies through STRICT and CONTEXTUAL mode selection",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "3afcafd8def1ad0ce0bf983a23420960605aeea6f100372ebe8a1a267b3de123",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0017",
    "providerId": "cohere",
    "techniqueId": "tech-audit-logging",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise audit logging for disallowed prompts and safety mode enforcement",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "3afcafd8def1ad0ce0bf983a23420960605aeea6f100372ebe8a1a267b3de123",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0018",
    "providerId": "cohere",
    "techniqueId": "tech-enterprise-integration",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise security integration with on-premises deployment options",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cohere.com/enterprise",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0019",
    "providerId": "cohere",
    "techniqueId": "tech-sovereignty-options",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "On-premises deployment options for data sovereignty and enterprise control",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cohere.com/enterprise",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0020",
    "providerId": "cohere",
    "techniqueId": "tech-incident-reporting",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic incident reporting through enterprise support channels",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "3afcafd8def1ad0ce0bf983a23420960605aeea6f100372ebe8a1a267b3de123",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0021",
    "providerId": "cohere",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Usage monitoring and analytics for enterprise safety and compliance tracking",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "3afcafd8def1ad0ce0bf983a23420960605aeea6f100372ebe8a1a267b3de123",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0022",
    "providerId": "cohere",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise regulatory compliance frameworks with industry-specific requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cohere.com/enterprise",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0023",
    "providerId": "cohere",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited academic partnerships with focus on enterprise applications",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cohere.com/research",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "fe01c483bb6290abae52cf5267e011d0d23cc311b545b70325722abe0c28a348",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0024",
    "providerId": "cohere",
    "techniqueId": "tech-community-governance",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited community governance with enterprise customer feedback integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "3afcafd8def1ad0ce0bf983a23420960605aeea6f100372ebe8a1a267b3de123",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0025",
    "providerId": "cohere",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic safety documentation focused on safety modes and enterprise implementation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "3afcafd8def1ad0ce0bf983a23420960605aeea6f100372ebe8a1a267b3de123",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0026",
    "providerId": "cohere",
    "techniqueId": "tech-model-cards",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited model cards and technical specifications with enterprise focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "8d47e6182a26160cc3cc20b77acb27a597db44a04a2fec1fbe15924342c6bf7d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0027",
    "providerId": "cohere",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited safety research publications with focus on enterprise applications",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cohere.com/research",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "fe01c483bb6290abae52cf5267e011d0d23cc311b545b70325722abe0c28a348",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0028",
    "providerId": "cohere",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise policy and compliance documentation with safety mode implementation guides",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "3afcafd8def1ad0ce0bf983a23420960605aeea6f100372ebe8a1a267b3de123",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-mistral-0001",
    "providerId": "mistral",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Lightweight filtering with community-driven approach and European data focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "42e42303d707a87b264548da624f5c818f9a4422dfcb1e549d49f423518b79b5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0002",
    "providerId": "mistral",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "European AI sovereignty focus with EU regulatory compliance measures",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "42e42303d707a87b264548da624f5c818f9a4422dfcb1e549d49f423518b79b5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-mistral-0003",
    "providerId": "mistral",
    "techniqueId": "tech-rlhf",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Minimal RLHF implementation with community feedback integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "42e42303d707a87b264548da624f5c818f9a4422dfcb1e549d49f423518b79b5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0004",
    "providerId": "mistral",
    "techniqueId": "tech-community-feedback",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community feedback integration for model improvement and safety enhancement",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "42e42303d707a87b264548da624f5c818f9a4422dfcb1e549d49f423518b79b5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0005",
    "providerId": "mistral",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Domain-specific fine-tuning capabilities with European regulatory focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.mistral.ai/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "ad7583ca2eb5b9617f12f9ae9246128a5488fef2e5181126347bbfa273489c69",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-mistral-0006",
    "providerId": "mistral",
    "techniqueId": "tech-input-classification",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Moderation API for input content classification with lightweight approach",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "42e42303d707a87b264548da624f5c818f9a4422dfcb1e549d49f423518b79b5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0007",
    "providerId": "mistral",
    "techniqueId": "tech-output-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Content classification and filtering through Moderation API",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "42e42303d707a87b264548da624f5c818f9a4422dfcb1e549d49f423518b79b5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0008",
    "providerId": "mistral",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic prompt injection protection through content classification",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "42e42303d707a87b264548da624f5c818f9a4422dfcb1e549d49f423518b79b5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0009",
    "providerId": "mistral",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Lightweight safety pipeline with moderation API and content classification",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "42e42303d707a87b264548da624f5c818f9a4422dfcb1e549d49f423518b79b5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0010",
    "providerId": "mistral",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic configurable policies through moderation API categories",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "42e42303d707a87b264548da624f5c818f9a4422dfcb1e549d49f423518b79b5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0011",
    "providerId": "mistral",
    "techniqueId": "tech-community-governance",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community governance model with European AI sovereignty principles",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "42e42303d707a87b264548da624f5c818f9a4422dfcb1e549d49f423518b79b5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0012",
    "providerId": "mistral",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "EU-focused regulatory compliance with European AI sovereignty emphasis",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "42e42303d707a87b264548da624f5c818f9a4422dfcb1e549d49f423518b79b5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-mistral-0013",
    "providerId": "mistral",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited academic partnerships with European research institutions",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/research",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0014",
    "providerId": "mistral",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic safety documentation with moderation API specifications",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "42e42303d707a87b264548da624f5c818f9a4422dfcb1e549d49f423518b79b5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0015",
    "providerId": "mistral",
    "techniqueId": "tech-model-cards",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited model cards and technical documentation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.mistral.ai/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "ad7583ca2eb5b9617f12f9ae9246128a5488fef2e5181126347bbfa273489c69",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0016",
    "providerId": "mistral",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Minimal safety research publications with focus on efficiency",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/research",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0017",
    "providerId": "mistral",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic policy documentation with EU regulatory compliance focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-07-10",
        "sourceHash": "42e42303d707a87b264548da624f5c818f9a4422dfcb1e549d49f423518b79b5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-stability-ai-0001",
    "providerId": "stability-ai",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited content filtering with community reports and post-hoc safety additions",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://stability.ai/safety",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "db514ea99c651453e4d5239d49b869fd178e450e0c9ea5779566d52d998e5210",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-stability-ai-0002",
    "providerId": "stability-ai",
    "techniqueId": "tech-community-feedback",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community feedback integration for safety improvement and content policy development",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://stability.ai/safety",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "db514ea99c651453e4d5239d49b869fd178e450e0c9ea5779566d52d998e5210",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-stability-ai-0003",
    "providerId": "stability-ai",
    "techniqueId": "tech-input-classification",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic NSFW filters and community moderation tools for input content",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://stability.ai/safety",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "db514ea99c651453e4d5239d49b869fd178e450e0c9ea5779566d52d998e5210",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-stability-ai-0004",
    "providerId": "stability-ai",
    "techniqueId": "tech-output-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic NSFW filters for generated content with community moderation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://stability.ai/safety",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "db514ea99c651453e4d5239d49b869fd178e450e0c9ea5779566d52d998e5210",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-stability-ai-0005",
    "providerId": "stability-ai",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic safety pipeline with NSFW filtering and community moderation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://stability.ai/safety",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "db514ea99c651453e4d5239d49b869fd178e450e0c9ea5779566d52d998e5210",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-stability-ai-0006",
    "providerId": "stability-ai",
    "techniqueId": "tech-community-governance",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community governance model with open-source image generation focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://stability.ai/safety",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "db514ea99c651453e4d5239d49b869fd178e450e0c9ea5779566d52d998e5210",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-stability-ai-0007",
    "providerId": "stability-ai",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Academic partnerships for image generation research and safety evaluation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://stability.ai/research",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "c1f73caecefc76662ba7337428789ec1ce1cd25ec4fb9d16d21fa2a7cda226ad",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-stability-ai-0008",
    "providerId": "stability-ai",
    "techniqueId": "tech-model-cards",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic model cards for image generation models with safety considerations",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://stability.ai/safety",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "db514ea99c651453e4d5239d49b869fd178e450e0c9ea5779566d52d998e5210",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-stability-ai-0009",
    "providerId": "stability-ai",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited safety research with focus on image generation and community-driven development",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://stability.ai/research",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "c1f73caecefc76662ba7337428789ec1ce1cd25ec4fb9d16d21fa2a7cda226ad",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-hugging-face-0001",
    "providerId": "hugging-face",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Platform-level content policies with model scanning and community-driven filtering",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://huggingface.co/docs/hub/security",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "36a41741954adc4b17ddd0b2bccd0d89ea8a58501a36c6d903fb413c55e7d285",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-hugging-face-0002",
    "providerId": "hugging-face",
    "techniqueId": "tech-csam-detection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic CSAM detection through platform-level content policies and community reporting",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://huggingface.co/docs/hub/security",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "36a41741954adc4b17ddd0b2bccd0d89ea8a58501a36c6d903fb413c55e7d285",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-hugging-face-0003",
    "providerId": "hugging-face",
    "techniqueId": "tech-copyright-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Copyright filtering through platform policies and community moderation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://huggingface.co/docs/hub/security",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "36a41741954adc4b17ddd0b2bccd0d89ea8a58501a36c6d903fb413c55e7d285",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-hugging-face-0004",
    "providerId": "hugging-face",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic PII protection through platform policies and model scanning",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://huggingface.co/docs/hub/security",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "36a41741954adc4b17ddd0b2bccd0d89ea8a58501a36c6d903fb413c55e7d285",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-hugging-face-0005",
    "providerId": "hugging-face",
    "techniqueId": "tech-community-feedback",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community feedback integration through platform governance and model reports",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://huggingface.co/docs/hub/community",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-hugging-face-0006",
    "providerId": "hugging-face",
    "techniqueId": "tech-input-classification",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Safety Checker API for content classification with model card requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://huggingface.co/docs/diffusers/conceptual/safety_checker",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "807a276e391cca651748a4757e32b553f86c76e929f637d440b7b7d2ef32fde0",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-hugging-face-0007",
    "providerId": "hugging-face",
    "techniqueId": "tech-output-filtering",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Output filtering through Safety Checker API and content warnings",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://huggingface.co/docs/diffusers/conceptual/safety_checker",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "807a276e391cca651748a4757e32b553f86c76e929f637d440b7b7d2ef32fde0",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-hugging-face-0008",
    "providerId": "hugging-face",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Platform-level monitoring with community reporting and automated scanning",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://huggingface.co/docs/hub/security",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "36a41741954adc4b17ddd0b2bccd0d89ea8a58501a36c6d903fb413c55e7d285",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-hugging-face-0009",
    "providerId": "hugging-face",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Platform safety pipeline with model scanning, content warnings, and community moderation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://huggingface.co/docs/hub/security",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "36a41741954adc4b17ddd0b2bccd0d89ea8a58501a36c6d903fb413c55e7d285",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-hugging-face-0010",
    "providerId": "hugging-face",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic PII detection through platform policies and model scanning capabilities",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://huggingface.co/docs/hub/security",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "36a41741954adc4b17ddd0b2bccd0d89ea8a58501a36c6d903fb413c55e7d285",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-hugging-face-0011",
    "providerId": "hugging-face",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Platform-level configurable policies with model card requirements and content warnings",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://huggingface.co/docs/hub/security",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "36a41741954adc4b17ddd0b2bccd0d89ea8a58501a36c6d903fb413c55e7d285",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-hugging-face-0012",
    "providerId": "hugging-face",
    "techniqueId": "tech-audit-logging",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic audit logging through platform analytics and community reporting",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://huggingface.co/docs/hub/security",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "36a41741954adc4b17ddd0b2bccd0d89ea8a58501a36c6d903fb413c55e7d285",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-hugging-face-0013",
    "providerId": "hugging-face",
    "techniqueId": "tech-opensource-tools",
    "modelIds": [],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive open source safety tooling ecosystem with community contributions",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://huggingface.co/docs/diffusers/conceptual/safety_checker",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "807a276e391cca651748a4757e32b553f86c76e929f637d440b7b7d2ef32fde0",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-hugging-face-0014",
    "providerId": "hugging-face",
    "techniqueId": "tech-community-governance",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community governance with platform governance and collaborative safety development",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://huggingface.co/docs/hub/community",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-hugging-face-0015",
    "providerId": "hugging-face",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Academic collaborations for safety research and platform development",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://huggingface.co/research",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "97775f820a91aec1b1aa7deb882588704d9e90f7afe4fd4d27edb1d0f6bddebc",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-hugging-face-0016",
    "providerId": "hugging-face",
    "techniqueId": "tech-model-cards",
    "modelIds": [],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Extensive model cards and technical specifications with safety information requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://huggingface.co/docs/hub/model-cards",
        "documentType": "system-card",
        "lastVerified": "2025-07-10",
        "sourceHash": "1eb44738206e2adc917c27008d78426d3d04c54477ce8d49a9b67039aaad4a85",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-hugging-face-0017",
    "providerId": "hugging-face",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited safety research publications with focus on platform governance",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://huggingface.co/research",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "97775f820a91aec1b1aa7deb882588704d9e90f7afe4fd4d27edb1d0f6bddebc",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-hugging-face-0018",
    "providerId": "hugging-face",
    "techniqueId": "tech-community-evaluation",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community evaluation frameworks with collaborative safety assessment tools",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://huggingface.co/docs/hub/community",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-baidu-0001",
    "providerId": "baidu",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Chinese regulatory compliance with government-approved content filtering",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "7918a2c220206c72635563f8d7033ee68bf7f298d5773977a9d52c8069ad6ffb",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0002",
    "providerId": "baidu",
    "techniqueId": "tech-csam-detection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "CSAM detection in compliance with Chinese internet regulations",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "7918a2c220206c72635563f8d7033ee68bf7f298d5773977a9d52c8069ad6ffb",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0003",
    "providerId": "baidu",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive Chinese regulatory compliance with government oversight integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "7918a2c220206c72635563f8d7033ee68bf7f298d5773977a9d52c8069ad6ffb",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-baidu-0004",
    "providerId": "baidu",
    "techniqueId": "tech-rlhf",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "RLHF with alignment to Chinese values and regulatory requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "7918a2c220206c72635563f8d7033ee68bf7f298d5773977a9d52c8069ad6ffb",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0005",
    "providerId": "baidu",
    "techniqueId": "tech-input-classification",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Real-time censorship and political content filtering for input classification",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "7918a2c220206c72635563f8d7033ee68bf7f298d5773977a9d52c8069ad6ffb",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0006",
    "providerId": "baidu",
    "techniqueId": "tech-output-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Political content filtering and real-time censorship for output content",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "7918a2c220206c72635563f8d7033ee68bf7f298d5773977a9d52c8069ad6ffb",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0007",
    "providerId": "baidu",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic prompt injection protection through content filtering and government oversight",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "7918a2c220206c72635563f8d7033ee68bf7f298d5773977a9d52c8069ad6ffb",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0008",
    "providerId": "baidu",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Real-time monitoring with government oversight and regulatory compliance",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "7918a2c220206c72635563f8d7033ee68bf7f298d5773977a9d52c8069ad6ffb",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0009",
    "providerId": "baidu",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Multi-stage pipeline with government oversight and political content filtering",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "7918a2c220206c72635563f8d7033ee68bf7f298d5773977a9d52c8069ad6ffb",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0010",
    "providerId": "baidu",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Government-configured safety policies with Chinese regulatory compliance",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "7918a2c220206c72635563f8d7033ee68bf7f298d5773977a9d52c8069ad6ffb",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0011",
    "providerId": "baidu",
    "techniqueId": "tech-audit-logging",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Government audit logging and compliance tracking for regulatory oversight",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "7918a2c220206c72635563f8d7033ee68bf7f298d5773977a9d52c8069ad6ffb",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0012",
    "providerId": "baidu",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Direct government oversight and regulatory compliance with Chinese authorities",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "7918a2c220206c72635563f8d7033ee68bf7f298d5773977a9d52c8069ad6ffb",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-baidu-0013",
    "providerId": "baidu",
    "techniqueId": "tech-incident-reporting",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Government incident reporting with regulatory compliance tracking",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "7918a2c220206c72635563f8d7033ee68bf7f298d5773977a9d52c8069ad6ffb",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0014",
    "providerId": "baidu",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Usage monitoring with government oversight and regulatory compliance",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "7918a2c220206c72635563f8d7033ee68bf7f298d5773977a9d52c8069ad6ffb",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0015",
    "providerId": "baidu",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive Chinese regulatory compliance with government framework integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "7918a2c220206c72635563f8d7033ee68bf7f298d5773977a9d52c8069ad6ffb",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-baidu-0016",
    "providerId": "baidu",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited academic partnerships with Chinese research institutions",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "7918a2c220206c72635563f8d7033ee68bf7f298d5773977a9d52c8069ad6ffb",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0017",
    "providerId": "baidu",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited international transparency with Chinese regulatory documentation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "7918a2c220206c72635563f8d7033ee68bf7f298d5773977a9d52c8069ad6ffb",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0018",
    "providerId": "baidu",
    "techniqueId": "tech-model-cards",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic model cards with Chinese regulatory compliance information",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "7918a2c220206c72635563f8d7033ee68bf7f298d5773977a9d52c8069ad6ffb",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0019",
    "providerId": "baidu",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited international safety research publications with regulatory focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://research.baidu.com/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0129a6649f7b95098cc2b812c5293740889775136b8738106035d05363431f8d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0020",
    "providerId": "baidu",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Chinese regulatory documentation with limited international transparency",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "7918a2c220206c72635563f8d7033ee68bf7f298d5773977a9d52c8069ad6ffb",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0001",
    "providerId": "alibaba",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Commercial focus with regulatory compliance and business-oriented filtering",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "854665679f57dbb57361179cf88ab5483eb6b3ba86a78cb28799fa3591650682",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0002",
    "providerId": "alibaba",
    "techniqueId": "tech-csam-detection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "CSAM detection for Chinese regulatory compliance and commercial deployment",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "16edbf5f23f6c7a2275be9c690adc3416d7326b28a034e0fe64cb309fee16bd7",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0003",
    "providerId": "alibaba",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Chinese regulatory compliance with commercial focus and efficiency optimization",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "331ba2cd11c07e1bc626e9e15bcbac40264e9cd966534b93edfb5eda2019e65a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0004",
    "providerId": "alibaba",
    "techniqueId": "tech-rlhf",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Business-oriented RLHF with efficiency focus and commercial optimization",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "22afc15d9fafb8a668c3e0673568d405f7a32593789492fa243da7955de47495",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0005",
    "providerId": "alibaba",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Domain-specific fine-tuning for business process automation and commercial safety",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "d478ecd3a090e8f44e3d018caf1ff04b79bf02f3e0824c3b0c6b5ff9b0e8af61",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0006",
    "providerId": "alibaba",
    "techniqueId": "tech-input-classification",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise content filtering with customer customization for business use cases",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "1265ac8cbedbbc56fee64e7618deae893574d144d263cf964884a09d14e3e8ea",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0007",
    "providerId": "alibaba",
    "techniqueId": "tech-output-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Customer-customizable output filtering for enterprise and commercial applications",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "ff7fe1c16dbf30c35f63fcb4381090b2e9fe687c788cc234be31262b7aaad4e4",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0008",
    "providerId": "alibaba",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic prompt injection protection through enterprise content filtering",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "a32a328fcb499443713d694111bda315eacc22d8c61ec720423a453089d6c415",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0009",
    "providerId": "alibaba",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Real-time monitoring for commercial applications with business process integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "711b60a31bf665f6d5acf0dd23f6388523840a2c30f2c1d6a54a2d294ce17684",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0010",
    "providerId": "alibaba",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Multi-stage pipeline with cloud integration and business process automation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "37606db17dc2f14b03dc5eb2a77529e373c22fd89cec66faa6bc1ab3a1ce8f32",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0011",
    "providerId": "alibaba",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic PII detection for enterprise data protection and commercial compliance",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "c3e1b400fa558ef3c3d27e479bd6b583c623ab96b73af468e7be38bf5ff1cdfc",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0012",
    "providerId": "alibaba",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Customer-configurable safety policies for enterprise deployment and business needs",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "79633a56a36b1362cfd811f3994b4485c54aea6eee855e474defaae50e1669ae",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0013",
    "providerId": "alibaba",
    "techniqueId": "tech-audit-logging",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise audit logging for business compliance and commercial accountability",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "5644c1c434f176f7f2a2f7a36f55b5097e354cd9b5afb150be55e00cabe66075",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0014",
    "providerId": "alibaba",
    "techniqueId": "tech-enterprise-integration",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Cloud integration with Alibaba Cloud security and business process automation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "92226400959d0ef437b78e7d60de58e9d4b4d6c9d20e6f0dacd0cc7e5d4f3565",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0015",
    "providerId": "alibaba",
    "techniqueId": "tech-sovereignty-options",
    "modelIds": [],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Data sovereignty options through Alibaba Cloud with regional deployment flexibility",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "bdd79b4bb74440697b28d2da1d5d6a4b2511bad1263b2a4019b32b1d6f93c8b8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-alibaba-0016",
    "providerId": "alibaba",
    "techniqueId": "tech-incident-reporting",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic incident reporting through enterprise support and commercial channels",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "9058d2718604bf728e00ccf222a3e36483dfaec7127fc025ed4e2d9c54d0677e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0017",
    "providerId": "alibaba",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise usage monitoring with business analytics and commercial optimization",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "fae6b0410d53a09105bcb6208bcdfc6c893ef846b0104fc7ef6388aa18936c6a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0018",
    "providerId": "alibaba",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Chinese regulatory compliance frameworks with commercial focus and enterprise requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "c0afd0b591a66c6df9bddbc3c5f72c9ad76abbf3b01e528dedd018bb9a95b52a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0019",
    "providerId": "alibaba",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Business documentation with limited research disclosure and commercial focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "bf9ef2e93dcc9773f64e329cd8f9603718e17a67c4eea9afd906f2ee8e22adab",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0020",
    "providerId": "alibaba",
    "techniqueId": "tech-model-cards",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic model cards with commercial specifications and business application focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "112dc132169dce8df524e03884f7cd25d1cad5e758c77795136789b13d77e197",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0021",
    "providerId": "alibaba",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Business policy documentation with enterprise compliance and commercial requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "400036d35fac0016d9f602bb27990e653581c6af216f95ef08552c08ca05718d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-x-constitutional-ai-001",
    "providerId": "x",
    "techniqueId": "tech-constitutional-ai",
    "modelIds": [
      "model-grok-4"
    ],
    "summary": "Constitutional AI training methodology implemented in Grok-4 to align model behavior with human values and safety principles",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.ai/news/grok-4",
        "documentType": "blog-post",
        "relevantSection": "Training and Safety",
        "lastVerified": "2025-07-24",
        "sourceHash": "c6d3e7bfa462aef2201bdff29ed7472fefb66eed1a8478ae51f05b63a54e3de3"
      }
    ],
    "knownLimitations": [
      "Limited public details on specific constitutional principles",
      "No published effectiveness metrics"
    ],
    "notes": "Grok-4 implements constitutional AI for value alignment",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-realtime-fact-check-002",
    "providerId": "x",
    "techniqueId": "tech-realtime-fact-checking",
    "modelIds": [
      "model-grok-4"
    ],
    "summary": "Integration with X platform's real-time information feed to fact-check claims and provide current information verification",
    "rating": "medium-high",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.ai/news/grok-4",
        "documentType": "blog-post",
        "relevantSection": "Real-time Information Access",
        "lastVerified": "2025-07-24",
        "sourceHash": "c6d3e7bfa462aef2201bdff29ed7472fefb66eed1a8478ae51f05b63a54e3de3"
      }
    ],
    "knownLimitations": [
      "Dependent on X platform data quality",
      "May amplify trending misinformation"
    ],
    "notes": "Unique capability leveraging X's real-time data stream",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "premium-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-platform-context-003",
    "providerId": "x",
    "techniqueId": "tech-contextual-safety",
    "modelIds": [
      "model-grok-4"
    ],
    "summary": "Safety measures that consider broader X platform context, user interaction history, and social graph for contextual risk assessment",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.com/privacy",
        "documentType": "privacy-policy",
        "relevantSection": "Data Usage for AI Services",
        "lastVerified": "2025-07-24",
        "sourceHash": "513d7ecde9321768275d88c28293cb49b3a69e6921c0015a4ad3d760d9b3c513"
      }
    ],
    "knownLimitations": [
      "Privacy implications of using social context",
      "Potential for social bias amplification"
    ],
    "notes": "Leverages X platform social context for safety",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-multimodal-safety-004",
    "providerId": "x",
    "techniqueId": "tech-multimodal-safety-alignment",
    "modelIds": [
      "model-grok-4"
    ],
    "summary": "Cross-modal safety alignment for Grok-4's multimodal capabilities, ensuring safety across text, image, and audio interactions",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.ai/news/grok-4",
        "documentType": "blog-post",
        "relevantSection": "Multimodal Capabilities",
        "lastVerified": "2025-07-24",
        "sourceHash": "c6d3e7bfa462aef2201bdff29ed7472fefb66eed1a8478ae51f05b63a54e3de3"
      }
    ],
    "knownLimitations": [
      "Cross-modal safety interactions are complex",
      "Limited multimodal safety evaluation data"
    ],
    "notes": "Addresses safety across multiple modalities in Grok-4",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-input-classification-005",
    "providerId": "x",
    "techniqueId": "tech-input-classification",
    "modelIds": [
      "model-grok-4"
    ],
    "summary": "Pre-processing classification of user inputs to identify potential safety risks before processing by Grok-4",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://help.x.com/en/rules-and-policies",
        "documentType": "policy-documentation",
        "relevantSection": "Content Moderation",
        "lastVerified": "2025-07-24",
        "sourceHash": "b737b99b7dde781f17abe0db3c6129d63edce718f07dad841b9e15ffd47fef2a"
      }
    ],
    "knownLimitations": [
      "May block benign content",
      "Context-dependent risks challenging to detect"
    ],
    "notes": "Integrated with X platform content moderation",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-output-filtering-006",
    "providerId": "x",
    "techniqueId": "tech-output-filtering",
    "modelIds": [
      "model-grok-4"
    ],
    "summary": "Post-generation filtering of Grok-4 outputs for safety violations before presentation to users",
    "rating": "medium-high",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://help.x.com/en/rules-and-policies",
        "documentType": "policy-documentation",
        "relevantSection": "AI Content Guidelines",
        "lastVerified": "2025-07-24",
        "sourceHash": "b737b99b7dde781f17abe0db3c6129d63edce718f07dad841b9e15ffd47fef2a"
      }
    ],
    "knownLimitations": [
      "May alter intended meaning",
      "Can be overly restrictive"
    ],
    "notes": "Aligned with X platform community guidelines",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-realtime-monitoring-007",
    "providerId": "x",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "model-grok-4"
    ],
    "summary": "Continuous monitoring of Grok-4 interactions for safety violations and emerging risk patterns",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.com/tos",
        "documentType": "terms-of-service",
        "relevantSection": "Monitoring and Enforcement",
        "lastVerified": "2025-07-24",
        "sourceHash": "609d7b180f98578d6303a8b71961b90a8324ecc31e9d42c10f01b2df8930690c"
      }
    ],
    "knownLimitations": [
      "Latency impact on user experience",
      "May miss contextual nuances"
    ],
    "notes": "Integrated with X platform monitoring infrastructure",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-pii-detection-008",
    "providerId": "x",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "model-grok-4"
    ],
    "summary": "Real-time detection and redaction of personally identifiable information in Grok-4 interactions",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.com/privacy",
        "documentType": "privacy-policy",
        "relevantSection": "Personal Information Protection",
        "lastVerified": "2025-07-24",
        "sourceHash": "513d7ecde9321768275d88c28293cb49b3a69e6921c0015a4ad3d760d9b3c513"
      }
    ],
    "knownLimitations": [
      "Context-dependent PII challenging to detect",
      "May miss novel PII patterns"
    ],
    "notes": "Complies with X platform privacy standards",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "GDPR",
      "CCPA"
    ],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-training-filtering-009",
    "providerId": "x",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [
      "model-grok-4"
    ],
    "summary": "Systematic filtering of training data for Grok-4 to remove harmful, biased, or inappropriate content",
    "rating": "medium-low",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.ai/news/grok-4",
        "documentType": "blog-post",
        "relevantSection": "Data and Training",
        "lastVerified": "2025-07-24",
        "sourceHash": "c6d3e7bfa462aef2201bdff29ed7472fefb66eed1a8478ae51f05b63a54e3de3"
      }
    ],
    "knownLimitations": [
      "Limited transparency on filtering criteria",
      "May introduce demographic biases"
    ],
    "notes": "Standard pre-training data curation practices",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-audit-logging-010",
    "providerId": "x",
    "techniqueId": "tech-audit-logging",
    "modelIds": [
      "model-grok-4"
    ],
    "summary": "Comprehensive logging of Grok-4 safety-relevant events and decisions for audit and improvement purposes",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.com/tos",
        "documentType": "terms-of-service",
        "relevantSection": "Data Retention and Logging",
        "lastVerified": "2025-07-24",
        "sourceHash": "609d7b180f98578d6303a8b71961b90a8324ecc31e9d42c10f01b2df8930690c"
      }
    ],
    "knownLimitations": [
      "Storage and privacy considerations",
      "Log completeness not specified"
    ],
    "notes": "Supports X platform compliance requirements",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "SOC2"
    ],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  }
]