[
  {
    "providerId": "anthropic",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Constitutional training data with filtered corpora designed to reduce harmful content and improve model alignment",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "policy",
        "lastVerified": "2025-10-31",
        "sourceHash": "ed8696308562ffccd4915156623309b52a370f9e9e48ba986f71065bd375962f",
        "relevantSection": "Safety and Security Standards"
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Specific filtering methods not detailed"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Part of Constitutional AI framework",
    "id": "ev-anthropic-0002"
  },
  {
    "providerId": "anthropic",
    "techniqueId": "tech-constitutional-ai",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Self-critique training using constitutional principles for helpful, harmless, honest behavior with scalable oversight",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2212.08073",
        "documentType": "research-paper",
        "lastVerified": "2025-10-31",
        "sourceHash": "9a456a07ad346e3372f9867d346f69f5b0f68b4c65f060aca0b8a13fa9d98e83",
        "relevantSection": "Section 3: Constitutional AI"
      }
    ],
    "implementationDate": "2022-12-15",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "evaluationMetrics": [
      {
        "metric": "human_preference_rate",
        "value": 76,
        "unit": "percent",
        "benchmarkContext": {
          "name": "Constitutional AI Eval",
          "version": "v1",
          "url": "https://arxiv.org/abs/2212.08073"
        }
      }
    ],
    "knownLimitations": [
      "May be overly conservative",
      "Principles require careful design"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Core safety innovation from Anthropic",
    "id": "ev-anthropic-0003"
  },
  {
    "providerId": "anthropic",
    "techniqueId": "tech-rlhf",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Constitutional AI approach combining self-critique with RLHF for scalable oversight and preference learning",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2212.08073",
        "documentType": "research-paper",
        "lastVerified": "2025-10-31",
        "sourceHash": "9a456a07ad346e3372f9867d346f69f5b0f68b4c65f060aca0b8a13fa9d98e83",
        "relevantSection": "Section 4: Training Process"
      }
    ],
    "implementationDate": "2022-12-15",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Subject to annotator biases",
      "Computationally expensive"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Combined with Constitutional AI for enhanced safety",
    "id": "ev-anthropic-0004"
  },
  {
    "providerId": "google",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Multi-lingual safety filtering and bias detection in training data preparation for Gemini models",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": "Training Data Safety"
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Specific methods not detailed"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "EU AI Act"
    ],
    "notes": "Focus on multilingual safety",
    "id": "ev-google-0005"
  },
  {
    "providerId": "google",
    "techniqueId": "tech-rlhf",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "B",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "RLHF with adversarial safety tuning datasets and Sparrow-style critiquing methodology",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2209.14375",
        "documentType": "research-paper",
        "lastVerified": "2025-10-31",
        "sourceHash": "e7df8fc1e41dfc3b47a781958fc53e6467f3b0ba3b0c10db5040f7924097709a",
        "relevantSection": "Section 3: Training Sparrow"
      }
    ],
    "implementationDate": "2022-09-29",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Limited to English initially"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Based on Sparrow research",
    "id": "ev-google-0006"
  },
  {
    "providerId": "meta",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Open training with safety benchmarks and Llama Guard integration for content filtering",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-10-31",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": "Section 4: Safety"
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Community-dependent verification"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Open source approach enables community verification",
    "id": "ev-meta-0007"
  },
  {
    "providerId": "meta",
    "techniqueId": "tech-rlhf",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Two-phase RLHF with community-driven safety feedback and open source evaluation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-10-31",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": "Section 3.3: Fine-tuning"
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Resource intensive",
      "Community feedback quality varies"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Two-phase approach with safety-specific rewards",
    "id": "ev-meta-0008"
  },
  {
    "providerId": "meta",
    "techniqueId": "tech-input-classification",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Llama Guard as separate safety classifier for input content with open source implementation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "research-paper",
        "lastVerified": "2025-10-31",
        "sourceHash": "1bb96ca85616724ca6c2ef3ee779ca0b15f894c3e0983babe1745d817bf6f9d7",
        "relevantSection": "Section 2: Llama Guard"
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Requires separate model inference"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Open source safety classifier",
    "id": "ev-meta-0009"
  },
  {
    "providerId": "amazon",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "B",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Advanced PII detection and redaction through Bedrock Guardrails with enterprise-grade protection",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails-sensitive-filters.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "8a8472e6da3e6f22c214f4a5c5806981dd9f9b8bfa43c2c8e6a8979f2bb07220",
        "relevantSection": "Sensitive Information Filters"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Language support varies",
      "Context-dependent PII challenging"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "HIPAA",
      "PCI-DSS"
    ],
    "notes": "Enterprise-grade PII protection",
    "id": "ev-amazon-0010"
  },
  {
    "providerId": "amazon",
    "techniqueId": "tech-input-classification",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Bedrock Guardrails input classification with customizable policies and enterprise integration",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": "Content Filters"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Requires configuration",
      "May have false positives"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Highly configurable for enterprise needs",
    "id": "ev-amazon-0011"
  },
  {
    "providerId": "amazon",
    "techniqueId": "tech-output-filtering",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Bedrock Guardrails output filtering with hallucination detection and content policy enforcement",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": "Output Moderation"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "May alter outputs",
      "Hallucination detection has limits"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Includes hallucination detection",
    "id": "ev-amazon-0012"
  },
  {
    "providerId": "anthropic",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "External red team engagement as part of responsible scaling policy and AI Safety Level assessments",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "policy",
        "lastVerified": "2025-10-31",
        "sourceHash": "d739190f25df6a5b8566b5dcc0e9ab5f8fb208fa582df6518cbed545eaf8ec3b",
        "relevantSection": "AI Safety Levels"
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Specific findings not always public"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Part of ASL framework",
    "id": "ev-anthropic-0013"
  },
  {
    "providerId": "anthropic",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Responsible scaling policy and constitutional AI research provide comprehensive safety framework documentation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "policy",
        "lastVerified": "2025-10-31",
        "sourceHash": "80f335540745b5207d53f260f0085a845e1b7c3753248f0f716be55b9148c546",
        "relevantSection": "Full Document"
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P12M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Industry-leading transparency",
    "id": "ev-anthropic-0014"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-csam-detection",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Automated detection and removal of child sexual abuse material using specialized classifiers during pre-training data preparation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://openai.com/policies/usage-policies",
        "documentType": "policy",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "Prohibited Usage"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Detection rates not disclosed"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "NCMEC"
    ],
    "notes": "Part of comprehensive content filtering",
    "id": "ev-openai-0003"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-copyright-filtering",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Fingerprinting system to remove opted-out images from training data, building on DALL-E 3 opt-out mechanism",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-31",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Section 2.1"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Only for opted-out content"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "DMCA"
    ],
    "notes": "Extends DALL-E 3 opt-out system",
    "id": "ev-openai-0004"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-bias-detection-training",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Advanced data filtering processes to reduce biased content, though specific bias detection methods not fully detailed",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-31",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Safety Evaluations"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Specific methods not disclosed"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0005"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Advanced data filtering processes to reduce personal information from training data using automated detection systems",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-31",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Data Processing"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Cannot catch all PII"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "GDPR",
      "CCPA"
    ],
    "notes": "",
    "id": "ev-openai-0006"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-adversarial-training",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Red team data integration and adversarial testing during training, though specific methods not detailed",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-31",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Red Teaming"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Methods not fully disclosed"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0007"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-red-team-data",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "100+ external red teamers across 45 languages and 29 countries, data integrated into training process",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-31",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "External Red Teaming"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Extensive red team network",
    "id": "ev-openai-0008"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-input-classification",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Layered policy engine with system prompt \u2192 model \u2192 content filter pipeline, including specialized voice classifiers",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-31",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Safety Pipeline"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Multi-layer approach",
    "id": "ev-openai-0009"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-output-filtering",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Multi-stage content filtering with moderation API applied to both text and audio outputs",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-31",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Output Moderation"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Includes audio moderation",
    "id": "ev-openai-0010"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "System prompt protections and multi-layer filtering, though specific prompt injection defenses not detailed",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-31",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Safety Mitigations"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Specific defenses not disclosed"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0011"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Real-time monitoring and enforcement with product-level mitigations including streaming audio analysis",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-31",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Real-time Voice"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Includes voice monitoring",
    "id": "ev-openai-0012"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-contextual-safety",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Context-aware safety evaluation, particularly for voice interactions, though implementation not detailed",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-31",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Voice Safety"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Implementation details limited"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0013"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Comprehensive safety pipeline spanning pre-training, post-training, product development, and policy enforcement",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-31",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Safety Architecture"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "End-to-end approach",
    "id": "ev-openai-0014"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "PII detection capabilities integrated into content filtering systems for personal information protection",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://openai.com/policies/usage-policies",
        "documentType": "policy",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "Privacy"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Details not specified"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "GDPR",
      "CCPA"
    ],
    "notes": "",
    "id": "ev-openai-0015"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Usage policies and moderation tools provided to users, with transparency reports and configurable settings",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://openai.com/policies/usage-policies",
        "documentType": "policy",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "Usage Policies"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Limited configurability"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0016"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-audit-logging",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Usage monitoring and incident reporting systems for tracking and analyzing safety incidents",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-31",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Monitoring"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "SOC2"
    ],
    "notes": "",
    "id": "ev-openai-0017"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Preparedness Framework with pre-defined capability thresholds and deployment decisions based on risk assessments",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/openai-preparedness-framework-beta.pdf",
        "documentType": "policy",
        "lastVerified": "2025-10-31",
        "sourceHash": "c84e3a59c7dab251e45434e0b0d3e8abadcea7293f995cf92d32269e7d290398",
        "relevantSection": "Full Document"
      }
    ],
    "implementationDate": "2023-10-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Industry-leading framework",
    "id": "ev-openai-0018"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-safety-advisory",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Safety Advisory Group providing independent oversight and recommendations on deployment decisions",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-31",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Governance"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P12M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0019"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-incident-reporting",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": true
    },
    "summary": "Systematic incident reporting and analysis with internal tracking and external disclosure mechanisms",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-31",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Incident Response"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0020"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": true
    },
    "summary": "Comprehensive usage monitoring with analytics for detecting patterns of misuse and safety incidents",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-31",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Usage Analytics"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0021"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Compliance with voluntary White House commitments and development of internal governance frameworks",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://openai.com/index/our-approach-to-ai-safety",
        "documentType": "blog-post",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "Commitments"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "White House Commitments"
    ],
    "notes": "",
    "id": "ev-openai-0022"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Collaboration with academic institutions and independent research organizations for safety evaluation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-31",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "External Collaboration"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P12M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0023"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-model-cards",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Technical documentation including model architecture, training methodology, and safety evaluation results",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-31",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Full Document"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P12M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Comprehensive system card",
    "id": "ev-openai-0024"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Regular publication of safety research, evaluation methodologies, and lessons learned from deployment",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://openai.com/research",
        "documentType": "research-paper",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "Safety Research"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P12M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0025"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Comprehensive usage policies, terms of service, and compliance documentation publicly available",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://openai.com/policies",
        "documentType": "policy",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "All Policies"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0026"
  },
  {
    "providerId": "google",
    "techniqueId": "tech-watermarking",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": true
    },
    "summary": "SynthID watermarking technology for AI-generated image and audio content identification",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/science/synthid/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "6d067c776240a1988fac53b0f0198d094af15770d674ec119bd4a28bf2f07230",
        "relevantSection": "Technology Overview"
      }
    ],
    "implementationDate": "2023-08-29",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Limited to certain content types"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Industry-leading watermarking",
    "id": "ev-google-0003"
  },
  {
    "providerId": "google",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "EU AI Act compliance measures with transparency registers and regulatory reporting mechanisms",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://blog.google/technology/ai/google-ai-act-preparation/",
        "documentType": "blog-post",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "Compliance Measures"
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "EU AI Act"
    ],
    "notes": "Proactive compliance",
    "id": "ev-google-0004"
  },
  {
    "providerId": "google",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Multi-stage safety layers including toxicity detection, policy checks, and SynthID watermarking",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": "Safety Architecture"
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-google-0005"
  },
  {
    "providerId": "google",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Academic partnerships for AI safety research and independent evaluation of safety measures",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/research/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "67cb4749a4251699d56f60bdda03b286d1f7a854a2f54f14a94a809c84fb3a85",
        "relevantSection": "Collaborations"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P12M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-google-0006"
  },
  {
    "providerId": "meta",
    "techniqueId": "tech-output-filtering",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Llama Guard output filtering with contextual moderation and open source validation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "research-paper",
        "lastVerified": "2025-10-31",
        "sourceHash": "ec4d42cc3c7d4ad550e31b8760d2ec633d89e1c46806cd9e28c376aaff5acb78",
        "relevantSection": "Output Moderation"
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Requires separate inference"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Open source implementation",
    "id": "ev-meta-0004"
  },
  {
    "providerId": "meta",
    "techniqueId": "tech-bias-detection-training",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "B",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Bias detection and mitigation with community-driven evaluation and open source validation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-10-31",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": "Section 5.2: Bias Evaluation"
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Community-dependent validation"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-meta-0005"
  },
  {
    "id": "ev-openai-0027",
    "providerId": "openai",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Systematic evaluation protocols for dangerous capabilities including cybersecurity, CBRN, persuasion, and autonomy",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-31",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-openai-0028",
    "providerId": "openai",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Systematic red team exercises across multiple phases with diverse expert networks and real-world testing scenarios",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-31",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-openai-0031",
    "providerId": "openai",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Detailed system cards providing comprehensive safety evaluations, methodologies, and results for each model release",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-31",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-anthropic-0005",
    "providerId": "anthropic",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Personal information filtering as part of constitutional training data preparation",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/claude-3-model-card",
        "documentType": "system-card",
        "lastVerified": "2025-10-31",
        "sourceHash": "88ae851f53c3034d436816164ce49a876b333fa9b550fb7ef29838182b59ba7d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-03-04",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0006",
    "providerId": "anthropic",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Compliance with emerging AI regulations and industry standards through responsible scaling policy",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "b3447b5c13953841005f5885ef3a0457ddfc8171b3bf2f7050973e03c1082d9a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0009",
    "providerId": "anthropic",
    "techniqueId": "tech-safety-reward-modeling",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Safety considerations integrated into reward modeling as part of constitutional AI framework",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2212.08073",
        "documentType": "research-paper",
        "lastVerified": "2025-10-31",
        "sourceHash": "9a456a07ad346e3372f9867d346f69f5b0f68b4c65f060aca0b8a13fa9d98e83",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2022-12-15",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0010",
    "providerId": "anthropic",
    "techniqueId": "tech-adversarial-training",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Adversarial testing integrated into constitutional AI training process for robustness",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2212.08073",
        "documentType": "research-paper",
        "lastVerified": "2025-10-31",
        "sourceHash": "9a456a07ad346e3372f9867d346f69f5b0f68b4c65f060aca0b8a13fa9d98e83",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2022-12-15",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBC"
  },
  {
    "id": "ev-anthropic-0011",
    "providerId": "anthropic",
    "techniqueId": "tech-red-team-data",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Red team exercises and data integration as part of responsible scaling policy and safety evaluation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "4b519cdf38181ebfd43e3fd427c1aff19e73fbcaedbae4ba767aafafdd283de7",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-anthropic-0012",
    "providerId": "anthropic",
    "techniqueId": "tech-input-classification",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Content classification systems for input filtering, though specific implementation details not public",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/claude-3-model-card",
        "documentType": "system-card",
        "lastVerified": "2025-10-31",
        "sourceHash": "88ae851f53c3034d436816164ce49a876b333fa9b550fb7ef29838182b59ba7d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-03-04",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0015",
    "providerId": "anthropic",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Safety monitoring systems in place, though specific real-time implementation details not disclosed",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/claude-3-model-card",
        "documentType": "system-card",
        "lastVerified": "2025-10-31",
        "sourceHash": "88ae851f53c3034d436816164ce49a876b333fa9b550fb7ef29838182b59ba7d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-03-04",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0016",
    "providerId": "anthropic",
    "techniqueId": "tech-contextual-safety",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Constitutional AI enables sophisticated contextual safety assessment through principle-based reasoning",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2212.08073",
        "documentType": "research-paper",
        "lastVerified": "2025-10-31",
        "sourceHash": "9a456a07ad346e3372f9867d346f69f5b0f68b4c65f060aca0b8a13fa9d98e83",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2022-12-15",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-anthropic-0017",
    "providerId": "anthropic",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive safety pipeline including constitutional training, RLHF, and responsible scaling evaluation",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "11648f3b44c2eff948204131953c4d79c26406a55eb44f7006ada6e34a90958b",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-anthropic-0018",
    "providerId": "anthropic",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "PII protection mechanisms integrated into constitutional AI framework",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/claude-3-model-card",
        "documentType": "system-card",
        "lastVerified": "2025-10-31",
        "sourceHash": "88ae851f53c3034d436816164ce49a876b333fa9b550fb7ef29838182b59ba7d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-03-04",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0019",
    "providerId": "anthropic",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Constitutional principles provide framework for configurable safety responses",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2212.08073",
        "documentType": "research-paper",
        "lastVerified": "2025-10-31",
        "sourceHash": "9a456a07ad346e3372f9867d346f69f5b0f68b4c65f060aca0b8a13fa9d98e83",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2022-12-15",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0020",
    "providerId": "anthropic",
    "techniqueId": "tech-audit-logging",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Audit and monitoring capabilities as part of responsible scaling policy framework",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "382b10d451ac96b89728011c7cc0cd0af1470d61ba71eeccd9999e771a298570",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0021",
    "providerId": "anthropic",
    "techniqueId": "tech-watermarking",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "B",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Research into watermarking techniques for AI-generated content detection and provenance",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "a6fd5bc31c58a76b39f2ddb273300ae0e4f017cbcf72b1a2c97a8e6335b6681b",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MRC"
  },
  {
    "id": "ev-anthropic-0023",
    "providerId": "anthropic",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "AI Safety Level (ASL) framework with clear classifications and deployment thresholds",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "66f482e8fa7a027e3c22a53478105d0df6402254e1c399c6877b785554f1cd98",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-anthropic-0024",
    "providerId": "anthropic",
    "techniqueId": "tech-safety-advisory",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Independent safety advisory structure as part of responsible scaling policy governance",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "6115876a3298dcac6a47eff3284f1375aefbd02208e957c9e9519f0c7e01f0a7",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-anthropic-0025",
    "providerId": "anthropic",
    "techniqueId": "tech-incident-reporting",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Incident reporting and analysis systems integrated into responsible scaling framework",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "d8c0e8350b21a7d4f3e6945321b8eeba77a2b16da2072534d476c94d8550ce60",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-anthropic-0026",
    "providerId": "anthropic",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Usage monitoring capabilities for safety assessment and responsible scaling decisions",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "27da254719b7fcb2bf8dcf9e2b2b71912e30968bd9774ea1a8c70a1e10d7f8f5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0027",
    "providerId": "anthropic",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Systematic capability evaluation protocols as part of ASL framework and responsible scaling",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "f139ff2a4e7c0b8be9800ff68122028c65200af955d5e776e7b5927e0df4559b",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-anthropic-0028",
    "providerId": "anthropic",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive red team exercises for capability assessment and safety evaluation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "ad2d3dc873a8b599101c8934cc554abd4b9b796b91c6a4bca5b5fa2b359fff93",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-anthropic-0029",
    "providerId": "anthropic",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Proactive regulatory compliance through responsible scaling policy and industry engagement",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "965aa1d1c2873e75d6fc600b593cce8a988ee3885a2e73e9d5e8689d35716bd7",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-anthropic-0030",
    "providerId": "anthropic",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Academic collaborations for safety research and constitutional AI development",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/research",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "dac9bcf7400b2ad139abccc1a61eaa8b219f558b0aeb13c49a81d0a71917a8e4",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-anthropic-0032",
    "providerId": "anthropic",
    "techniqueId": "tech-model-cards",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Model cards available for Claude models with technical specifications and safety information",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/claude-3-model-card",
        "documentType": "system-card",
        "lastVerified": "2025-10-31",
        "sourceHash": "88ae851f53c3034d436816164ce49a876b333fa9b550fb7ef29838182b59ba7d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-03-04",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-anthropic-0033",
    "providerId": "anthropic",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Extensive publication of constitutional AI research and safety methodologies",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/research",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "f55741f339578aa26a208dbdeb1573cec90dfc2d0a3559d977126f39734fb592",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-anthropic-0034",
    "providerId": "anthropic",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive policy documentation including responsible scaling policy and usage guidelines",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "308059505c5d68847cadb0efa7620eb7371eae0e96c23db3a548135dd32196c3",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-google-0002",
    "providerId": "google",
    "techniqueId": "tech-csam-detection",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "CSAM detection and removal systems implemented as part of standard content filtering pipeline",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0008",
    "providerId": "google",
    "techniqueId": "tech-constitutional-ai",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "B",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Research into constitutional AI principles and self-critique mechanisms for Gemini safety",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MRC"
  },
  {
    "id": "ev-google-0009",
    "providerId": "google",
    "techniqueId": "tech-safety-reward-modeling",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Safety considerations integrated into reward modeling for Gemini training optimization",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0010",
    "providerId": "google",
    "techniqueId": "tech-adversarial-training",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Adversarial safety tuning datasets used in RLHF process for robustness improvement",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2209.14375",
        "documentType": "research-paper",
        "lastVerified": "2025-10-31",
        "sourceHash": "e7df8fc1e41dfc3b47a781958fc53e6467f3b0ba3b0c10db5040f7924097709a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2022-09-29",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBC"
  },
  {
    "id": "ev-google-0011",
    "providerId": "google",
    "techniqueId": "tech-red-team-data",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Red team exercises and data integration for Gemini safety evaluation and improvement",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0012",
    "providerId": "google",
    "techniqueId": "tech-input-classification",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Multi-stage safety layer including toxicity and content classification for input processing",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0013",
    "providerId": "google",
    "techniqueId": "tech-output-filtering",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Output content filtering with toxicity classifiers and safety policy enforcement",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0014",
    "providerId": "google",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic prompt injection protection through input filtering and safety classifiers",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBC"
  },
  {
    "id": "ev-google-0015",
    "providerId": "google",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Real-time safety monitoring capabilities integrated into Gemini deployment infrastructure",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0016",
    "providerId": "google",
    "techniqueId": "tech-contextual-safety",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Contextual safety assessment capabilities, though specific implementation details not disclosed",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBC"
  },
  {
    "id": "ev-google-0018",
    "providerId": "google",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "PII detection and redaction capabilities integrated into safety pipeline",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0019",
    "providerId": "google",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Configurable safety policies and content filtering options for different deployment contexts",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0020",
    "providerId": "google",
    "techniqueId": "tech-audit-logging",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Audit logging capabilities for safety incident tracking and regulatory compliance",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://blog.google/technology/ai/google-ai-act-preparation/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0022",
    "providerId": "google",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "External red team engagement for Gemini safety evaluation and testing",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0023",
    "providerId": "google",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Internal safety classification system for model capabilities and deployment decisions",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0024",
    "providerId": "google",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Capability evaluation protocols for dangerous capabilities and safety assessment",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0025",
    "providerId": "google",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Red team exercises for capability discovery and safety evaluation across multiple domains",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0026",
    "providerId": "google",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive regulatory compliance frameworks including EU AI Act preparation and transparency measures",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://blog.google/technology/ai/google-ai-act-preparation/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-google-0028",
    "providerId": "google",
    "techniqueId": "tech-model-cards",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Model cards and technical documentation for Gemini models with safety information",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/gemini/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "41226294bd499fce8505758df12a8a3d3c26b5b8c329ba19034fb0b188f2d8e6",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-meta-0002",
    "providerId": "meta",
    "techniqueId": "tech-csam-detection",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "CSAM detection and removal processes integrated into training data preparation",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "b746711519bb46cc466aa5742a4dc0b29d56df69aff271d8d85626aa1dc208a6",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0003",
    "providerId": "meta",
    "techniqueId": "tech-copyright-filtering",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Copyright filtering mechanisms for training data with open source transparency",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-10-31",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0006",
    "providerId": "meta",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic regulatory compliance measures with limited international regulatory integration",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "90ddf625d46928d6b451b85b0ee1f68f51b0ebe2821e88a423db9caa6b60a708",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPC"
  },
  {
    "id": "ev-meta-0010",
    "providerId": "meta",
    "techniqueId": "tech-community-feedback",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community-driven safety feedback with open source evaluation harness and academic partnerships",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "979c71af348bc8f77fc51b66493fce8373be11b9711dc3bddc4bced5cd422965",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPV"
  },
  {
    "id": "ev-meta-0013",
    "providerId": "meta",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic prompt injection protection through Llama Guard classification and community testing",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "1fb45b129d5740400136f45d4f2438f3eec09eaf386222f3092fda453200a16a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBC"
  },
  {
    "id": "ev-meta-0014",
    "providerId": "meta",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Real-time safety monitoring capabilities through Llama Guard integration",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "1b69a2cdd9886fcafe176125f3ffca9ef6c63d6965484cce223ef8a5c5593b63",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0015",
    "providerId": "meta",
    "techniqueId": "tech-contextual-safety",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Contextual moderation capabilities through Llama Guard classification system",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "1b2bc684fb28351e9a26e67181fa6dfb570f825ec0d4490ad6e3b7c028be43b7",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBC"
  },
  {
    "id": "ev-meta-0016",
    "providerId": "meta",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Multi-stage safety pipeline with Llama Guard integration and community validation",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-10-31",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0017",
    "providerId": "meta",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "PII detection capabilities integrated into Llama Guard classification system",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "2aca1d65d43323b32cc1bf5779b53ab03cf4407097936e1cc5ba0f4b4a026245",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0018",
    "providerId": "meta",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Configurable safety policies through open source Llama Guard implementation",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "c69d1eee45a54de76e48b3aea5ecee6155545d8e3cf0718faac93f3932b06d10",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0019",
    "providerId": "meta",
    "techniqueId": "tech-audit-logging",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic audit logging capabilities with open source transparency and community oversight",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "ca4c9b123dfedc3d9c267b1426ce6a0bc05b7262ccbc54b77ccc34ab83735946",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0020",
    "providerId": "meta",
    "techniqueId": "tech-opensource-tools",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive open source safety tools including Llama Guard and evaluation frameworks",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://github.com/meta-llama",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "10eeb98958d75e4d7977ad8070b8d84378aea8b2586d910152a82c2b6218b48e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-meta-0021",
    "providerId": "meta",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community-driven red team networks with academic partnerships and open evaluation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-10-31",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBV"
  },
  {
    "id": "ev-meta-0022",
    "providerId": "meta",
    "techniqueId": "tech-responsible-release",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Responsible release checklist with community evaluation and academic partnership validation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "2590441a0855e6c8d901d6181c4bd5b9f7574e49566d42f85121e4eb23e1c58c",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-meta-0023",
    "providerId": "meta",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Extensive academic partnerships for safety evaluation and community-driven research",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "61c530f6ff6cc2c568ce5c2c771b506a00ea74a88ff4c58fd8fcce7609deb316",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-meta-0024",
    "providerId": "meta",
    "techniqueId": "tech-safety-benchmarks",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Open safety benchmarks and evaluation metrics with community validation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-10-31",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-meta-0025",
    "providerId": "meta",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community-driven capability evaluation protocols with open source validation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-10-31",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBV"
  },
  {
    "id": "ev-meta-0026",
    "providerId": "meta",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community-driven red team exercises with academic partnerships and open evaluation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-10-31",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBV"
  },
  {
    "id": "ev-meta-0027",
    "providerId": "meta",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic regulatory compliance frameworks with open source transparency",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "fa47886aedd1534e5f70aa4f8319d7668db4a505a7deb88181f710e4ec82e088",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0028",
    "providerId": "meta",
    "techniqueId": "tech-community-governance",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Community governance model with open source development and academic oversight",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "770d8cfc75948fd452d46c1bee4caf710e386360b0ab282ade1e11614de720ce",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-meta-0029",
    "providerId": "meta",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Open safety documentation with research papers and community evaluation results",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-10-31",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-meta-0030",
    "providerId": "meta",
    "techniqueId": "tech-model-cards",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Open model cards and technical specifications with community validation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "4358ac1e0afc34e782a2eafd0f6ad7ae414cc8d7e4b478bc17eef0bf4561b2fe",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-meta-0031",
    "providerId": "meta",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Extensive safety research publications with peer review and community validation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "617f59778cf6117c36524bd289c32f96548914c9609e1d10ea1e590d0f96b06a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-meta-0032",
    "providerId": "meta",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Open policy and compliance documentation with community feedback integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "72c9cc6e4be6d945fc815eb075665267873c4621d52a79f2fbb54b8ca0bcfc3b",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-meta-0033",
    "providerId": "meta",
    "techniqueId": "tech-community-evaluation",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Open community evaluation frameworks with academic partnerships and peer review",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "7149901a910b5e1842d759a930621ff113b336ef20c555f8bdd79391c308497a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0001",
    "providerId": "amazon",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [
      "titan-express"
    ],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise-focused training data curation with customer data isolation and basic filtering",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "9efac3b7025e270277bf5a83d228de2c4326c5ee8216f5180b5c243d3582a659",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-amazon-0002",
    "providerId": "amazon",
    "techniqueId": "tech-csam-detection",
    "modelIds": [
      "titan-express"
    ],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Standard CSAM detection integrated into Bedrock platform with enterprise compliance",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-amazon-0003",
    "providerId": "amazon",
    "techniqueId": "tech-copyright-filtering",
    "modelIds": [
      "titan-express"
    ],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic copyright filtering with enterprise compliance and customer-configurable policies",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-amazon-0004",
    "providerId": "amazon",
    "techniqueId": "tech-bias-detection-training",
    "modelIds": [
      "titan-express"
    ],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited bias detection capabilities with enterprise compliance focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-amazon-0006",
    "providerId": "amazon",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise regulatory compliance frameworks with industry-specific guardrails",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://aws.amazon.com/compliance/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "ea10363fb16cbd11af9d2804c5800191c550f5c67406d8a6c612c83aa850ab42",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0007",
    "providerId": "amazon",
    "techniqueId": "tech-rlhf",
    "modelIds": [
      "titan-express"
    ],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic RLHF with customer fine-tuning options and domain-specific safety optimization",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "9efac3b7025e270277bf5a83d228de2c4326c5ee8216f5180b5c243d3582a659",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-amazon-0008",
    "providerId": "amazon",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Customer fine-tuning options with domain-specific safety configurations and enterprise controls",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/custom-models.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "301087a714a78598071f99b28724305dd5e13615552c20cd0db8eebd52422e32",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0013",
    "providerId": "amazon",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Multi-stage safety pipeline with Bedrock Guardrails and AWS security integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0014",
    "providerId": "amazon",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "titan-express"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Advanced PII detection and redaction with enterprise-grade sensitive information filters",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails-sensitive-filters.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "8a8472e6da3e6f22c214f4a5c5806981dd9f9b8bfa43c2c8e6a8979f2bb07220",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0015",
    "providerId": "amazon",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [
      "titan-express"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Highly configurable safety policies through Bedrock Guardrails with customer customization",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0016",
    "providerId": "amazon",
    "techniqueId": "tech-audit-logging",
    "modelIds": [
      "titan-express"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive audit logging through AWS CloudTrail with enterprise compliance tracking",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/logging-monitoring.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "e287c7b44ce23e4a471bebf2532b8c016fe17840bd35f1c048360118f99a599e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0017",
    "providerId": "amazon",
    "techniqueId": "tech-enterprise-integration",
    "modelIds": [
      "titan-express"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Deep enterprise security integration with AWS IAM, VPC, and compliance frameworks",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/security.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "3e82ddd78f2de438f7b597e4418a6287c23eff16d0bb89d37d7138cf6c11c247",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0018",
    "providerId": "amazon",
    "techniqueId": "tech-sovereignty-options",
    "modelIds": [
      "titan-express"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Data sovereignty options with AWS regions and customer-controlled encryption keys",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://aws.amazon.com/compliance/data-privacy/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "3e4fb157c877a05a8e18ca0b729f4f3634f886e3a7efd8cb1eca2219cfeba369",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0019",
    "providerId": "amazon",
    "techniqueId": "tech-incident-reporting",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise incident reporting through AWS support and compliance frameworks",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/logging-monitoring.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "e287c7b44ce23e4a471bebf2532b8c016fe17840bd35f1c048360118f99a599e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0020",
    "providerId": "amazon",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "titan-express"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive usage monitoring through AWS CloudWatch with enterprise analytics",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/logging-monitoring.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "e287c7b44ce23e4a471bebf2532b8c016fe17840bd35f1c048360118f99a599e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0021",
    "providerId": "amazon",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise regulatory compliance with AWS compliance certifications and industry standards",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://aws.amazon.com/compliance/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "4750a3251ccf73ea0842b13d7b7fe538e627115246f3af513df85abcb0670285",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0022",
    "providerId": "amazon",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise-focused safety documentation with AWS service documentation and compliance guides",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0023",
    "providerId": "amazon",
    "techniqueId": "tech-model-cards",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "AWS AI Service Cards with model specifications and enterprise integration documentation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://aws.amazon.com/machine-learning/ai-service-cards/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0024",
    "providerId": "amazon",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Comprehensive enterprise policy and compliance documentation with AWS security frameworks",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://aws.amazon.com/compliance/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "7aebc6ba51d8d5c30c521a712af004ce6327265ef0f4c3a61607090261adeec2",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0001",
    "providerId": "cohere",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise document focus with bias metrics during training for business use cases",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "b0dba8cabd9869b78f0e3482f3f224ec1d897a7cdd88bd616ee019e61841d615",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0002",
    "providerId": "cohere",
    "techniqueId": "tech-csam-detection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic CSAM detection as part of enterprise content filtering systems",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "b0dba8cabd9869b78f0e3482f3f224ec1d897a7cdd88bd616ee019e61841d615",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0003",
    "providerId": "cohere",
    "techniqueId": "tech-copyright-filtering",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Copyright filtering mechanisms for enterprise compliance and content policies",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "b0dba8cabd9869b78f0e3482f3f224ec1d897a7cdd88bd616ee019e61841d615",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-cohere-0004",
    "providerId": "cohere",
    "techniqueId": "tech-bias-detection-training",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Bias metrics published during training with focus on enterprise fairness requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "b0dba8cabd9869b78f0e3482f3f224ec1d897a7cdd88bd616ee019e61841d615",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0005",
    "providerId": "cohere",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic PII reduction capabilities for enterprise data protection requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "b0dba8cabd9869b78f0e3482f3f224ec1d897a7cdd88bd616ee019e61841d615",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0006",
    "providerId": "cohere",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise compliance filtering with focus on business regulatory requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "b0dba8cabd9869b78f0e3482f3f224ec1d897a7cdd88bd616ee019e61841d615",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0007",
    "providerId": "cohere",
    "techniqueId": "tech-rlhf",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "RLHF for business use cases with enterprise-focused training optimization",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "b0dba8cabd9869b78f0e3482f3f224ec1d897a7cdd88bd616ee019e61841d615",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0008",
    "providerId": "cohere",
    "techniqueId": "tech-community-feedback",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited community feedback integration focused on enterprise customer requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "b0dba8cabd9869b78f0e3482f3f224ec1d897a7cdd88bd616ee019e61841d615",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0009",
    "providerId": "cohere",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Domain-specific fine-tuning for enterprise safety requirements and business use cases",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/fine-tuning",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "70eb0e1acb0421ecb2e2168e780e3c0a1208ce54b1fe014c29007995013e088a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0010",
    "providerId": "cohere",
    "techniqueId": "tech-input-classification",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic input content classification with dual safety modes (strict/contextual)",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "b0dba8cabd9869b78f0e3482f3f224ec1d897a7cdd88bd616ee019e61841d615",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0011",
    "providerId": "cohere",
    "techniqueId": "tech-output-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Output filtering through dual safety modes with enterprise logging capabilities",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "b0dba8cabd9869b78f0e3482f3f224ec1d897a7cdd88bd616ee019e61841d615",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0012",
    "providerId": "cohere",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic prompt injection protection through safety mode filtering",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "b0dba8cabd9869b78f0e3482f3f224ec1d897a7cdd88bd616ee019e61841d615",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0013",
    "providerId": "cohere",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited real-time monitoring capabilities through safety mode enforcement",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "b0dba8cabd9869b78f0e3482f3f224ec1d897a7cdd88bd616ee019e61841d615",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0014",
    "providerId": "cohere",
    "techniqueId": "tech-contextual-safety",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Contextual safety assessment through CONTEXTUAL safety mode allowing nuanced moderation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "b0dba8cabd9869b78f0e3482f3f224ec1d897a7cdd88bd616ee019e61841d615",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0015",
    "providerId": "cohere",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic multi-stage pipeline with dual safety modes and enterprise integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "b0dba8cabd9869b78f0e3482f3f224ec1d897a7cdd88bd616ee019e61841d615",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0016",
    "providerId": "cohere",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Configurable safety policies through STRICT and CONTEXTUAL mode selection",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "b0dba8cabd9869b78f0e3482f3f224ec1d897a7cdd88bd616ee019e61841d615",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0017",
    "providerId": "cohere",
    "techniqueId": "tech-audit-logging",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise audit logging for disallowed prompts and safety mode enforcement",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "b0dba8cabd9869b78f0e3482f3f224ec1d897a7cdd88bd616ee019e61841d615",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0018",
    "providerId": "cohere",
    "techniqueId": "tech-enterprise-integration",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise security integration with on-premises deployment options",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cohere.com/enterprise",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0019",
    "providerId": "cohere",
    "techniqueId": "tech-sovereignty-options",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "On-premises deployment options for data sovereignty and enterprise control",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cohere.com/enterprise",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0020",
    "providerId": "cohere",
    "techniqueId": "tech-incident-reporting",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic incident reporting through enterprise support channels",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "b0dba8cabd9869b78f0e3482f3f224ec1d897a7cdd88bd616ee019e61841d615",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0021",
    "providerId": "cohere",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Usage monitoring and analytics for enterprise safety and compliance tracking",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "b0dba8cabd9869b78f0e3482f3f224ec1d897a7cdd88bd616ee019e61841d615",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0022",
    "providerId": "cohere",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise regulatory compliance frameworks with industry-specific requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cohere.com/enterprise",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0023",
    "providerId": "cohere",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited academic partnerships with focus on enterprise applications",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cohere.com/research",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "f14df3a380dc3097df675aef52ce4969021d10cbefc168fa882a014c04bb4b76",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0024",
    "providerId": "cohere",
    "techniqueId": "tech-community-governance",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited community governance with enterprise customer feedback integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "b0dba8cabd9869b78f0e3482f3f224ec1d897a7cdd88bd616ee019e61841d615",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0025",
    "providerId": "cohere",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic safety documentation focused on safety modes and enterprise implementation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "b0dba8cabd9869b78f0e3482f3f224ec1d897a7cdd88bd616ee019e61841d615",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0026",
    "providerId": "cohere",
    "techniqueId": "tech-model-cards",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited model cards and technical specifications with enterprise focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "7b2927e417f7b0646d1c468893629c1f8fd896e19c43a700d7cf0c77eccb6d7d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0027",
    "providerId": "cohere",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited safety research publications with focus on enterprise applications",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cohere.com/research",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "f14df3a380dc3097df675aef52ce4969021d10cbefc168fa882a014c04bb4b76",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0028",
    "providerId": "cohere",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise policy and compliance documentation with safety mode implementation guides",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "b0dba8cabd9869b78f0e3482f3f224ec1d897a7cdd88bd616ee019e61841d615",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-mistral-0001",
    "providerId": "mistral",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Lightweight filtering with community-driven approach and European data focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "40a31e413e1347a37468976344e89264c954d881a7dcd6c9ca0e0b3c404e0946",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0002",
    "providerId": "mistral",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "European AI sovereignty focus with EU regulatory compliance measures",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "40a31e413e1347a37468976344e89264c954d881a7dcd6c9ca0e0b3c404e0946",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-mistral-0003",
    "providerId": "mistral",
    "techniqueId": "tech-rlhf",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Minimal RLHF implementation with community feedback integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "40a31e413e1347a37468976344e89264c954d881a7dcd6c9ca0e0b3c404e0946",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0004",
    "providerId": "mistral",
    "techniqueId": "tech-community-feedback",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community feedback integration for model improvement and safety enhancement",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "40a31e413e1347a37468976344e89264c954d881a7dcd6c9ca0e0b3c404e0946",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0005",
    "providerId": "mistral",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Domain-specific fine-tuning capabilities with European regulatory focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.mistral.ai/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "1b4a51d20be6f483dc9079763b3bca8d388e9224d7f639e21a5efd415930b0da",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-mistral-0006",
    "providerId": "mistral",
    "techniqueId": "tech-input-classification",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Moderation API for input content classification with lightweight approach",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "40a31e413e1347a37468976344e89264c954d881a7dcd6c9ca0e0b3c404e0946",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0007",
    "providerId": "mistral",
    "techniqueId": "tech-output-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Content classification and filtering through Moderation API",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "40a31e413e1347a37468976344e89264c954d881a7dcd6c9ca0e0b3c404e0946",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0008",
    "providerId": "mistral",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic prompt injection protection through content classification",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "40a31e413e1347a37468976344e89264c954d881a7dcd6c9ca0e0b3c404e0946",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0009",
    "providerId": "mistral",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Lightweight safety pipeline with moderation API and content classification",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "40a31e413e1347a37468976344e89264c954d881a7dcd6c9ca0e0b3c404e0946",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0010",
    "providerId": "mistral",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic configurable policies through moderation API categories",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "40a31e413e1347a37468976344e89264c954d881a7dcd6c9ca0e0b3c404e0946",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0011",
    "providerId": "mistral",
    "techniqueId": "tech-community-governance",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community governance model with European AI sovereignty principles",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "40a31e413e1347a37468976344e89264c954d881a7dcd6c9ca0e0b3c404e0946",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0012",
    "providerId": "mistral",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "EU-focused regulatory compliance with European AI sovereignty emphasis",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "40a31e413e1347a37468976344e89264c954d881a7dcd6c9ca0e0b3c404e0946",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-mistral-0013",
    "providerId": "mistral",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited academic partnerships with European research institutions",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/research",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0014",
    "providerId": "mistral",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic safety documentation with moderation API specifications",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "40a31e413e1347a37468976344e89264c954d881a7dcd6c9ca0e0b3c404e0946",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0015",
    "providerId": "mistral",
    "techniqueId": "tech-model-cards",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited model cards and technical documentation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.mistral.ai/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "1b4a51d20be6f483dc9079763b3bca8d388e9224d7f639e21a5efd415930b0da",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0016",
    "providerId": "mistral",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Minimal safety research publications with focus on efficiency",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/research",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0017",
    "providerId": "mistral",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic policy documentation with EU regulatory compliance focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-10-31",
        "sourceHash": "40a31e413e1347a37468976344e89264c954d881a7dcd6c9ca0e0b3c404e0946",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0001",
    "providerId": "baidu",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Chinese regulatory compliance with government-approved content filtering",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0002",
    "providerId": "baidu",
    "techniqueId": "tech-csam-detection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "CSAM detection in compliance with Chinese internet regulations",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0003",
    "providerId": "baidu",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive Chinese regulatory compliance with government oversight integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-baidu-0004",
    "providerId": "baidu",
    "techniqueId": "tech-rlhf",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "RLHF with alignment to Chinese values and regulatory requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0005",
    "providerId": "baidu",
    "techniqueId": "tech-input-classification",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Real-time censorship and political content filtering for input classification",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0006",
    "providerId": "baidu",
    "techniqueId": "tech-output-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Political content filtering and real-time censorship for output content",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0007",
    "providerId": "baidu",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic prompt injection protection through content filtering and government oversight",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0008",
    "providerId": "baidu",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Real-time monitoring with government oversight and regulatory compliance",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0009",
    "providerId": "baidu",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Multi-stage pipeline with government oversight and political content filtering",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0010",
    "providerId": "baidu",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Government-configured safety policies with Chinese regulatory compliance",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0011",
    "providerId": "baidu",
    "techniqueId": "tech-audit-logging",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Government audit logging and compliance tracking for regulatory oversight",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0012",
    "providerId": "baidu",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Direct government oversight and regulatory compliance with Chinese authorities",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-baidu-0013",
    "providerId": "baidu",
    "techniqueId": "tech-incident-reporting",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Government incident reporting with regulatory compliance tracking",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0014",
    "providerId": "baidu",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Usage monitoring with government oversight and regulatory compliance",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0015",
    "providerId": "baidu",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive Chinese regulatory compliance with government framework integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-baidu-0016",
    "providerId": "baidu",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited academic partnerships with Chinese research institutions",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0017",
    "providerId": "baidu",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited international transparency with Chinese regulatory documentation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0018",
    "providerId": "baidu",
    "techniqueId": "tech-model-cards",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic model cards with Chinese regulatory compliance information",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0019",
    "providerId": "baidu",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited international safety research publications with regulatory focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://research.baidu.com/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "0129a6649f7b95098cc2b812c5293740889775136b8738106035d05363431f8d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0020",
    "providerId": "baidu",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Chinese regulatory documentation with limited international transparency",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "6039b90e483fe006cf7bb323462fa150ecc77b4bb62d6c98364f0f8a07d6c0a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0001",
    "providerId": "alibaba",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Commercial focus with regulatory compliance and business-oriented filtering",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "864fab3015dd0c8bcd91056d43810316066489c212032afb572afffa7117d5a2",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0002",
    "providerId": "alibaba",
    "techniqueId": "tech-csam-detection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "CSAM detection for Chinese regulatory compliance and commercial deployment",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "29ad5bac3f20d7d9f97eb0d8b01a1215fee965bcebb912ea02a200b79125c9e6",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0003",
    "providerId": "alibaba",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Chinese regulatory compliance with commercial focus and efficiency optimization",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "7cd427fc4320b697a946fa9cebed3ec6294cd7f7989613bc620b1a553f71f7dd",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0004",
    "providerId": "alibaba",
    "techniqueId": "tech-rlhf",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Business-oriented RLHF with efficiency focus and commercial optimization",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "e2a50b3ce2ee9ce76a95a0d3b2968881b028cc9a432f8530bfd2df497567b47e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0005",
    "providerId": "alibaba",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Domain-specific fine-tuning for business process automation and commercial safety",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "cfd9970e3bafc576d4faa38723ad01e5ca34bd40c14fdff86894afb20c950138",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0006",
    "providerId": "alibaba",
    "techniqueId": "tech-input-classification",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise content filtering with customer customization for business use cases",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "23cb65443897cc2547cb3170e9c9108b694abe937ee2c67bc611fc8f0a060bd8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0007",
    "providerId": "alibaba",
    "techniqueId": "tech-output-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Customer-customizable output filtering for enterprise and commercial applications",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "0945d38b0994265a081baf42c0a10c4757f65dd5b70155a0d087a9d7f9bd7452",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0008",
    "providerId": "alibaba",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic prompt injection protection through enterprise content filtering",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "966fd1516865afc415624e129f5932178cff4f0c63c1f77cd561f6be18c6f69c",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0009",
    "providerId": "alibaba",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Real-time monitoring for commercial applications with business process integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "a4d45c18e582f7b7502c9d79b3e9a2b3cc5b4904a9b833600663f31d449f3235",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0010",
    "providerId": "alibaba",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Multi-stage pipeline with cloud integration and business process automation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "a1dc79df8a2c76a8558c9fa09d073eccdd2e0eaa3399b7a6eb22578f15e69640",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0011",
    "providerId": "alibaba",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic PII detection for enterprise data protection and commercial compliance",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "7acf82e2edd40fb300d18fcf67620cb82bd0d6028e8fe78b869d7179e8bea5bb",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0012",
    "providerId": "alibaba",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Customer-configurable safety policies for enterprise deployment and business needs",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "233cd81a5cdcc9de3d668e900a8432185df3d7c3063a0c13faf30e6227a51696",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0013",
    "providerId": "alibaba",
    "techniqueId": "tech-audit-logging",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise audit logging for business compliance and commercial accountability",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "32383683bf44e2a54ec4fb8d66726d746d5904fde7654bec3de1ddfd4a177baf",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0014",
    "providerId": "alibaba",
    "techniqueId": "tech-enterprise-integration",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Cloud integration with Alibaba Cloud security and business process automation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "280e0db3c4a71c3d830e8125ffc52498cf2e1cffbcff240dc10e046d81230614",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0015",
    "providerId": "alibaba",
    "techniqueId": "tech-sovereignty-options",
    "modelIds": [],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Data sovereignty options through Alibaba Cloud with regional deployment flexibility",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "b9c1e72f82660f13d0ecdb07b4b1ac8f779c3f49da85585d3d8a95c7ea61ac9d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-alibaba-0016",
    "providerId": "alibaba",
    "techniqueId": "tech-incident-reporting",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic incident reporting through enterprise support and commercial channels",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "3dadb27aab5e4663f9e69636f83559687c12edd975ceae1f2d2dbd66b2fad519",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0017",
    "providerId": "alibaba",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise usage monitoring with business analytics and commercial optimization",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "d663c50fb9bce33cc3ab736f13d63d840691f0bc8e2232c95105b9c2738494d8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0018",
    "providerId": "alibaba",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Chinese regulatory compliance frameworks with commercial focus and enterprise requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "3edd68d0744fcb9fb37a5dcc2bcb57d4c40fd70cef8ec27331648dc719ba2483",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0019",
    "providerId": "alibaba",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Business documentation with limited research disclosure and commercial focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "1a4b961742e4a4209acfc59242ff694a22f53b1cc9c84028b8e5b7bfeee57b50",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0020",
    "providerId": "alibaba",
    "techniqueId": "tech-model-cards",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic model cards with commercial specifications and business application focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "a6c56c099d421879cd887a9d307dd5530202ed2d70e4ac62ebff452faeec7251",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0021",
    "providerId": "alibaba",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Business policy documentation with enterprise compliance and commercial requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-31",
        "sourceHash": "34f93cb405ebc4e6e6038a6d9a1267804047f26d85d61dee189f4b50a5ca56b1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-x-constitutional-ai-001",
    "providerId": "x",
    "techniqueId": "tech-constitutional-ai",
    "modelIds": [],
    "summary": "Constitutional AI training methodology implemented in Grok-4 to align model behavior with human values and safety principles",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.ai/news/grok-4",
        "documentType": "blog-post",
        "relevantSection": "Training and Safety",
        "lastVerified": "2025-07-24",
        "sourceHash": "c6d3e7bfa462aef2201bdff29ed7472fefb66eed1a8478ae51f05b63a54e3de3"
      }
    ],
    "knownLimitations": [
      "Limited public details on specific constitutional principles",
      "No published effectiveness metrics"
    ],
    "notes": "Grok-4 implements constitutional AI for value alignment",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-realtime-fact-check-002",
    "providerId": "x",
    "techniqueId": "tech-realtime-fact-checking",
    "modelIds": [],
    "summary": "Integration with X platform's real-time information feed to fact-check claims and provide current information verification",
    "rating": "medium-high",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.ai/news/grok-4",
        "documentType": "blog-post",
        "relevantSection": "Real-time Information Access",
        "lastVerified": "2025-07-24",
        "sourceHash": "c6d3e7bfa462aef2201bdff29ed7472fefb66eed1a8478ae51f05b63a54e3de3"
      }
    ],
    "knownLimitations": [
      "Dependent on X platform data quality",
      "May amplify trending misinformation"
    ],
    "notes": "Unique capability leveraging X's real-time data stream",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "premium-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-platform-context-003",
    "providerId": "x",
    "techniqueId": "tech-contextual-safety",
    "modelIds": [],
    "summary": "Safety measures that consider broader X platform context, user interaction history, and social graph for contextual risk assessment",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.com/privacy",
        "documentType": "privacy-policy",
        "relevantSection": "Data Usage for AI Services",
        "lastVerified": "2025-10-31",
        "sourceHash": "60fbee901072617ffcb0c516ef98af0e099b6e95e27d545df1c5763e12cc4a93"
      }
    ],
    "knownLimitations": [
      "Privacy implications of using social context",
      "Potential for social bias amplification"
    ],
    "notes": "Leverages X platform social context for safety",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-multimodal-safety-004",
    "providerId": "x",
    "techniqueId": "tech-multimodal-safety-alignment",
    "modelIds": [],
    "summary": "Cross-modal safety alignment for Grok-4's multimodal capabilities, ensuring safety across text, image, and audio interactions",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.ai/news/grok-4",
        "documentType": "blog-post",
        "relevantSection": "Multimodal Capabilities",
        "lastVerified": "2025-07-24",
        "sourceHash": "c6d3e7bfa462aef2201bdff29ed7472fefb66eed1a8478ae51f05b63a54e3de3"
      }
    ],
    "knownLimitations": [
      "Cross-modal safety interactions are complex",
      "Limited multimodal safety evaluation data"
    ],
    "notes": "Addresses safety across multiple modalities in Grok-4",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-input-classification-005",
    "providerId": "x",
    "techniqueId": "tech-input-classification",
    "modelIds": [],
    "summary": "Pre-processing classification of user inputs to identify potential safety risks before processing by Grok-4",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://help.x.com/en/rules-and-policies",
        "documentType": "policy-documentation",
        "relevantSection": "Content Moderation",
        "lastVerified": "2025-07-24",
        "sourceHash": "b737b99b7dde781f17abe0db3c6129d63edce718f07dad841b9e15ffd47fef2a"
      }
    ],
    "knownLimitations": [
      "May block benign content",
      "Context-dependent risks challenging to detect"
    ],
    "notes": "Integrated with X platform content moderation",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-output-filtering-006",
    "providerId": "x",
    "techniqueId": "tech-output-filtering",
    "modelIds": [],
    "summary": "Post-generation filtering of Grok-4 outputs for safety violations before presentation to users",
    "rating": "medium-high",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://help.x.com/en/rules-and-policies",
        "documentType": "policy-documentation",
        "relevantSection": "AI Content Guidelines",
        "lastVerified": "2025-07-24",
        "sourceHash": "b737b99b7dde781f17abe0db3c6129d63edce718f07dad841b9e15ffd47fef2a"
      }
    ],
    "knownLimitations": [
      "May alter intended meaning",
      "Can be overly restrictive"
    ],
    "notes": "Aligned with X platform community guidelines",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-realtime-monitoring-007",
    "providerId": "x",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "summary": "Continuous monitoring of Grok-4 interactions for safety violations and emerging risk patterns",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.com/tos",
        "documentType": "terms-of-service",
        "relevantSection": "Monitoring and Enforcement",
        "lastVerified": "2025-10-31",
        "sourceHash": "ad559eb7e548b3d75b89fe369fbe019c7209df50851738e07f5af1d67761fc4a"
      }
    ],
    "knownLimitations": [
      "Latency impact on user experience",
      "May miss contextual nuances"
    ],
    "notes": "Integrated with X platform monitoring infrastructure",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-pii-detection-008",
    "providerId": "x",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [],
    "summary": "Real-time detection and redaction of personally identifiable information in Grok-4 interactions",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.com/privacy",
        "documentType": "privacy-policy",
        "relevantSection": "Personal Information Protection",
        "lastVerified": "2025-10-31",
        "sourceHash": "73c0a9e0df55e38cf294615ece89c4ca3b5b28cc3839ad7b6113ba536c11063a"
      }
    ],
    "knownLimitations": [
      "Context-dependent PII challenging to detect",
      "May miss novel PII patterns"
    ],
    "notes": "Complies with X platform privacy standards",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "GDPR",
      "CCPA"
    ],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-training-filtering-009",
    "providerId": "x",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [],
    "summary": "Systematic filtering of training data for Grok-4 to remove harmful, biased, or inappropriate content",
    "rating": "medium-low",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.ai/news/grok-4",
        "documentType": "blog-post",
        "relevantSection": "Data and Training",
        "lastVerified": "2025-07-24",
        "sourceHash": "c6d3e7bfa462aef2201bdff29ed7472fefb66eed1a8478ae51f05b63a54e3de3"
      }
    ],
    "knownLimitations": [
      "Limited transparency on filtering criteria",
      "May introduce demographic biases"
    ],
    "notes": "Standard pre-training data curation practices",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-audit-logging-010",
    "providerId": "x",
    "techniqueId": "tech-audit-logging",
    "modelIds": [],
    "summary": "Comprehensive logging of Grok-4 safety-relevant events and decisions for audit and improvement purposes",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.com/tos",
        "documentType": "terms-of-service",
        "relevantSection": "Data Retention and Logging",
        "lastVerified": "2025-10-31",
        "sourceHash": "d24a8fc779fd90221af3ece262f9573b8da38282b80b1cd02c0871acada57e67"
      }
    ],
    "knownLimitations": [
      "Storage and privacy considerations",
      "Log completeness not specified"
    ],
    "notes": "Supports X platform compliance requirements",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "SOC2"
    ],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  }
]