{
  "sources": [
    {
      "id": "gpt-5-system-card",
      "title": "GPT-5 System Card",
      "provider": "openai",
      "url": "https://cdn.openai.com/gpt-5-system-card.pdf",
      "type": "System Card",
      "date_added": "2026-01-15",
      "models": [
        {
          "modelId": "gpt-5-thinking",
          "name": "GPT-5"
        },
        {
          "modelId": "gpt-5.2",
          "name": "GPT-5.2"
        },
        {
          "modelId": "gpt-5-mini",
          "name": "GPT-5 Mini"
        }
      ],
      "content_metadata": {
        "document_purpose": "system_card",
        "signal_strength": "high",
        "temporal_focus": "implemented",
        "scope": "model_family",
        "technical_depth": "moderate",
        "primary_topics": [
          "alignment_methods",
          "pre_training_safety",
          "transparency",
          "governance",
          "safety_benchmarking"
        ],
        "excluded_topics": [],
        "confidence_weight": 1.0,
        "language": "en",
        "notes": "Official GPT-5 system card describing multi-model architecture with router, reasoning capabilities, and Preparedness Framework classification for biological risks"
      }
    },
    {
      "id": "claude-opus-4-5-system-card",
      "title": "Claude Opus 4.5 System Card",
      "provider": "anthropic",
      "url": "https://assets.anthropic.com/m/64823ba7485345a7/Claude-Opus-4-5-System-Card.pdf",
      "type": "System Card",
      "date_added": "2026-01-20",
      "models": [
        {
          "modelId": "claude-opus-4.5",
          "name": "Claude 3.5 Opus"
        }
      ],
      "content_metadata": {
        "document_purpose": "system_card",
        "signal_strength": "high",
        "temporal_focus": "implemented",
        "scope": "specific_model",
        "technical_depth": "deep",
        "primary_topics": [
          "safety_benchmarking",
          "red_teaming",
          "alignment_methods",
          "output_guardrails",
          "governance",
          "transparency"
        ],
        "excluded_topics": [],
        "confidence_weight": 1.0,
        "language": "en",
        "notes": "Comprehensive official system card for Claude Opus 4.5 covering capabilities evaluation, safety testing, alignment assessment, and AI Safety Level 3 deployment decision."
      }
    },
    {
      "id": "gemini-3-technical-report",
      "title": "Gemini 3 Technical Report",
      "provider": "google",
      "url": "https://storage.googleapis.com/deepmind-media/gemini/gemini_3_pro_fsf_report.pdf",
      "type": "Technical Report",
      "date_added": "2026-01-22",
      "models": [
        {
          "modelId": "gemini-3-pro",
          "name": "Gemini 3 Pro"
        },
        {
          "modelId": "gemini-3-flash",
          "name": "Gemini 3 Flash"
        },
        {
          "modelId": "gemini-3-deep-think",
          "name": "Gemini 3 Deep Think"
        }
      ],
      "content_metadata": {
        "document_purpose": "system_card",
        "signal_strength": "high",
        "temporal_focus": "implemented",
        "scope": "specific_model",
        "technical_depth": "moderate",
        "primary_topics": [
          "governance",
          "red_teaming",
          "safety_benchmarking",
          "transparency"
        ],
        "excluded_topics": [],
        "confidence_weight": 1.0,
        "language": "en",
        "notes": "Frontier Safety Framework implementation report focusing on CBRN, cybersecurity, ML R&D, and manipulation risks for Gemini 3 Pro"
      }
    },
    {
      "id": "llama-4-responsible-use-guide",
      "title": "Llama 4 Responsible Use Guide",
      "provider": "meta",
      "url": "https://d1.awsstatic.com/products/generative-ai/responsbile-ai/AWS-Responsible-Use-of-AI-Guide-Final.pdf",
      "type": "Guide",
      "models": [
        {
          "modelId": "llama-4-8b",
          "name": "Llama 4 8B"
        },
        {
          "modelId": "llama-4-17b",
          "name": "Llama 4 17B"
        },
        {
          "modelId": "llama-4-scout",
          "name": "Llama 4 Scout"
        },
        {
          "modelId": "llama-4-maverick",
          "name": "Llama 4 Maverick"
        }
      ],
      "content_metadata": {
        "document_purpose": "policy",
        "signal_strength": "medium",
        "temporal_focus": "implemented",
        "scope": "provider_wide",
        "technical_depth": "shallow",
        "primary_topics": [
          "governance",
          "transparency",
          "alignment_methods",
          "safety_benchmarking"
        ],
        "excluded_topics": [
          "cat_model_development",
          "cat_evaluation",
          "cat_harm_classification"
        ],
        "confidence_weight": 0.7,
        "language": "en",
        "notes": "High-level framework for responsible AI practices across design, development, deployment, and operation phases with organizational maturity model"
      }
    },
    {
      "id": "aws-nova-service-card",
      "title": "Amazon Nova Micro, Lite, Pro, and Premier - AWS AI Service Cards",
      "provider": "amazon",
      "url": "https://docs.aws.amazon.com/ai/responsible-ai/nova-micro-lite-pro/overview.html",
      "type": "System Card",
      "models": [
        {
          "modelId": "nova-pro",
          "name": "Amazon Nova Pro"
        },
        {
          "modelId": "nova-lite",
          "name": "Amazon Nova Lite"
        },
        {
          "modelId": "nova-micro",
          "name": "Amazon Nova Micro"
        }
      ],
      "content_metadata": {
        "document_purpose": "system_card",
        "signal_strength": "high",
        "temporal_focus": "implemented",
        "scope": "model_family",
        "technical_depth": "moderate",
        "primary_topics": [
          "transparency",
          "safety_benchmarking",
          "runtime_safety",
          "governance",
          "privacy_protection"
        ],
        "excluded_topics": [],
        "confidence_weight": 1.0,
        "language": "en",
        "notes": "AWS AI Service Card covering Nova Micro, Lite, Pro, and Premier models with details on safety filtering, fairness evaluations, privacy controls, and responsible AI dimensions."
      }
    },
    {
      "id": "mistral-large-2411-card",
      "title": "Mistral Large 2411 Model Card",
      "provider": "mistral",
      "url": "https://huggingface.co/mistralai/Mistral-Large-Instruct-2411",
      "type": "Model Card",
      "models": [
        {
          "modelId": "mistral-large-3",
          "name": "Mistral Large 3"
        },
        {
          "modelId": "ministral-3",
          "name": "Ministral 3"
        }
      ],
      "content_metadata": {
        "document_purpose": "model_card",
        "signal_strength": "medium",
        "temporal_focus": "implemented",
        "scope": "specific_model",
        "technical_depth": "shallow",
        "primary_topics": [
          "transparency",
          "alignment_methods"
        ],
        "excluded_topics": [],
        "confidence_weight": 0.7,
        "language": "en",
        "notes": "HuggingFace model card for Mistral Large Instruct 2411 with basic model capabilities and usage information."
      }
    },
    {
      "id": "o3-pro",
      "title": "OpenAI o3 and o4-mini System Card",
      "provider": "openai",
      "url": "https://cdn.openai.com/pdf/2221c875-02dc-4789-800b-e7758f3722c1/o3-and-o4-mini-system-card.pdf",
      "type": "System Card",
      "models": [
        {
          "modelId": "o3-pro",
          "name": "o3"
        },
        {
          "modelId": "o4-mini",
          "name": "o4-mini"
        },
        {
          "modelId": "o3",
          "name": "o3"
        }
      ],
      "content_metadata": {
        "document_purpose": "system_card",
        "signal_strength": "high",
        "temporal_focus": "implemented",
        "scope": "model_family",
        "technical_depth": "moderate",
        "primary_topics": [
          "alignment_methods",
          "safety_benchmarking",
          "governance",
          "pre_training_safety",
          "output_guardrails",
          "transparency"
        ],
        "excluded_topics": [],
        "confidence_weight": 1.0,
        "language": "en",
        "notes": "Official system card for o3 and o4-mini models covering deliberative alignment, Preparedness Framework v2 evaluations, and safety assessment across biological, cybersecurity, and AI self-improvement risk categories."
      }
    },
    {
      "id": "deepseek-r1-paper",
      "title": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning",
      "provider": "deepseek",
      "url": "https://arxiv.org/pdf/2501.12948",
      "type": "Paper",
      "models": [
        {
          "modelId": "deepseek-r1",
          "name": "DeepSeek-R1"
        },
        {
          "modelId": "deepseek-r1-distill",
          "name": "DeepSeek-R1-Distill"
        }
      ],
      "content_metadata": {
        "document_purpose": "primary_research",
        "signal_strength": "high",
        "temporal_focus": "research",
        "scope": "specific_model",
        "technical_depth": "deep",
        "primary_topics": [
          "alignment_methods",
          "safety_benchmarking"
        ],
        "excluded_topics": [
          "cat_governance"
        ],
        "confidence_weight": 0.9,
        "language": "en",
        "notes": "Research paper on training reasoning capabilities via pure reinforcement learning without supervised fine-tuning on human demonstrations."
      }
    },
    {
      "id": "cohere-safety-framework",
      "title": "Cohere Safety Framework (ArXiv)",
      "provider": "cohere",
      "url": "https://arxiv.org/pdf/2409.11295",
      "type": "Paper",
      "models": [
        {
          "modelId": "command-r-plus",
          "name": "Command R+"
        },
        {
          "modelId": "command-a",
          "name": "Command A"
        }
      ],
      "content_metadata": {
        "document_purpose": "primary_research",
        "signal_strength": "high",
        "temporal_focus": "research",
        "scope": "industry_wide",
        "technical_depth": "deep",
        "primary_topics": [
          "security",
          "red_teaming",
          "privacy_protection",
          "runtime_safety"
        ],
        "excluded_topics": [
          "cat_model_development",
          "cat_governance"
        ],
        "confidence_weight": 0.95,
        "language": "en",
        "notes": "Novel adversarial attack method (EIA) demonstrating privacy vulnerabilities in generalist web agents operating on compromised websites with 70% attack success rate."
      }
    },
    {
      "id": "claude-3-5-sonnet-card",
      "title": "Claude 3.5 Sonnet System Card",
      "provider": "anthropic",
      "url": "https://www-cdn.anthropic.com/fed9cc193a14b84131812372d8d5857f8f304c52/Model_Card_Claude_3_Addendum.pdf",
      "type": "System Card",
      "models": [
        {
          "modelId": "claude-sonnet-4.5",
          "name": "Claude 3.5 Sonnet"
        }
      ],
      "content_metadata": {
        "document_purpose": "system_card",
        "signal_strength": "high",
        "temporal_focus": "implemented",
        "scope": "specific_model",
        "technical_depth": "moderate",
        "primary_topics": [
          "safety_benchmarking",
          "transparency",
          "alignment_methods"
        ],
        "excluded_topics": [
          "cat_runtime_safety",
          "cat_harm_classification"
        ],
        "confidence_weight": 1.0,
        "language": "en",
        "notes": "Official model card addendum focusing on Claude 3.5 Sonnet's performance benchmarks and capabilities evaluation across reasoning, coding, and vision tasks."
      }
    },
    {
      "id": "qwen2-5-tech-report",
      "title": "Qwen2.5 Technical Report",
      "provider": "alibaba",
      "url": "https://arxiv.org/pdf/2409.12191",
      "type": "Technical Report",
      "models": [
        {
          "modelId": "qwen-2-5-72b",
          "name": "Qwen2.5-72B"
        }
      ],
      "content_metadata": {
        "document_purpose": "primary_research",
        "signal_strength": "high",
        "temporal_focus": "implemented",
        "scope": "model_family",
        "technical_depth": "deep",
        "primary_topics": [
          "transparency"
        ],
        "excluded_topics": [],
        "confidence_weight": 0.4,
        "language": "en",
        "notes": "Technical report on Qwen2-VL vision-language model architecture and capabilities with no apparent safety content in provided excerpt"
      }
    },
    {
      "id": "phi-4-tech-report",
      "title": "Phi-4 Technical Report",
      "provider": "microsoft",
      "url": "https://www.microsoft.com/en-us/research/uploads/prod/2024/12/P4TechReport.pdf",
      "type": "Technical Report",
      "models": [
        {
          "modelId": "phi-4",
          "name": "Phi-4"
        },
        {
          "modelId": "phi-4-multimodal",
          "name": "Phi-4 Multimodal"
        }
      ],
      "content_metadata": {
        "document_purpose": "primary_research",
        "signal_strength": "high",
        "temporal_focus": "implemented",
        "scope": "specific_model",
        "technical_depth": "deep",
        "primary_topics": [
          "pre_training_safety",
          "alignment_methods",
          "safety_benchmarking",
          "transparency"
        ],
        "excluded_topics": [
          "cat_runtime_safety",
          "cat_harm_classification"
        ],
        "confidence_weight": 1.0,
        "language": "en",
        "notes": "Technical report detailing Phi-4's synthetic data generation methods, training curriculum, and post-training techniques including DPO for a 14B parameter model."
      }
    },
    {
      "id": "nemotron-4-tech-report",
      "title": "Nemotron-4 340B Technical Report",
      "provider": "nvidia",
      "url": "https://arxiv.org/pdf/2406.11704",
      "type": "Technical Report",
      "models": [
        {
          "modelId": "nemotron-4",
          "name": "Nemotron-4 340B"
        },
        {
          "modelId": "llama-3.1-nemotron",
          "name": "Llama-3.1-Nemotron"
        }
      ],
      "content_metadata": {
        "document_purpose": "primary_research",
        "signal_strength": "high",
        "temporal_focus": "implemented",
        "scope": "model_family",
        "technical_depth": "deep",
        "primary_topics": [
          "alignment_methods",
          "pre_training_safety",
          "safety_benchmarking",
          "transparency"
        ],
        "excluded_topics": [
          "cat_harm_classification"
        ],
        "confidence_weight": 1.0,
        "language": "en",
        "notes": "Technical report releasing three Nemotron-4 340B models with detailed alignment methodology using 98% synthetic data and open-sourced training pipeline."
      }
    },
    {
      "id": "llama-3-paper",
      "title": "The Llama 3 Herd of Models",
      "provider": "meta",
      "url": "https://arxiv.org/pdf/2407.21783",
      "type": "Paper",
      "models": [
        {
          "modelId": "llama-3-1-405b",
          "name": "Llama 3.1 405B"
        }
      ],
      "content_metadata": {
        "document_purpose": "primary_research",
        "signal_strength": "high",
        "temporal_focus": "implemented",
        "scope": "model_family",
        "technical_depth": "deep",
        "primary_topics": [
          "transparency",
          "pre_training_safety",
          "alignment_methods",
          "output_guardrails"
        ],
        "excluded_topics": [],
        "confidence_weight": 1.0,
        "language": "en",
        "notes": "Official technical paper detailing the Llama 3 model family architecture, training methodology, and inclusion of Llama Guard 3 safety model."
      }
    },
    {
      "id": "grok-image-gen-update",
      "title": "@Grok Account Image Generation Updates",
      "provider": "xai",
      "url": "https://x.com/Safety/status/2011573102485127562",
      "type": "Blog Post",
      "models": [
        {
          "modelId": "grok-4",
          "name": "Grok 4"
        },
        {
          "modelId": "grok-4-thinking",
          "name": "Grok 4 (Thinking)"
        },
        {
          "modelId": "grok-4-fast",
          "name": "Grok 4 (Fast)"
        }
      ],
      "content_metadata": {
        "document_purpose": "blog_post",
        "signal_strength": "low",
        "temporal_focus": "implemented",
        "scope": "specific_model",
        "technical_depth": "shallow",
        "primary_topics": [
          "output_guardrails",
          "transparency"
        ],
        "excluded_topics": [],
        "confidence_weight": 0.3,
        "language": "en",
        "notes": "Document contains only JavaScript error message and footer content with no actual safety information about Grok image generation updates."
      }
    },
    {
      "id": "grok-security",
      "title": "xAI Security",
      "provider": "xai",
      "url": "https://docs.x.ai/developers/faq/security",
      "type": "Documentation",
      "models": [
        {
          "modelId": "grok-4",
          "name": "Grok 4"
        },
        {
          "modelId": "grok-4-thinking",
          "name": "Grok 4 (Thinking)"
        },
        {
          "modelId": "grok-4-fast",
          "name": "Grok 4 (Fast)"
        }
      ],
      "content_metadata": {
        "document_purpose": "documentation",
        "signal_strength": "high",
        "temporal_focus": "implemented",
        "scope": "provider_wide",
        "technical_depth": "moderate",
        "primary_topics": [
          "security",
          "privacy_protection",
          "governance",
          "transparency"
        ],
        "excluded_topics": [],
        "confidence_weight": 0.8,
        "language": "en",
        "notes": "Official API security documentation covering data retention policies, compliance certifications, audit logging, and API key management practices."
      }
    },
    {
      "id": "gemini-1-5-paper",
      "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
      "provider": "google",
      "url": "https://arxiv.org/pdf/2403.05530",
      "type": "Paper",
      "models": [
        {
          "modelId": "gemini-1-5-pro",
          "name": "Gemini 1.5 Pro"
        }
      ],
      "content_metadata": {
        "document_purpose": "primary_research",
        "signal_strength": "high",
        "temporal_focus": "implemented",
        "scope": "model_family",
        "technical_depth": "deep",
        "primary_topics": [
          "transparency",
          "safety_benchmarking"
        ],
        "excluded_topics": [],
        "confidence_weight": 1.0,
        "language": "en",
        "notes": "Technical research paper introducing Gemini 1.5 Pro and Flash models with focus on long-context multimodal capabilities up to 10M tokens."
      }
    },
    {
      "id": "gpt-4o-system-card",
      "title": "GPT-4o System Card",
      "provider": "openai",
      "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
      "type": "System Card",
      "models": [
        {
          "modelId": "gpt-4o",
          "name": "GPT-4o"
        }
      ],
      "content_metadata": {
        "document_purpose": "system_card",
        "signal_strength": "high",
        "temporal_focus": "implemented",
        "scope": "specific_model",
        "technical_depth": "moderate",
        "primary_topics": [
          "transparency",
          "safety_benchmarking",
          "red_teaming",
          "pre_training_safety",
          "alignment_methods",
          "runtime_safety"
        ],
        "excluded_topics": [
          "cat_evaluation"
        ],
        "confidence_weight": 1.0,
        "language": "en",
        "notes": "Official GPT-4o system card detailing multimodal capabilities, safety evaluations, and alignment measures across text, audio, and vision modalities."
      }
    },
    {
      "id": "claude-3-haiku-model-card",
      "title": "Claude 3 Haiku Model Card",
      "provider": "anthropic",
      "url": "https://assets.anthropic.com/m/1cd9d098ac3e6467/original/Claude-3-Model-Card-October-Addendum.pdf",
      "type": "Model Card",
      "models": [
        {
          "modelId": "claude-haiku-4.5",
          "name": "Claude 3 Haiku"
        }
      ],
      "content_metadata": {
        "document_purpose": "system_card",
        "signal_strength": "high",
        "temporal_focus": "implemented",
        "scope": "model_family",
        "technical_depth": "moderate",
        "primary_topics": [
          "safety_benchmarking",
          "red_teaming",
          "transparency",
          "governance",
          "alignment_methods"
        ],
        "excluded_topics": [],
        "confidence_weight": 1.0,
        "language": "en",
        "notes": "Official model card addendum for Claude 3.5 Haiku and upgraded Sonnet with computer use capability evaluations and safety assessments."
      }
    },
    {
      "id": "pixtral-12b-blog",
      "title": "Pixtral 12B Blog Post",
      "provider": "mistral",
      "url": "https://mistral.ai/news/pixtral-12b/",
      "type": "Blog Post",
      "models": [
        {
          "modelId": "pixtral",
          "name": "Pixtral 12B"
        }
      ],
      "content_metadata": {
        "document_purpose": "blog_post",
        "signal_strength": "medium",
        "temporal_focus": "implemented",
        "scope": "specific_model",
        "technical_depth": "moderate",
        "primary_topics": [
          "transparency",
          "safety_benchmarking"
        ],
        "excluded_topics": [],
        "confidence_weight": 0.7,
        "language": "en",
        "notes": "Product announcement for Pixtral 12B multimodal model focusing on architecture and performance benchmarks with minimal safety detail"
      }
    },
    {
      "id": "hunyuan-technical-report",
      "title": "Hunyuan-Large: An Open-Source MoE Model",
      "provider": "tencent",
      "url": "https://arxiv.org/pdf/2411.02265",
      "type": "Technical Report",
      "models": [
        {
          "modelId": "hunyuan-large",
          "name": "Hunyuan-Large"
        }
      ],
      "content_metadata": {
        "document_purpose": "primary_research",
        "signal_strength": "high",
        "temporal_focus": "implemented",
        "scope": "specific_model",
        "technical_depth": "deep",
        "primary_topics": [
          "transparency",
          "pre_training_safety"
        ],
        "excluded_topics": [
          "cat_evaluation",
          "cat_runtime_safety",
          "cat_governance"
        ],
        "confidence_weight": 1.0,
        "language": "en",
        "notes": "Technical report detailing architecture and training of Hunyuan-Large MoE model with focus on synthetic data and scaling laws rather than safety mechanisms"
      }
    },
    {
      "id": "qwen2-5-coder-tech-report",
      "title": "Qwen2.5-Coder Technical Report",
      "provider": "alibaba",
      "url": "https://arxiv.org/pdf/2409.12186",
      "type": "Technical Report",
      "models": [
        {
          "modelId": "qwen-2-5-coder",
          "name": "Qwen 2.5 Coder"
        }
      ],
      "content_metadata": {
        "document_purpose": "primary_research",
        "signal_strength": "high",
        "temporal_focus": "implemented",
        "scope": "model_family",
        "technical_depth": "deep",
        "primary_topics": [
          "pre_training_safety",
          "alignment_methods",
          "safety_benchmarking",
          "transparency"
        ],
        "excluded_topics": [
          "cat_evaluation",
          "cat_harm_classification"
        ],
        "confidence_weight": 1.0,
        "language": "en",
        "notes": "Technical report detailing architecture, pre-training data composition, post-training methods, and comprehensive benchmark evaluations for the Qwen2.5-Coder model family (0.5B-32B parameters)."
      }
    },
    {
      "id": "deepseek-v3-paper",
      "title": "DeepSeek-V3 Technical Report",
      "provider": "deepseek",
      "url": "https://arxiv.org/pdf/2412.19437",
      "type": "Technical Report",
      "models": [
        {
          "modelId": "deepseek-v3",
          "name": "DeepSeek-V3"
        },
        {
          "modelId": "deepseek-v3-lite",
          "name": "DeepSeek-V3-Lite"
        },
        {
          "modelId": "deepseek-v3.2",
          "name": "DeepSeek-V3.2"
        }
      ],
      "content_metadata": {
        "document_purpose": "primary_research",
        "signal_strength": "high",
        "temporal_focus": "implemented",
        "scope": "specific_model",
        "technical_depth": "deep",
        "primary_topics": [
          "transparency",
          "alignment_methods",
          "pre_training_safety",
          "safety_benchmarking"
        ],
        "excluded_topics": [
          "cat_runtime_safety",
          "cat_harm_classification"
        ],
        "confidence_weight": 1.0,
        "language": "en",
        "notes": "Technical report detailing DeepSeek-V3's architecture, training methodology, and benchmark performance with emphasis on cost-effective MoE implementation."
      }
    },
    {
      "id": "microsoft-rai-standard",
      "title": "Microsoft Responsible AI Standard v2",
      "provider": "microsoft",
      "url": "https://cdn-dynmedia-1.microsoft.com/is/content/microsoftcorp/microsoft/final/en-us/microsoft-brand/documents/Microsoft-Responsible-AI-Standard-General-Requirements.pdf",
      "type": "Policy",
      "models": [
        {
          "modelId": "phi-3-mini"
        },
        {
          "modelId": "phi-4"
        },
        {
          "modelId": "phi-4-multimodal"
        }
      ],
      "content_metadata": {
        "document_purpose": "policy",
        "signal_strength": "high",
        "temporal_focus": "implemented",
        "scope": "provider_wide",
        "technical_depth": "moderate",
        "primary_topics": [
          "governance",
          "transparency",
          "safety_benchmarking",
          "red_teaming"
        ],
        "excluded_topics": [
          "cat_model_development",
          "cat_runtime_safety"
        ],
        "confidence_weight": 0.9,
        "language": "en",
        "notes": "Microsoft's operational policy framework defining accountability requirements and impact assessment processes for all AI systems across the organization"
      }
    },
    {
      "id": "google-ai-principles-2024",
      "title": "Google AI Principles Progress Update 2024",
      "provider": "google",
      "url": "https://ai.google/static/documents/ai-responsibility-2024-update.pdf",
      "type": "Policy",
      "models": [
        {
          "modelId": "gemini-1-5-pro"
        },
        {
          "modelId": "gemini-3-pro"
        },
        {
          "modelId": "gemini-3-flash"
        },
        {
          "modelId": "gemini-3-deep-think"
        },
        {
          "modelId": "gemini-2.5-flash-lite"
        }
      ],
      "content_metadata": {
        "document_purpose": "policy",
        "signal_strength": "medium",
        "temporal_focus": "mixed",
        "scope": "provider_wide",
        "technical_depth": "shallow",
        "primary_topics": [
          "governance",
          "transparency",
          "red_teaming",
          "safety_benchmarking"
        ],
        "excluded_topics": [
          "cat_model_development"
        ],
        "confidence_weight": 0.7,
        "language": "en",
        "notes": "Annual progress report on Google's AI Principles implementation describing a four-phase responsibility lifecycle framework."
      }
    },
    {
      "id": "anthropic-rsp",
      "title": "Anthropic Responsible Scaling Policy",
      "provider": "anthropic",
      "url": "https://www-cdn.anthropic.com/17310f6d70ae5627f55313ed067afc1a762a4068.pdf",
      "type": "Policy",
      "models": [
        {
          "modelId": "claude-3-opus"
        },
        {
          "modelId": "claude-3-5-sonnet"
        },
        {
          "modelId": "claude-opus-4.5"
        },
        {
          "modelId": "claude-sonnet-4.5"
        },
        {
          "modelId": "claude-haiku-4.5"
        }
      ],
      "content_metadata": {
        "document_purpose": "policy",
        "signal_strength": "high",
        "temporal_focus": "implemented",
        "scope": "provider_wide",
        "technical_depth": "moderate",
        "primary_topics": [
          "governance",
          "safety_benchmarking",
          "red_teaming",
          "security"
        ],
        "excluded_topics": [],
        "confidence_weight": 1.0,
        "language": "en",
        "notes": "Formal risk governance framework defining capability thresholds (CBRN, AI R&D) and corresponding safeguard requirements across ASL levels."
      }
    },
    {
      "id": "openai-preparedness",
      "title": "OpenAI Preparedness Framework",
      "provider": "openai",
      "url": "https://cdn.openai.com/openai-preparedness-framework-beta.pdf",
      "type": "Framework",
      "models": [
        {
          "modelId": "o3-pro"
        },
        {
          "modelId": "o3"
        },
        {
          "modelId": "o4-mini"
        },
        {
          "modelId": "gpt-5-thinking"
        },
        {
          "modelId": "gpt-5.2"
        },
        {
          "modelId": "gpt-5-mini"
        },
        {
          "modelId": "gpt-oss-120b"
        }
      ],
      "content_metadata": {
        "document_purpose": "policy",
        "signal_strength": "high",
        "temporal_focus": "planned",
        "scope": "provider_wide",
        "technical_depth": "moderate",
        "primary_topics": [
          "governance",
          "safety_benchmarking",
          "red_teaming",
          "security",
          "transparency"
        ],
        "excluded_topics": [
          "cat_model_development",
          "cat_harm_classification"
        ],
        "confidence_weight": 0.95,
        "language": "en",
        "notes": "Authoritative framework establishing OpenAI's systematic approach to evaluating and governing catastrophic AI risks through scorecards and safety baselines"
      }
    },
    {
      "id": "meta-llama-responsible-use",
      "title": "Meta Llama 3 Responsible Use Guide",
      "provider": "meta",
      "url": "https://github.com/meta-llama/llama/raw/main/Responsible-Use-Guide.pdf",
      "type": "Guide",
      "models": [
        {
          "modelId": "llama-3-1-405b"
        },
        {
          "modelId": "llama-3-70b"
        },
        {
          "modelId": "llama-4-8b"
        },
        {
          "modelId": "llama-4-17b"
        },
        {
          "modelId": "llama-4-scout"
        },
        {
          "modelId": "llama-4-maverick"
        }
      ],
      "content_metadata": {
        "document_purpose": "policy",
        "signal_strength": "medium",
        "temporal_focus": "implemented",
        "scope": "model_family",
        "technical_depth": "shallow",
        "primary_topics": [
          "transparency",
          "governance",
          "alignment_methods",
          "red_teaming"
        ],
        "excluded_topics": [],
        "confidence_weight": 0.75,
        "language": "en",
        "notes": "Responsible use guide for Llama 2 emphasizing open science philosophy and developer responsibilities for downstream deployment safety"
      }
    },
    {
      "id": "xai-security",
      "title": "xAI Trust & Security",
      "provider": "xai",
      "url": "https://x.ai/security",
      "type": "Policy",
      "models": [
        {
          "modelId": "grok-1-5"
        },
        {
          "modelId": "grok-4"
        },
        {
          "modelId": "grok-4-fast"
        },
        {
          "modelId": "grok-4-thinking"
        }
      ],
      "content_metadata": {
        "document_purpose": "policy",
        "signal_strength": "medium",
        "temporal_focus": "implemented",
        "scope": "provider_wide",
        "technical_depth": "moderate",
        "primary_topics": [
          "security",
          "governance",
          "privacy_protection",
          "transparency"
        ],
        "excluded_topics": [
          "cat_model_development",
          "cat_evaluation",
          "cat_harm_classification"
        ],
        "confidence_weight": 0.75,
        "language": "en",
        "notes": "Provider-wide trust and security policy covering data handling, access control, encryption, and compliance practices for xAI's enterprise platform."
      }
    },
    {
      "id": "deepseek-privacy",
      "title": "DeepSeek Privacy Policy",
      "provider": "deepseek",
      "url": "https://cdn.deepseek.com/policies/en-US/deepseek-privacy-policy.html",
      "type": "Policy",
      "models": [
        {
          "modelId": "deepseek-v3"
        },
        {
          "modelId": "deepseek-r1"
        },
        {
          "modelId": "deepseek-v3.2"
        },
        {
          "modelId": "deepseek-v3-lite"
        },
        {
          "modelId": "deepseek-r1-distill"
        }
      ],
      "content_metadata": {
        "document_purpose": "policy",
        "signal_strength": "medium",
        "temporal_focus": "implemented",
        "scope": "provider_wide",
        "technical_depth": "shallow",
        "primary_topics": [
          "privacy_protection",
          "governance",
          "transparency",
          "security"
        ],
        "excluded_topics": [
          "cat_model_development",
          "cat_evaluation",
          "cat_runtime_safety"
        ],
        "confidence_weight": 0.8,
        "language": "en",
        "notes": "Official privacy policy detailing data collection, usage, and protection practices for DeepSeek services."
      }
    },
    {
      "id": "command-a",
      "title": "Command A Technical Report",
      "provider": "cohere",
      "url": "https://arxiv.org/pdf/2504.00698",
      "type": "Technical Report",
      "date_added": "2026-02-06",
      "models": [
        {
          "modelId": "command-a",
          "name": "Command A"
        }
      ],
      "content_metadata": {
        "document_purpose": "primary_research",
        "signal_strength": "high",
        "temporal_focus": "implemented",
        "scope": "model_family",
        "technical_depth": "deep",
        "primary_topics": [
          "transparency",
          "safety_benchmarking"
        ],
        "excluded_topics": [
          "cat_evaluation"
        ],
        "confidence_weight": 1.0,
        "language": "en",
        "notes": "Technical report detailing Command A and Command R7B architecture, training methodology, and enterprise-focused benchmark performance with minimal safety discussion."
      }
    },
    {
      "id": "gemini-3-pro",
      "title": "Gemini 3 Pro - Model Card",
      "provider": "google",
      "url": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf",
      "type": "Model Card",
      "date_added": "2026-02-06",
      "models": [
        {
          "modelId": "gemini-3-pro",
          "name": "Gemini 3 Pro"
        }
      ],
      "content_metadata": {
        "document_purpose": "system_card",
        "signal_strength": "high",
        "temporal_focus": "implemented",
        "scope": "specific_model",
        "technical_depth": "moderate",
        "primary_topics": [
          "transparency",
          "pre_training_safety",
          "alignment_methods",
          "governance"
        ],
        "excluded_topics": [
          "cat_runtime_safety"
        ],
        "confidence_weight": 0.85,
        "language": "en",
        "notes": "Official model card describing Gemini 3 Pro's architecture, training data sources, and preprocessing approaches with emphasis on transparency."
      }
    },
    {
      "id": "gemini-25-flash-lite",
      "title": "Gemini 2.5 Flash-Lite - Model Card",
      "provider": "google",
      "url": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Flash-Lite-Model-Card.pdf",
      "type": "Model Card",
      "date_added": "2026-02-06",
      "models": [
        {
          "modelId": "gemini-2.5-flash-lite",
          "name": "Gemini 2.5 Flash-Lite"
        }
      ],
      "content_metadata": {
        "document_purpose": "system_card",
        "signal_strength": "high",
        "temporal_focus": "implemented",
        "scope": "specific_model",
        "technical_depth": "moderate",
        "primary_topics": [
          "transparency",
          "pre_training_safety",
          "alignment_methods"
        ],
        "excluded_topics": [
          "cat_runtime_safety"
        ],
        "confidence_weight": 1.0,
        "language": "en",
        "notes": "Official model card for Gemini 2.5 Flash-Lite describing architecture, training data processing including safety filtering, and deployment specifications."
      }
    },
    {
      "id": "grok-4",
      "title": "Grok 4 Model Card",
      "provider": "xai",
      "url": "https://data.x.ai/2025-08-20-grok-4-model-card.pdf",
      "type": "Model Card",
      "date_added": "2026-02-06",
      "models": [
        {
          "modelId": "grok-4",
          "name": "Grok 4"
        },
        {
          "modelId": "grok-4-fast",
          "name": "Grok 4 Fast"
        },
        {
          "modelId": "grok-4-thinking",
          "name": "Grok 4 Thinking"
        }
      ],
      "content_metadata": {
        "document_purpose": "system_card",
        "signal_strength": "high",
        "temporal_focus": "implemented",
        "scope": "specific_model",
        "technical_depth": "moderate",
        "primary_topics": [
          "safety_benchmarking",
          "output_guardrails",
          "red_teaming",
          "alignment_methods",
          "transparency",
          "governance"
        ],
        "excluded_topics": [],
        "confidence_weight": 1.0,
        "language": "en",
        "notes": "Official model card for Grok 4 detailing safety evaluations across abuse potential, concerning propensities, and dual-use capabilities with implemented safeguards."
      }
    },
    {
      "id": "llama-4-maverick",
      "title": "Llama 3 & 4 Safety Protections",
      "provider": "meta",
      "url": "https://www.llama.com/llama-protections/",
      "type": "Website",
      "date_added": "2026-02-06",
      "models": [
        {
          "modelId": "llama-3-70b",
          "name": "Llama 3 70B"
        },
        {
          "modelId": "llama-4-8b",
          "name": "Llama 4 8B"
        },
        {
          "modelId": "llama-4-17b",
          "name": "Llama 4 17B"
        },
        {
          "modelId": "llama-4-scout",
          "name": "Llama 4 Scout"
        },
        {
          "modelId": "llama-4-maverick",
          "name": "Llama 4 Maverick"
        }
      ],
      "content_metadata": {
        "document_purpose": "documentation",
        "signal_strength": "medium",
        "temporal_focus": "implemented",
        "scope": "model_family",
        "technical_depth": "moderate",
        "primary_topics": [
          "input_guardrails",
          "output_guardrails",
          "runtime_safety",
          "security",
          "transparency"
        ],
        "excluded_topics": [
          "cat_model_development",
          "cat_harm_classification",
          "cat_governance"
        ],
        "confidence_weight": 0.75,
        "language": "en",
        "notes": "Developer-focused documentation of Meta's protection toolkit for Llama models including guard models and security tools."
      }
    },
    {
      "id": "mistral-large-3",
      "title": "Mistral Guardrailing Capabilities",
      "provider": "mistral",
      "url": "https://docs.mistral.ai/capabilities/guardrailing",
      "type": "Documentation",
      "date_added": "2026-02-06",
      "models": [
        {
          "modelId": "mistral-large-3",
          "name": "Mistral Large 3"
        },
        {
          "modelId": "ministral-3",
          "name": "Ministral 3"
        }
      ],
      "content_metadata": {
        "document_purpose": "documentation",
        "signal_strength": "high",
        "temporal_focus": "implemented",
        "scope": "provider_wide",
        "technical_depth": "moderate",
        "primary_topics": [
          "output_guardrails",
          "input_guardrails",
          "runtime_safety",
          "privacy_protection"
        ],
        "excluded_topics": [
          "cat_model_development",
          "cat_evaluation"
        ],
        "confidence_weight": 0.85,
        "language": "en",
        "notes": "Official API documentation for Mistral's moderation endpoints and system prompt guardrailing capabilities with implementation examples."
      }
    },
    {
      "id": "qwen3-max",
      "title": "Qwen3Guard Technical Report",
      "provider": "alibaba",
      "url": "https://arxiv.org/pdf/2510.14276v1",
      "type": "Technical Report",
      "date_added": "2026-02-06",
      "models": [
        {
          "modelId": "qwen3-max",
          "name": "Qwen3-Max"
        },
        {
          "modelId": "qwen3-turbo",
          "name": "Qwen3-Turbo"
        }
      ],
      "content_metadata": {
        "document_purpose": "primary_research",
        "signal_strength": "high",
        "temporal_focus": "implemented",
        "scope": "model_family",
        "technical_depth": "deep",
        "primary_topics": [
          "output_guardrails",
          "input_guardrails",
          "runtime_safety",
          "safety_benchmarking",
          "alignment_methods"
        ],
        "excluded_topics": [
          "cat_governance"
        ],
        "confidence_weight": 1.0,
        "language": "en",
        "notes": "Technical report introducing Qwen3Guard safety guardrail models with novel generative and streaming variants for multilingual content moderation."
      }
    },
    {
      "id": "falcon-series-paper",
      "title": "The Falcon Series of Open Language Models",
      "provider": "tii",
      "url": "https://arxiv.org/pdf/2311.16867",
      "type": "Technical Report",
      "date_added": "2026-02-16",
      "models": [
        {
          "modelId": "falcon-180b",
          "name": "Falcon 180B"
        },
        {
          "modelId": "falcon-3",
          "name": "Falcon 3"
        }
      ],
      "content_metadata": {
        "document_purpose": "technical_report",
        "signal_strength": "high",
        "temporal_focus": "implemented",
        "scope": "model_family",
        "technical_depth": "high",
        "primary_topics": [],
        "excluded_topics": [],
        "confidence_weight": 1.0,
        "language": "en",
        "notes": "Covers Falcon 7B/40B/180B pretraining, data curation (RefinedWeb), and evaluation. Falcon 3 is not covered (released later)."
      }
    },
    {
      "id": "magistral-paper",
      "title": "Magistral Technical Report",
      "provider": "mistral",
      "url": "https://arxiv.org/pdf/2506.10910",
      "type": "Technical Report",
      "date_added": "2026-02-16",
      "models": [
        {
          "modelId": "magistral-medium-1.2",
          "name": "Magistral Medium 1.2"
        }
      ],
      "content_metadata": {
        "document_purpose": "technical_report",
        "signal_strength": "high",
        "temporal_focus": "implemented",
        "scope": "model_family",
        "technical_depth": "high",
        "primary_topics": [],
        "excluded_topics": [],
        "confidence_weight": 1.0,
        "language": "en",
        "notes": "Covers Magistral Small (24B) and Medium. Details RL pipeline and reasoning capabilities."
      }
    },
    {
      "id": "qwen3-tech-report",
      "title": "Qwen3 Technical Report",
      "provider": "alibaba",
      "url": "https://arxiv.org/pdf/2505.09388",
      "type": "Technical Report",
      "date_added": "2026-02-16",
      "models": [
        {
          "modelId": "qwen3-thinking",
          "name": "Qwen3-Thinking"
        },
        {
          "modelId": "qwen3-turbo",
          "name": "Qwen3-Turbo"
        },
        {
          "modelId": "qwen3-max",
          "name": "Qwen3-Max"
        }
      ],
      "content_metadata": {
        "document_purpose": "technical_report",
        "signal_strength": "high",
        "temporal_focus": "implemented",
        "scope": "model_family",
        "technical_depth": "high",
        "primary_topics": [],
        "excluded_topics": [],
        "confidence_weight": 1.0,
        "language": "en",
        "notes": "Covers entire Qwen3 series (0.6B-235B), including hybrid thinking/non-thinking mode, RL training, and multilingual support."
      }
    }
  ]
}