[
  {
    "providerId": "anthropic",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Constitutional training data with filtered corpora designed to reduce harmful content and improve model alignment",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "policy",
        "lastVerified": "2025-11-12",
        "sourceHash": "c2b1daa7f1648a074c2e610bb763bf42db3319c2cfd5a3b23e29294516090918",
        "relevantSection": "Safety and Security Standards"
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Specific filtering methods not detailed"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Part of Constitutional AI framework",
    "id": "ev-anthropic-0002"
  },
  {
    "providerId": "anthropic",
    "techniqueId": "tech-constitutional-ai",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Self-critique training using constitutional principles for helpful, harmless, honest behavior with scalable oversight",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2212.08073",
        "documentType": "research-paper",
        "lastVerified": "2025-11-12",
        "sourceHash": "9a456a07ad346e3372f9867d346f69f5b0f68b4c65f060aca0b8a13fa9d98e83",
        "relevantSection": "Section 3: Constitutional AI"
      }
    ],
    "implementationDate": "2022-12-15",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "evaluationMetrics": [
      {
        "metric": "human_preference_rate",
        "value": 76,
        "unit": "percent",
        "benchmarkContext": {
          "name": "Constitutional AI Eval",
          "version": "v1",
          "url": "https://arxiv.org/abs/2212.08073"
        }
      }
    ],
    "knownLimitations": [
      "May be overly conservative",
      "Principles require careful design"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Core safety innovation from Anthropic",
    "id": "ev-anthropic-0003"
  },
  {
    "providerId": "anthropic",
    "techniqueId": "tech-rlhf",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Constitutional AI approach combining self-critique with RLHF for scalable oversight and preference learning",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2212.08073",
        "documentType": "research-paper",
        "lastVerified": "2025-11-12",
        "sourceHash": "9a456a07ad346e3372f9867d346f69f5b0f68b4c65f060aca0b8a13fa9d98e83",
        "relevantSection": "Section 4: Training Process"
      }
    ],
    "implementationDate": "2022-12-15",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Subject to annotator biases",
      "Computationally expensive"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Combined with Constitutional AI for enhanced safety",
    "id": "ev-anthropic-0004"
  },
  {
    "providerId": "google",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Multi-lingual safety filtering and bias detection in training data preparation for Gemini models",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "3476973fc521f3590d2132ce1a804e9e39ced083d4714765626cdc5f0c44bf61",
        "relevantSection": "Training Data Safety"
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Specific methods not detailed"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "EU AI Act"
    ],
    "notes": "Focus on multilingual safety",
    "id": "ev-google-0005"
  },
  {
    "providerId": "google",
    "techniqueId": "tech-rlhf",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "B",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "RLHF with adversarial safety tuning datasets and Sparrow-style critiquing methodology",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2209.14375",
        "documentType": "research-paper",
        "lastVerified": "2025-11-12",
        "sourceHash": "e7df8fc1e41dfc3b47a781958fc53e6467f3b0ba3b0c10db5040f7924097709a",
        "relevantSection": "Section 3: Training Sparrow"
      }
    ],
    "implementationDate": "2022-09-29",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Limited to English initially"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Based on Sparrow research",
    "id": "ev-google-0006"
  },
  {
    "providerId": "meta",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Open training with safety benchmarks and Llama Guard integration for content filtering",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-11-12",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": "Section 4: Safety"
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Community-dependent verification"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Open source approach enables community verification",
    "id": "ev-meta-0007"
  },
  {
    "providerId": "meta",
    "techniqueId": "tech-rlhf",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Two-phase RLHF with community-driven safety feedback and open source evaluation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-11-12",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": "Section 3.3: Fine-tuning"
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Resource intensive",
      "Community feedback quality varies"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Two-phase approach with safety-specific rewards",
    "id": "ev-meta-0008"
  },
  {
    "providerId": "meta",
    "techniqueId": "tech-input-classification",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Llama Guard as separate safety classifier for input content with open source implementation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "research-paper",
        "lastVerified": "2025-11-12",
        "sourceHash": "2bab1e098cc626c8adda035af69cb03f224291ccea3de94456b6938c31617e54",
        "relevantSection": "Section 2: Llama Guard"
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Requires separate model inference"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Open source safety classifier",
    "id": "ev-meta-0009"
  },
  {
    "providerId": "amazon",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "B",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Advanced PII detection and redaction through Bedrock Guardrails with enterprise-grade protection",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails-sensitive-filters.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "2e1b15bc85fc8b37e81960cb9f302cc4c3e1a235df00a026518e0bc7efdb33fd",
        "relevantSection": "Sensitive Information Filters"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Language support varies",
      "Context-dependent PII challenging"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "HIPAA",
      "PCI-DSS"
    ],
    "notes": "Enterprise-grade PII protection",
    "id": "ev-amazon-0010"
  },
  {
    "providerId": "amazon",
    "techniqueId": "tech-input-classification",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Bedrock Guardrails input classification with customizable policies and enterprise integration",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": "Content Filters"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Requires configuration",
      "May have false positives"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Highly configurable for enterprise needs",
    "id": "ev-amazon-0011"
  },
  {
    "providerId": "amazon",
    "techniqueId": "tech-output-filtering",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Bedrock Guardrails output filtering with hallucination detection and content policy enforcement",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": "Output Moderation"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "May alter outputs",
      "Hallucination detection has limits"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Includes hallucination detection",
    "id": "ev-amazon-0012"
  },
  {
    "providerId": "anthropic",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "External red team engagement as part of responsible scaling policy and AI Safety Level assessments",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "policy",
        "lastVerified": "2025-11-12",
        "sourceHash": "fd1f8804b2017d40df74407e447fdec53a9d7c0f0316349887d681a609fc0721",
        "relevantSection": "AI Safety Levels"
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Specific findings not always public"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Part of ASL framework",
    "id": "ev-anthropic-0013"
  },
  {
    "providerId": "anthropic",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Responsible scaling policy and constitutional AI research provide comprehensive safety framework documentation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "policy",
        "lastVerified": "2025-11-12",
        "sourceHash": "2b3fd2f2558b40730bd569a214fdca253a3e14d9d9817eaaf3d34b2d4a4c0c08",
        "relevantSection": "Full Document"
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P12M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Industry-leading transparency",
    "id": "ev-anthropic-0014"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-csam-detection",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Automated detection and removal of child sexual abuse material using specialized classifiers during pre-training data preparation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://openai.com/policies/usage-policies",
        "documentType": "policy",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "Prohibited Usage"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Detection rates not disclosed"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "NCMEC"
    ],
    "notes": "Part of comprehensive content filtering",
    "id": "ev-openai-0003"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-copyright-filtering",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Fingerprinting system to remove opted-out images from training data, building on DALL-E 3 opt-out mechanism",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-12",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Section 2.1"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Only for opted-out content"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "DMCA"
    ],
    "notes": "Extends DALL-E 3 opt-out system",
    "id": "ev-openai-0004"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-bias-detection-training",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Advanced data filtering processes to reduce biased content, though specific bias detection methods not fully detailed",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-12",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Safety Evaluations"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Specific methods not disclosed"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0005"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Advanced data filtering processes to reduce personal information from training data using automated detection systems",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-12",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Data Processing"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Cannot catch all PII"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "GDPR",
      "CCPA"
    ],
    "notes": "",
    "id": "ev-openai-0006"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-adversarial-training",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Red team data integration and adversarial testing during training, though specific methods not detailed",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-12",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Red Teaming"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Methods not fully disclosed"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0007"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-red-team-data",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "100+ external red teamers across 45 languages and 29 countries, data integrated into training process",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-12",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "External Red Teaming"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Extensive red team network",
    "id": "ev-openai-0008"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-input-classification",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Layered policy engine with system prompt \u2192 model \u2192 content filter pipeline, including specialized voice classifiers",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-12",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Safety Pipeline"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Multi-layer approach",
    "id": "ev-openai-0009"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-output-filtering",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Multi-stage content filtering with moderation API applied to both text and audio outputs",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-12",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Output Moderation"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Includes audio moderation",
    "id": "ev-openai-0010"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "System prompt protections and multi-layer filtering, though specific prompt injection defenses not detailed",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-12",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Safety Mitigations"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Specific defenses not disclosed"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0011"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Real-time monitoring and enforcement with product-level mitigations including streaming audio analysis",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-12",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Real-time Voice"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Includes voice monitoring",
    "id": "ev-openai-0012"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-contextual-safety",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Context-aware safety evaluation, particularly for voice interactions, though implementation not detailed",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-12",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Voice Safety"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Implementation details limited"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0013"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Comprehensive safety pipeline spanning pre-training, post-training, product development, and policy enforcement",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-12",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Safety Architecture"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "End-to-end approach",
    "id": "ev-openai-0014"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "PII detection capabilities integrated into content filtering systems for personal information protection",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://openai.com/policies/usage-policies",
        "documentType": "policy",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "Privacy"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Details not specified"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "GDPR",
      "CCPA"
    ],
    "notes": "",
    "id": "ev-openai-0015"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Usage policies and moderation tools provided to users, with transparency reports and configurable settings",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://openai.com/policies/usage-policies",
        "documentType": "policy",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "Usage Policies"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Limited configurability"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0016"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-audit-logging",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Usage monitoring and incident reporting systems for tracking and analyzing safety incidents",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-12",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Monitoring"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "SOC2"
    ],
    "notes": "",
    "id": "ev-openai-0017"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Preparedness Framework with pre-defined capability thresholds and deployment decisions based on risk assessments",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/openai-preparedness-framework-beta.pdf",
        "documentType": "policy",
        "lastVerified": "2025-11-12",
        "sourceHash": "c84e3a59c7dab251e45434e0b0d3e8abadcea7293f995cf92d32269e7d290398",
        "relevantSection": "Full Document"
      }
    ],
    "implementationDate": "2023-10-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Industry-leading framework",
    "id": "ev-openai-0018"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-safety-advisory",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Safety Advisory Group providing independent oversight and recommendations on deployment decisions",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-12",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Governance"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P12M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0019"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-incident-reporting",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": true
    },
    "summary": "Systematic incident reporting and analysis with internal tracking and external disclosure mechanisms",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-12",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Incident Response"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0020"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": true
    },
    "summary": "Comprehensive usage monitoring with analytics for detecting patterns of misuse and safety incidents",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-12",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Usage Analytics"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0021"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Compliance with voluntary White House commitments and development of internal governance frameworks",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://openai.com/index/our-approach-to-ai-safety",
        "documentType": "blog-post",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "Commitments"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "White House Commitments"
    ],
    "notes": "",
    "id": "ev-openai-0022"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Collaboration with academic institutions and independent research organizations for safety evaluation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-12",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "External Collaboration"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P12M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0023"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-model-cards",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Technical documentation including model architecture, training methodology, and safety evaluation results",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-12",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Full Document"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P12M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Comprehensive system card",
    "id": "ev-openai-0024"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Regular publication of safety research, evaluation methodologies, and lessons learned from deployment",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://openai.com/research",
        "documentType": "research-paper",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "Safety Research"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P12M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0025"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Comprehensive usage policies, terms of service, and compliance documentation publicly available",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://openai.com/policies",
        "documentType": "policy",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "All Policies"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0026"
  },
  {
    "providerId": "google",
    "techniqueId": "tech-watermarking",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": true
    },
    "summary": "SynthID watermarking technology for AI-generated image and audio content identification",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/science/synthid/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "a9557656d413af8dd20cc5445b9f542d4593013463aab4acad809b2ecb6e76b4",
        "relevantSection": "Technology Overview"
      }
    ],
    "implementationDate": "2023-08-29",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Limited to certain content types"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Industry-leading watermarking",
    "id": "ev-google-0003"
  },
  {
    "providerId": "google",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "EU AI Act compliance measures with transparency registers and regulatory reporting mechanisms",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://blog.google/technology/ai/google-ai-act-preparation/",
        "documentType": "blog-post",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "Compliance Measures"
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "EU AI Act"
    ],
    "notes": "Proactive compliance",
    "id": "ev-google-0004"
  },
  {
    "providerId": "google",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Multi-stage safety layers including toxicity detection, policy checks, and SynthID watermarking",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "3476973fc521f3590d2132ce1a804e9e39ced083d4714765626cdc5f0c44bf61",
        "relevantSection": "Safety Architecture"
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-google-0005"
  },
  {
    "providerId": "google",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Academic partnerships for AI safety research and independent evaluation of safety measures",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/research/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "16c1c3e104dfacd5f00f32ddddeb5cee8eb724f818cfc07ab0b21bd6302698a8",
        "relevantSection": "Collaborations"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P12M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-google-0006"
  },
  {
    "providerId": "meta",
    "techniqueId": "tech-output-filtering",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Llama Guard output filtering with contextual moderation and open source validation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "research-paper",
        "lastVerified": "2025-11-12",
        "sourceHash": "21781a6744f1b7c075ddfc4ad9084ef9a3149fba94635053e947ff5fac7041ec",
        "relevantSection": "Output Moderation"
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Requires separate inference"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Open source implementation",
    "id": "ev-meta-0004"
  },
  {
    "providerId": "meta",
    "techniqueId": "tech-bias-detection-training",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "B",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Bias detection and mitigation with community-driven evaluation and open source validation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-11-12",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": "Section 5.2: Bias Evaluation"
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Community-dependent validation"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-meta-0005"
  },
  {
    "id": "ev-openai-0027",
    "providerId": "openai",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Systematic evaluation protocols for dangerous capabilities including cybersecurity, CBRN, persuasion, and autonomy",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-12",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-openai-0028",
    "providerId": "openai",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Systematic red team exercises across multiple phases with diverse expert networks and real-world testing scenarios",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-12",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-openai-0031",
    "providerId": "openai",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Detailed system cards providing comprehensive safety evaluations, methodologies, and results for each model release",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-11-12",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-anthropic-0005",
    "providerId": "anthropic",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Personal information filtering as part of constitutional training data preparation",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/claude-3-model-card",
        "documentType": "system-card",
        "lastVerified": "2025-11-12",
        "sourceHash": "88ae851f53c3034d436816164ce49a876b333fa9b550fb7ef29838182b59ba7d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-03-04",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0006",
    "providerId": "anthropic",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Compliance with emerging AI regulations and industry standards through responsible scaling policy",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "9ed0de7406221991b2177a64ddbf85c55a17b7f8cc413aa0c07a78fda14820b9",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0009",
    "providerId": "anthropic",
    "techniqueId": "tech-safety-reward-modeling",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Safety considerations integrated into reward modeling as part of constitutional AI framework",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2212.08073",
        "documentType": "research-paper",
        "lastVerified": "2025-11-12",
        "sourceHash": "9a456a07ad346e3372f9867d346f69f5b0f68b4c65f060aca0b8a13fa9d98e83",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2022-12-15",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0010",
    "providerId": "anthropic",
    "techniqueId": "tech-adversarial-training",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Adversarial testing integrated into constitutional AI training process for robustness",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2212.08073",
        "documentType": "research-paper",
        "lastVerified": "2025-11-12",
        "sourceHash": "9a456a07ad346e3372f9867d346f69f5b0f68b4c65f060aca0b8a13fa9d98e83",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2022-12-15",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBC"
  },
  {
    "id": "ev-anthropic-0011",
    "providerId": "anthropic",
    "techniqueId": "tech-red-team-data",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Red team exercises and data integration as part of responsible scaling policy and safety evaluation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "75b291e472398319dca4abaa4fdc53e36d2d689fa5abe6679382b9402da6a7b4",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-anthropic-0012",
    "providerId": "anthropic",
    "techniqueId": "tech-input-classification",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Content classification systems for input filtering, though specific implementation details not public",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/claude-3-model-card",
        "documentType": "system-card",
        "lastVerified": "2025-11-12",
        "sourceHash": "88ae851f53c3034d436816164ce49a876b333fa9b550fb7ef29838182b59ba7d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-03-04",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0015",
    "providerId": "anthropic",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Safety monitoring systems in place, though specific real-time implementation details not disclosed",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/claude-3-model-card",
        "documentType": "system-card",
        "lastVerified": "2025-11-12",
        "sourceHash": "88ae851f53c3034d436816164ce49a876b333fa9b550fb7ef29838182b59ba7d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-03-04",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0016",
    "providerId": "anthropic",
    "techniqueId": "tech-contextual-safety",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Constitutional AI enables sophisticated contextual safety assessment through principle-based reasoning",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2212.08073",
        "documentType": "research-paper",
        "lastVerified": "2025-11-12",
        "sourceHash": "9a456a07ad346e3372f9867d346f69f5b0f68b4c65f060aca0b8a13fa9d98e83",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2022-12-15",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-anthropic-0017",
    "providerId": "anthropic",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive safety pipeline including constitutional training, RLHF, and responsible scaling evaluation",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "a17dfc825ae25fca0209c79cd30815a48ee08b6f39f0d01e1dc99bf8fa4b490c",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-anthropic-0018",
    "providerId": "anthropic",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "PII protection mechanisms integrated into constitutional AI framework",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/claude-3-model-card",
        "documentType": "system-card",
        "lastVerified": "2025-11-12",
        "sourceHash": "88ae851f53c3034d436816164ce49a876b333fa9b550fb7ef29838182b59ba7d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-03-04",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0019",
    "providerId": "anthropic",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Constitutional principles provide framework for configurable safety responses",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2212.08073",
        "documentType": "research-paper",
        "lastVerified": "2025-11-12",
        "sourceHash": "9a456a07ad346e3372f9867d346f69f5b0f68b4c65f060aca0b8a13fa9d98e83",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2022-12-15",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0020",
    "providerId": "anthropic",
    "techniqueId": "tech-audit-logging",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Audit and monitoring capabilities as part of responsible scaling policy framework",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "9ca983833bcaaeb44be160ce317087aea6e674acb6cbb623d71372ecc496fbd9",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0021",
    "providerId": "anthropic",
    "techniqueId": "tech-watermarking",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "B",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Research into watermarking techniques for AI-generated content detection and provenance",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "ebeaeab563e4389b7a239cf2e2537285a8b25fd46b5326edf53ab04737e339c4",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MRC"
  },
  {
    "id": "ev-anthropic-0023",
    "providerId": "anthropic",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "AI Safety Level (ASL) framework with clear classifications and deployment thresholds",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "1c120c8f33da1baaff81137f9601e65dfa902f3a9ff59fd594f6938901676b64",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-anthropic-0024",
    "providerId": "anthropic",
    "techniqueId": "tech-safety-advisory",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Independent safety advisory structure as part of responsible scaling policy governance",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "1184eb333a4380f90209f828b7c0f44ab954c7d2e6ead1600d3b079eee528108",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-anthropic-0025",
    "providerId": "anthropic",
    "techniqueId": "tech-incident-reporting",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Incident reporting and analysis systems integrated into responsible scaling framework",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "ab1d178b72bd7d3559f72f3bdddebf91d25527be978313e92e79cc6bd30cc8a1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-anthropic-0026",
    "providerId": "anthropic",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Usage monitoring capabilities for safety assessment and responsible scaling decisions",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "e512a269f2901dfcc53a96e5744668a9c703057ce32f635b3ae16034cc1b42b7",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0027",
    "providerId": "anthropic",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Systematic capability evaluation protocols as part of ASL framework and responsible scaling",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "27cecbedc08ca668dbf2866454f75dd8fbc29d4a4ac98e38e02c988f9223679c",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-anthropic-0028",
    "providerId": "anthropic",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive red team exercises for capability assessment and safety evaluation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "72321e460846381ce916d8aae40187b6ecb7f23083ca63aa43c67cf4fe2d19d0",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-anthropic-0029",
    "providerId": "anthropic",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Proactive regulatory compliance through responsible scaling policy and industry engagement",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "3ca9fbf7920b73c609a93e98081ef56bc75cf12c9173f2caeef8a0fe241ccd0d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-anthropic-0030",
    "providerId": "anthropic",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Academic collaborations for safety research and constitutional AI development",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/research",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "369dade302dd0754cc00cf4d94ae842f9630353823955282f64ba43429e19072",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-anthropic-0032",
    "providerId": "anthropic",
    "techniqueId": "tech-model-cards",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Model cards available for Claude models with technical specifications and safety information",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/claude-3-model-card",
        "documentType": "system-card",
        "lastVerified": "2025-11-12",
        "sourceHash": "88ae851f53c3034d436816164ce49a876b333fa9b550fb7ef29838182b59ba7d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-03-04",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-anthropic-0033",
    "providerId": "anthropic",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Extensive publication of constitutional AI research and safety methodologies",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/research",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "1d999d7e61b12242dd6eafc0f0091834e4c2c1482c100993db8724a87b83bb1b",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-anthropic-0034",
    "providerId": "anthropic",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive policy documentation including responsible scaling policy and usage guidelines",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "df6e47b59659e737cdb7d47274515a4ddb508531fe4fe8a80e23b992d1411b2b",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-google-0002",
    "providerId": "google",
    "techniqueId": "tech-csam-detection",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "CSAM detection and removal systems implemented as part of standard content filtering pipeline",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "3476973fc521f3590d2132ce1a804e9e39ced083d4714765626cdc5f0c44bf61",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0008",
    "providerId": "google",
    "techniqueId": "tech-constitutional-ai",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "B",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Research into constitutional AI principles and self-critique mechanisms for Gemini safety",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "3476973fc521f3590d2132ce1a804e9e39ced083d4714765626cdc5f0c44bf61",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MRC"
  },
  {
    "id": "ev-google-0009",
    "providerId": "google",
    "techniqueId": "tech-safety-reward-modeling",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Safety considerations integrated into reward modeling for Gemini training optimization",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "3476973fc521f3590d2132ce1a804e9e39ced083d4714765626cdc5f0c44bf61",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0010",
    "providerId": "google",
    "techniqueId": "tech-adversarial-training",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Adversarial safety tuning datasets used in RLHF process for robustness improvement",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2209.14375",
        "documentType": "research-paper",
        "lastVerified": "2025-11-12",
        "sourceHash": "e7df8fc1e41dfc3b47a781958fc53e6467f3b0ba3b0c10db5040f7924097709a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2022-09-29",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBC"
  },
  {
    "id": "ev-google-0011",
    "providerId": "google",
    "techniqueId": "tech-red-team-data",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Red team exercises and data integration for Gemini safety evaluation and improvement",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "3476973fc521f3590d2132ce1a804e9e39ced083d4714765626cdc5f0c44bf61",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0012",
    "providerId": "google",
    "techniqueId": "tech-input-classification",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Multi-stage safety layer including toxicity and content classification for input processing",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "3476973fc521f3590d2132ce1a804e9e39ced083d4714765626cdc5f0c44bf61",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0013",
    "providerId": "google",
    "techniqueId": "tech-output-filtering",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Output content filtering with toxicity classifiers and safety policy enforcement",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "3476973fc521f3590d2132ce1a804e9e39ced083d4714765626cdc5f0c44bf61",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0014",
    "providerId": "google",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic prompt injection protection through input filtering and safety classifiers",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "3476973fc521f3590d2132ce1a804e9e39ced083d4714765626cdc5f0c44bf61",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBC"
  },
  {
    "id": "ev-google-0015",
    "providerId": "google",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Real-time safety monitoring capabilities integrated into Gemini deployment infrastructure",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "3476973fc521f3590d2132ce1a804e9e39ced083d4714765626cdc5f0c44bf61",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0016",
    "providerId": "google",
    "techniqueId": "tech-contextual-safety",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Contextual safety assessment capabilities, though specific implementation details not disclosed",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "3476973fc521f3590d2132ce1a804e9e39ced083d4714765626cdc5f0c44bf61",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBC"
  },
  {
    "id": "ev-google-0018",
    "providerId": "google",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "PII detection and redaction capabilities integrated into safety pipeline",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "3476973fc521f3590d2132ce1a804e9e39ced083d4714765626cdc5f0c44bf61",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0019",
    "providerId": "google",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Configurable safety policies and content filtering options for different deployment contexts",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "3476973fc521f3590d2132ce1a804e9e39ced083d4714765626cdc5f0c44bf61",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0020",
    "providerId": "google",
    "techniqueId": "tech-audit-logging",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Audit logging capabilities for safety incident tracking and regulatory compliance",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://blog.google/technology/ai/google-ai-act-preparation/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0022",
    "providerId": "google",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "External red team engagement for Gemini safety evaluation and testing",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "3476973fc521f3590d2132ce1a804e9e39ced083d4714765626cdc5f0c44bf61",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0023",
    "providerId": "google",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Internal safety classification system for model capabilities and deployment decisions",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "3476973fc521f3590d2132ce1a804e9e39ced083d4714765626cdc5f0c44bf61",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0024",
    "providerId": "google",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Capability evaluation protocols for dangerous capabilities and safety assessment",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "3476973fc521f3590d2132ce1a804e9e39ced083d4714765626cdc5f0c44bf61",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0025",
    "providerId": "google",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Red team exercises for capability discovery and safety evaluation across multiple domains",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "3476973fc521f3590d2132ce1a804e9e39ced083d4714765626cdc5f0c44bf61",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0026",
    "providerId": "google",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive regulatory compliance frameworks including EU AI Act preparation and transparency measures",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://blog.google/technology/ai/google-ai-act-preparation/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-google-0028",
    "providerId": "google",
    "techniqueId": "tech-model-cards",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Model cards and technical documentation for Gemini models with safety information",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/gemini/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "1c2dff39c0f18a6ac6a047592666242a20571036baa1de097fd7a0747733a37b",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-meta-0002",
    "providerId": "meta",
    "techniqueId": "tech-csam-detection",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "CSAM detection and removal processes integrated into training data preparation",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "f2857f890ad959ad3c64c27dfa0ea4354aee3c78c50355883a4d619623584aa4",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0003",
    "providerId": "meta",
    "techniqueId": "tech-copyright-filtering",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Copyright filtering mechanisms for training data with open source transparency",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-11-12",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0006",
    "providerId": "meta",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic regulatory compliance measures with limited international regulatory integration",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "7806e707965463efb830bc5c71a77a52f03eac29ee32fd0eceff8a4d88460394",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPC"
  },
  {
    "id": "ev-meta-0010",
    "providerId": "meta",
    "techniqueId": "tech-community-feedback",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community-driven safety feedback with open source evaluation harness and academic partnerships",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "2775d64aaa2bf90020d176bccf66195b4ade2c65f695fef4209c93e01adfe433",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPV"
  },
  {
    "id": "ev-meta-0013",
    "providerId": "meta",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic prompt injection protection through Llama Guard classification and community testing",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "c7c0c326532544cc091727fd441e0f8118e054666fccb863b5b0f23426027daa",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBC"
  },
  {
    "id": "ev-meta-0014",
    "providerId": "meta",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Real-time safety monitoring capabilities through Llama Guard integration",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "034912ebc0f929c24bcdbe09a833e9ad950fcf30ddf056ae10e315c56a9af9d0",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0015",
    "providerId": "meta",
    "techniqueId": "tech-contextual-safety",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Contextual moderation capabilities through Llama Guard classification system",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "38ea9b94763566ccb64cdec3e45e8fca7505d990740c6a064a82b3d2dfb1fe13",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBC"
  },
  {
    "id": "ev-meta-0016",
    "providerId": "meta",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Multi-stage safety pipeline with Llama Guard integration and community validation",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-11-12",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0017",
    "providerId": "meta",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "PII detection capabilities integrated into Llama Guard classification system",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "5f3df025a7bf442e366a8538dbdbca1e799147ab7f82fd6e24770ad138de02f3",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0018",
    "providerId": "meta",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Configurable safety policies through open source Llama Guard implementation",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "3c116b2c05176409b258fc580d164333a328f8a90eaf8f217fc61392767be879",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0019",
    "providerId": "meta",
    "techniqueId": "tech-audit-logging",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic audit logging capabilities with open source transparency and community oversight",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "be4eefaf8de84d7b2210e083ee5766b7bc5b7a09afecaed469129d0cbbff7c9f",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0020",
    "providerId": "meta",
    "techniqueId": "tech-opensource-tools",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive open source safety tools including Llama Guard and evaluation frameworks",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://github.com/meta-llama",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "c515d92929cb39c5e8427dcaa1e574e488cd0071de1813acf70b000165bff91b",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-meta-0021",
    "providerId": "meta",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community-driven red team networks with academic partnerships and open evaluation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-11-12",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBV"
  },
  {
    "id": "ev-meta-0022",
    "providerId": "meta",
    "techniqueId": "tech-responsible-release",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Responsible release checklist with community evaluation and academic partnership validation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "24806e498d097181f80ad32a6c8c1574ff6fef82e4bbaddbd2805d35c24cd562",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-meta-0023",
    "providerId": "meta",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Extensive academic partnerships for safety evaluation and community-driven research",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "32a8656a37e240c784bd19ef549c0964b307a2f24d8a95a3105a474623735c10",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-meta-0024",
    "providerId": "meta",
    "techniqueId": "tech-safety-benchmarks",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Open safety benchmarks and evaluation metrics with community validation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-11-12",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-meta-0025",
    "providerId": "meta",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community-driven capability evaluation protocols with open source validation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-11-12",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBV"
  },
  {
    "id": "ev-meta-0026",
    "providerId": "meta",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community-driven red team exercises with academic partnerships and open evaluation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-11-12",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBV"
  },
  {
    "id": "ev-meta-0027",
    "providerId": "meta",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic regulatory compliance frameworks with open source transparency",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "58f83f0a332b2901bbc99eb8d28a39aa876c0c187c2cc5215e64a3021faa10b0",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0028",
    "providerId": "meta",
    "techniqueId": "tech-community-governance",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Community governance model with open source development and academic oversight",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "e46bb0fd36789952cc60ccc374d0eae02ec6fd9688e2be08bc400d575417fcbc",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-meta-0029",
    "providerId": "meta",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Open safety documentation with research papers and community evaluation results",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-11-12",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-meta-0030",
    "providerId": "meta",
    "techniqueId": "tech-model-cards",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Open model cards and technical specifications with community validation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "fe884e3146a22f8473194de9216a297356b4c93d04e509df600756a9ee62a0c6",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-meta-0031",
    "providerId": "meta",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Extensive safety research publications with peer review and community validation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "3bca60a0b570c471418c87b15eaa8a9e11cd7995abf01ba53973516001f2c705",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-meta-0032",
    "providerId": "meta",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Open policy and compliance documentation with community feedback integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "46e958f5aa5a03236b565c85e29162b0681be64419d2d6c6ed78ca727acff626",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-meta-0033",
    "providerId": "meta",
    "techniqueId": "tech-community-evaluation",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Open community evaluation frameworks with academic partnerships and peer review",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "e82b1d5739be256d129a4bbea8dc642c233e789d212586a21b1565b64a352e84",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0001",
    "providerId": "amazon",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [
      "titan-express"
    ],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise-focused training data curation with customer data isolation and basic filtering",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "9efac3b7025e270277bf5a83d228de2c4326c5ee8216f5180b5c243d3582a659",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-amazon-0002",
    "providerId": "amazon",
    "techniqueId": "tech-csam-detection",
    "modelIds": [
      "titan-express"
    ],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Standard CSAM detection integrated into Bedrock platform with enterprise compliance",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-amazon-0003",
    "providerId": "amazon",
    "techniqueId": "tech-copyright-filtering",
    "modelIds": [
      "titan-express"
    ],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic copyright filtering with enterprise compliance and customer-configurable policies",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-amazon-0004",
    "providerId": "amazon",
    "techniqueId": "tech-bias-detection-training",
    "modelIds": [
      "titan-express"
    ],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited bias detection capabilities with enterprise compliance focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-amazon-0006",
    "providerId": "amazon",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise regulatory compliance frameworks with industry-specific guardrails",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://aws.amazon.com/compliance/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "f4ac89283c78b0c417484c97d570582cc8f754e5d8f4f3e109735fd50a9492ea",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0007",
    "providerId": "amazon",
    "techniqueId": "tech-rlhf",
    "modelIds": [
      "titan-express"
    ],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic RLHF with customer fine-tuning options and domain-specific safety optimization",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "9efac3b7025e270277bf5a83d228de2c4326c5ee8216f5180b5c243d3582a659",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-amazon-0008",
    "providerId": "amazon",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Customer fine-tuning options with domain-specific safety configurations and enterprise controls",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/custom-models.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "301087a714a78598071f99b28724305dd5e13615552c20cd0db8eebd52422e32",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0013",
    "providerId": "amazon",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Multi-stage safety pipeline with Bedrock Guardrails and AWS security integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0014",
    "providerId": "amazon",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "titan-express"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Advanced PII detection and redaction with enterprise-grade sensitive information filters",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails-sensitive-filters.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "2e1b15bc85fc8b37e81960cb9f302cc4c3e1a235df00a026518e0bc7efdb33fd",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0015",
    "providerId": "amazon",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [
      "titan-express"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Highly configurable safety policies through Bedrock Guardrails with customer customization",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0016",
    "providerId": "amazon",
    "techniqueId": "tech-audit-logging",
    "modelIds": [
      "titan-express"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive audit logging through AWS CloudTrail with enterprise compliance tracking",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/logging-monitoring.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "e287c7b44ce23e4a471bebf2532b8c016fe17840bd35f1c048360118f99a599e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0017",
    "providerId": "amazon",
    "techniqueId": "tech-enterprise-integration",
    "modelIds": [
      "titan-express"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Deep enterprise security integration with AWS IAM, VPC, and compliance frameworks",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/security.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "3e82ddd78f2de438f7b597e4418a6287c23eff16d0bb89d37d7138cf6c11c247",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0018",
    "providerId": "amazon",
    "techniqueId": "tech-sovereignty-options",
    "modelIds": [
      "titan-express"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Data sovereignty options with AWS regions and customer-controlled encryption keys",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://aws.amazon.com/compliance/data-privacy/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "c675a9ff8a6ac477e4419f5465c2b783100ea9b11c3c48109ec7dd8d97a9fc3b",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0019",
    "providerId": "amazon",
    "techniqueId": "tech-incident-reporting",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise incident reporting through AWS support and compliance frameworks",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/logging-monitoring.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "e287c7b44ce23e4a471bebf2532b8c016fe17840bd35f1c048360118f99a599e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0020",
    "providerId": "amazon",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "titan-express"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive usage monitoring through AWS CloudWatch with enterprise analytics",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/logging-monitoring.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "e287c7b44ce23e4a471bebf2532b8c016fe17840bd35f1c048360118f99a599e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0021",
    "providerId": "amazon",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise regulatory compliance with AWS compliance certifications and industry standards",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://aws.amazon.com/compliance/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "e975b64d0adf8a907cf2ae72bea5f3140c39e98f998da306f0f9958bff0a2852",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0022",
    "providerId": "amazon",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise-focused safety documentation with AWS service documentation and compliance guides",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0023",
    "providerId": "amazon",
    "techniqueId": "tech-model-cards",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "AWS AI Service Cards with model specifications and enterprise integration documentation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://aws.amazon.com/machine-learning/ai-service-cards/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0024",
    "providerId": "amazon",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Comprehensive enterprise policy and compliance documentation with AWS security frameworks",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://aws.amazon.com/compliance/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "c128d95b8342b35a1701be6ce7a1fc52759d35601a9640ca876764b7098b1511",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0001",
    "providerId": "cohere",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise document focus with bias metrics during training for business use cases",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "19631b6b41b0c464fdc272ea9981cf842ad5ffc40f5cf93a6bd1f5ee2fef9ab8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0002",
    "providerId": "cohere",
    "techniqueId": "tech-csam-detection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic CSAM detection as part of enterprise content filtering systems",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "19631b6b41b0c464fdc272ea9981cf842ad5ffc40f5cf93a6bd1f5ee2fef9ab8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0003",
    "providerId": "cohere",
    "techniqueId": "tech-copyright-filtering",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Copyright filtering mechanisms for enterprise compliance and content policies",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "19631b6b41b0c464fdc272ea9981cf842ad5ffc40f5cf93a6bd1f5ee2fef9ab8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-cohere-0004",
    "providerId": "cohere",
    "techniqueId": "tech-bias-detection-training",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Bias metrics published during training with focus on enterprise fairness requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "19631b6b41b0c464fdc272ea9981cf842ad5ffc40f5cf93a6bd1f5ee2fef9ab8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0005",
    "providerId": "cohere",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic PII reduction capabilities for enterprise data protection requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "19631b6b41b0c464fdc272ea9981cf842ad5ffc40f5cf93a6bd1f5ee2fef9ab8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0006",
    "providerId": "cohere",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise compliance filtering with focus on business regulatory requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "19631b6b41b0c464fdc272ea9981cf842ad5ffc40f5cf93a6bd1f5ee2fef9ab8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0007",
    "providerId": "cohere",
    "techniqueId": "tech-rlhf",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "RLHF for business use cases with enterprise-focused training optimization",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "19631b6b41b0c464fdc272ea9981cf842ad5ffc40f5cf93a6bd1f5ee2fef9ab8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0008",
    "providerId": "cohere",
    "techniqueId": "tech-community-feedback",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited community feedback integration focused on enterprise customer requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "19631b6b41b0c464fdc272ea9981cf842ad5ffc40f5cf93a6bd1f5ee2fef9ab8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0009",
    "providerId": "cohere",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Domain-specific fine-tuning for enterprise safety requirements and business use cases",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/fine-tuning",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "9960622ecbbc5f5074391077ef2eaa230dca67857c0d81e66abc5c504fb675a6",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0010",
    "providerId": "cohere",
    "techniqueId": "tech-input-classification",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic input content classification with dual safety modes (strict/contextual)",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "19631b6b41b0c464fdc272ea9981cf842ad5ffc40f5cf93a6bd1f5ee2fef9ab8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0011",
    "providerId": "cohere",
    "techniqueId": "tech-output-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Output filtering through dual safety modes with enterprise logging capabilities",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "19631b6b41b0c464fdc272ea9981cf842ad5ffc40f5cf93a6bd1f5ee2fef9ab8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0012",
    "providerId": "cohere",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic prompt injection protection through safety mode filtering",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "19631b6b41b0c464fdc272ea9981cf842ad5ffc40f5cf93a6bd1f5ee2fef9ab8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0013",
    "providerId": "cohere",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited real-time monitoring capabilities through safety mode enforcement",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "19631b6b41b0c464fdc272ea9981cf842ad5ffc40f5cf93a6bd1f5ee2fef9ab8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0014",
    "providerId": "cohere",
    "techniqueId": "tech-contextual-safety",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Contextual safety assessment through CONTEXTUAL safety mode allowing nuanced moderation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "19631b6b41b0c464fdc272ea9981cf842ad5ffc40f5cf93a6bd1f5ee2fef9ab8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0015",
    "providerId": "cohere",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic multi-stage pipeline with dual safety modes and enterprise integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "19631b6b41b0c464fdc272ea9981cf842ad5ffc40f5cf93a6bd1f5ee2fef9ab8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0016",
    "providerId": "cohere",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Configurable safety policies through STRICT and CONTEXTUAL mode selection",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "19631b6b41b0c464fdc272ea9981cf842ad5ffc40f5cf93a6bd1f5ee2fef9ab8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0017",
    "providerId": "cohere",
    "techniqueId": "tech-audit-logging",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise audit logging for disallowed prompts and safety mode enforcement",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "19631b6b41b0c464fdc272ea9981cf842ad5ffc40f5cf93a6bd1f5ee2fef9ab8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0018",
    "providerId": "cohere",
    "techniqueId": "tech-enterprise-integration",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise security integration with on-premises deployment options",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cohere.com/enterprise",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0019",
    "providerId": "cohere",
    "techniqueId": "tech-sovereignty-options",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "On-premises deployment options for data sovereignty and enterprise control",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cohere.com/enterprise",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0020",
    "providerId": "cohere",
    "techniqueId": "tech-incident-reporting",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic incident reporting through enterprise support channels",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "19631b6b41b0c464fdc272ea9981cf842ad5ffc40f5cf93a6bd1f5ee2fef9ab8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0021",
    "providerId": "cohere",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Usage monitoring and analytics for enterprise safety and compliance tracking",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "19631b6b41b0c464fdc272ea9981cf842ad5ffc40f5cf93a6bd1f5ee2fef9ab8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0022",
    "providerId": "cohere",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise regulatory compliance frameworks with industry-specific requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cohere.com/enterprise",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0023",
    "providerId": "cohere",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited academic partnerships with focus on enterprise applications",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cohere.com/research",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "0fab10724fb58e3e089bf29539b8107bbd827316197f807409cd5fab72b0c384",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0024",
    "providerId": "cohere",
    "techniqueId": "tech-community-governance",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited community governance with enterprise customer feedback integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "19631b6b41b0c464fdc272ea9981cf842ad5ffc40f5cf93a6bd1f5ee2fef9ab8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0025",
    "providerId": "cohere",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic safety documentation focused on safety modes and enterprise implementation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "19631b6b41b0c464fdc272ea9981cf842ad5ffc40f5cf93a6bd1f5ee2fef9ab8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0026",
    "providerId": "cohere",
    "techniqueId": "tech-model-cards",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited model cards and technical specifications with enterprise focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "334f0977c31a5ab594e4afcf82504ac14da0c36e5b5e03be281cd0133b4b1e08",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0027",
    "providerId": "cohere",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited safety research publications with focus on enterprise applications",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cohere.com/research",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "0fab10724fb58e3e089bf29539b8107bbd827316197f807409cd5fab72b0c384",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0028",
    "providerId": "cohere",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise policy and compliance documentation with safety mode implementation guides",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "19631b6b41b0c464fdc272ea9981cf842ad5ffc40f5cf93a6bd1f5ee2fef9ab8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-mistral-0001",
    "providerId": "mistral",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Lightweight filtering with community-driven approach and European data focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "2eb4cfa534a9ed0ad88d51a12f4e4c45f85f170c432ecd8f319fbaf3e61d66e1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0002",
    "providerId": "mistral",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "European AI sovereignty focus with EU regulatory compliance measures",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "2eb4cfa534a9ed0ad88d51a12f4e4c45f85f170c432ecd8f319fbaf3e61d66e1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-mistral-0003",
    "providerId": "mistral",
    "techniqueId": "tech-rlhf",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Minimal RLHF implementation with community feedback integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "2eb4cfa534a9ed0ad88d51a12f4e4c45f85f170c432ecd8f319fbaf3e61d66e1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0004",
    "providerId": "mistral",
    "techniqueId": "tech-community-feedback",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community feedback integration for model improvement and safety enhancement",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "2eb4cfa534a9ed0ad88d51a12f4e4c45f85f170c432ecd8f319fbaf3e61d66e1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0005",
    "providerId": "mistral",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Domain-specific fine-tuning capabilities with European regulatory focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.mistral.ai/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "a83776976fedd3c16c15180d920c092d5398646771af584739d27d31b7cc5e5e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-mistral-0006",
    "providerId": "mistral",
    "techniqueId": "tech-input-classification",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Moderation API for input content classification with lightweight approach",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "2eb4cfa534a9ed0ad88d51a12f4e4c45f85f170c432ecd8f319fbaf3e61d66e1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0007",
    "providerId": "mistral",
    "techniqueId": "tech-output-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Content classification and filtering through Moderation API",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "2eb4cfa534a9ed0ad88d51a12f4e4c45f85f170c432ecd8f319fbaf3e61d66e1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0008",
    "providerId": "mistral",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic prompt injection protection through content classification",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "2eb4cfa534a9ed0ad88d51a12f4e4c45f85f170c432ecd8f319fbaf3e61d66e1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0009",
    "providerId": "mistral",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Lightweight safety pipeline with moderation API and content classification",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "2eb4cfa534a9ed0ad88d51a12f4e4c45f85f170c432ecd8f319fbaf3e61d66e1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0010",
    "providerId": "mistral",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic configurable policies through moderation API categories",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "2eb4cfa534a9ed0ad88d51a12f4e4c45f85f170c432ecd8f319fbaf3e61d66e1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0011",
    "providerId": "mistral",
    "techniqueId": "tech-community-governance",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community governance model with European AI sovereignty principles",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "2eb4cfa534a9ed0ad88d51a12f4e4c45f85f170c432ecd8f319fbaf3e61d66e1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0012",
    "providerId": "mistral",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "EU-focused regulatory compliance with European AI sovereignty emphasis",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "2eb4cfa534a9ed0ad88d51a12f4e4c45f85f170c432ecd8f319fbaf3e61d66e1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-mistral-0013",
    "providerId": "mistral",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited academic partnerships with European research institutions",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/research",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0014",
    "providerId": "mistral",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic safety documentation with moderation API specifications",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "2eb4cfa534a9ed0ad88d51a12f4e4c45f85f170c432ecd8f319fbaf3e61d66e1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0015",
    "providerId": "mistral",
    "techniqueId": "tech-model-cards",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited model cards and technical documentation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.mistral.ai/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "a83776976fedd3c16c15180d920c092d5398646771af584739d27d31b7cc5e5e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0016",
    "providerId": "mistral",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Minimal safety research publications with focus on efficiency",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/research",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0017",
    "providerId": "mistral",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic policy documentation with EU regulatory compliance focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-11-12",
        "sourceHash": "2eb4cfa534a9ed0ad88d51a12f4e4c45f85f170c432ecd8f319fbaf3e61d66e1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0001",
    "providerId": "baidu",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Chinese regulatory compliance with government-approved content filtering",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "796c83cb7b5e280e3774aeb976e3525a601307216f6458207bef0e4afb85751e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0002",
    "providerId": "baidu",
    "techniqueId": "tech-csam-detection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "CSAM detection in compliance with Chinese internet regulations",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "796c83cb7b5e280e3774aeb976e3525a601307216f6458207bef0e4afb85751e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0003",
    "providerId": "baidu",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive Chinese regulatory compliance with government oversight integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "796c83cb7b5e280e3774aeb976e3525a601307216f6458207bef0e4afb85751e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-baidu-0004",
    "providerId": "baidu",
    "techniqueId": "tech-rlhf",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "RLHF with alignment to Chinese values and regulatory requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "796c83cb7b5e280e3774aeb976e3525a601307216f6458207bef0e4afb85751e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0005",
    "providerId": "baidu",
    "techniqueId": "tech-input-classification",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Real-time censorship and political content filtering for input classification",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "796c83cb7b5e280e3774aeb976e3525a601307216f6458207bef0e4afb85751e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0006",
    "providerId": "baidu",
    "techniqueId": "tech-output-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Political content filtering and real-time censorship for output content",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "796c83cb7b5e280e3774aeb976e3525a601307216f6458207bef0e4afb85751e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0007",
    "providerId": "baidu",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic prompt injection protection through content filtering and government oversight",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "796c83cb7b5e280e3774aeb976e3525a601307216f6458207bef0e4afb85751e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0008",
    "providerId": "baidu",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Real-time monitoring with government oversight and regulatory compliance",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "796c83cb7b5e280e3774aeb976e3525a601307216f6458207bef0e4afb85751e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0009",
    "providerId": "baidu",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Multi-stage pipeline with government oversight and political content filtering",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "796c83cb7b5e280e3774aeb976e3525a601307216f6458207bef0e4afb85751e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0010",
    "providerId": "baidu",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Government-configured safety policies with Chinese regulatory compliance",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "796c83cb7b5e280e3774aeb976e3525a601307216f6458207bef0e4afb85751e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0011",
    "providerId": "baidu",
    "techniqueId": "tech-audit-logging",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Government audit logging and compliance tracking for regulatory oversight",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "796c83cb7b5e280e3774aeb976e3525a601307216f6458207bef0e4afb85751e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0012",
    "providerId": "baidu",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Direct government oversight and regulatory compliance with Chinese authorities",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "796c83cb7b5e280e3774aeb976e3525a601307216f6458207bef0e4afb85751e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-baidu-0013",
    "providerId": "baidu",
    "techniqueId": "tech-incident-reporting",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Government incident reporting with regulatory compliance tracking",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "796c83cb7b5e280e3774aeb976e3525a601307216f6458207bef0e4afb85751e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0014",
    "providerId": "baidu",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Usage monitoring with government oversight and regulatory compliance",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "796c83cb7b5e280e3774aeb976e3525a601307216f6458207bef0e4afb85751e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0015",
    "providerId": "baidu",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive Chinese regulatory compliance with government framework integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "796c83cb7b5e280e3774aeb976e3525a601307216f6458207bef0e4afb85751e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-baidu-0016",
    "providerId": "baidu",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited academic partnerships with Chinese research institutions",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "796c83cb7b5e280e3774aeb976e3525a601307216f6458207bef0e4afb85751e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0017",
    "providerId": "baidu",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited international transparency with Chinese regulatory documentation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "796c83cb7b5e280e3774aeb976e3525a601307216f6458207bef0e4afb85751e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0018",
    "providerId": "baidu",
    "techniqueId": "tech-model-cards",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic model cards with Chinese regulatory compliance information",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "796c83cb7b5e280e3774aeb976e3525a601307216f6458207bef0e4afb85751e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0019",
    "providerId": "baidu",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited international safety research publications with regulatory focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://research.baidu.com/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "0129a6649f7b95098cc2b812c5293740889775136b8738106035d05363431f8d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0020",
    "providerId": "baidu",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Chinese regulatory documentation with limited international transparency",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "796c83cb7b5e280e3774aeb976e3525a601307216f6458207bef0e4afb85751e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0001",
    "providerId": "alibaba",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Commercial focus with regulatory compliance and business-oriented filtering",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "17b6f15d314639c5c0130cfa45854ed0999c47aca0ab605d376eb43d28e670e3",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0002",
    "providerId": "alibaba",
    "techniqueId": "tech-csam-detection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "CSAM detection for Chinese regulatory compliance and commercial deployment",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "76176b5848d4153874596cabb5cfdea9ae9b44d9d5611fe610d105dd980f699f",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0003",
    "providerId": "alibaba",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Chinese regulatory compliance with commercial focus and efficiency optimization",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "ea2a37c4b0c4ce51725081931f4e1491f78249e4d2ba30d561d67933f1c101e0",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0004",
    "providerId": "alibaba",
    "techniqueId": "tech-rlhf",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Business-oriented RLHF with efficiency focus and commercial optimization",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "9c675b98f592500504fa582f9be33d488b5fea7338e9e46520c588859e8d25d3",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0005",
    "providerId": "alibaba",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Domain-specific fine-tuning for business process automation and commercial safety",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "751adb84e89bafff6f1147cf21a4a23fb235c1a9eed15d78462a03ad921aaa49",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0006",
    "providerId": "alibaba",
    "techniqueId": "tech-input-classification",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise content filtering with customer customization for business use cases",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "7e4292bcd8cec0006b8e97d227961bb3145e6052988a1907e279c117f4833883",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0007",
    "providerId": "alibaba",
    "techniqueId": "tech-output-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Customer-customizable output filtering for enterprise and commercial applications",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "8afd3f855edd3862960c2835bd934297772511de415bc73c6aa3312baa892e80",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0008",
    "providerId": "alibaba",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic prompt injection protection through enterprise content filtering",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "01e3b1efcfbea1b67f8c174adf9b5b8752966c9a8a7d1ca0f514ee2871c41010",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0009",
    "providerId": "alibaba",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Real-time monitoring for commercial applications with business process integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "50c85022c4e68d09682b6a19f77c6c244218e69db5bffac06a6494b81696cdb9",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0010",
    "providerId": "alibaba",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Multi-stage pipeline with cloud integration and business process automation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "7c6c476c2144caf1fab4e8fe8f89004df8d2a2591c2d43702589977c94773ccf",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0011",
    "providerId": "alibaba",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic PII detection for enterprise data protection and commercial compliance",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "a81c161a54080b56a8c95449eb0780405262672be55f067b05071338323969f1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0012",
    "providerId": "alibaba",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Customer-configurable safety policies for enterprise deployment and business needs",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "00d75e76f312445bdf4748c2adcce30dfa9c221ec2b2783a50d14eb89a96a09e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0013",
    "providerId": "alibaba",
    "techniqueId": "tech-audit-logging",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise audit logging for business compliance and commercial accountability",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "1cd564ba4b18e4787fe4cd2d780bc30bebe3763e0dd135d0c5296bb7ff8df8ea",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0014",
    "providerId": "alibaba",
    "techniqueId": "tech-enterprise-integration",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Cloud integration with Alibaba Cloud security and business process automation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "d9fe1f3d0f1a846e243e3ad6a858850dda0fdd5dc545941e2cfb778002d72f33",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0015",
    "providerId": "alibaba",
    "techniqueId": "tech-sovereignty-options",
    "modelIds": [],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Data sovereignty options through Alibaba Cloud with regional deployment flexibility",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "19c233b8f3cc14ec8bbc5219b0c1c4b119e51421a0e38b68304dee1bb948e1ba",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-alibaba-0016",
    "providerId": "alibaba",
    "techniqueId": "tech-incident-reporting",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic incident reporting through enterprise support and commercial channels",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "ebc59e072247936ce4bcaf3296461360c4d2333dd0fa9843deddb7e6ac60ec48",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0017",
    "providerId": "alibaba",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise usage monitoring with business analytics and commercial optimization",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "e528e93957f04c37dad95eec3e25286ee71f5a5dafb41abc5debcb496f5abdf6",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0018",
    "providerId": "alibaba",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Chinese regulatory compliance frameworks with commercial focus and enterprise requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "75fec580230dc0a629c11c3c064721e9b17dffa4367de078e4bc213460b46a78",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0019",
    "providerId": "alibaba",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Business documentation with limited research disclosure and commercial focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "74b52cfa87d68d33abcafaaad3752c4185f0e1eaaceb05aa14f9a907fa4635e3",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0020",
    "providerId": "alibaba",
    "techniqueId": "tech-model-cards",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic model cards with commercial specifications and business application focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "9fc95ac47c2630435bc68ae0f927ef636aad126e25242fe26f84d30aa722158a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0021",
    "providerId": "alibaba",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Business policy documentation with enterprise compliance and commercial requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-11-12",
        "sourceHash": "dedf507d2608dbe6ae51fbb055ff0abf3b8d2739e7e5a79c8c5339f059e6f5ee",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-x-constitutional-ai-001",
    "providerId": "x",
    "techniqueId": "tech-constitutional-ai",
    "modelIds": [],
    "summary": "Constitutional AI training methodology implemented in Grok-4 to align model behavior with human values and safety principles",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.ai/news/grok-4",
        "documentType": "blog-post",
        "relevantSection": "Training and Safety",
        "lastVerified": "2025-07-24",
        "sourceHash": "c6d3e7bfa462aef2201bdff29ed7472fefb66eed1a8478ae51f05b63a54e3de3"
      }
    ],
    "knownLimitations": [
      "Limited public details on specific constitutional principles",
      "No published effectiveness metrics"
    ],
    "notes": "Grok-4 implements constitutional AI for value alignment",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-realtime-fact-check-002",
    "providerId": "x",
    "techniqueId": "tech-realtime-fact-checking",
    "modelIds": [],
    "summary": "Integration with X platform's real-time information feed to fact-check claims and provide current information verification",
    "rating": "medium-high",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.ai/news/grok-4",
        "documentType": "blog-post",
        "relevantSection": "Real-time Information Access",
        "lastVerified": "2025-07-24",
        "sourceHash": "c6d3e7bfa462aef2201bdff29ed7472fefb66eed1a8478ae51f05b63a54e3de3"
      }
    ],
    "knownLimitations": [
      "Dependent on X platform data quality",
      "May amplify trending misinformation"
    ],
    "notes": "Unique capability leveraging X's real-time data stream",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "premium-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-platform-context-003",
    "providerId": "x",
    "techniqueId": "tech-contextual-safety",
    "modelIds": [],
    "summary": "Safety measures that consider broader X platform context, user interaction history, and social graph for contextual risk assessment",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.com/privacy",
        "documentType": "privacy-policy",
        "relevantSection": "Data Usage for AI Services",
        "lastVerified": "2025-11-12",
        "sourceHash": "9616dbc04cbac7b62f54cedeb02a8b7e936d68ac6db67c49d0565fdde5c4c6ae"
      }
    ],
    "knownLimitations": [
      "Privacy implications of using social context",
      "Potential for social bias amplification"
    ],
    "notes": "Leverages X platform social context for safety",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-multimodal-safety-004",
    "providerId": "x",
    "techniqueId": "tech-multimodal-safety-alignment",
    "modelIds": [],
    "summary": "Cross-modal safety alignment for Grok-4's multimodal capabilities, ensuring safety across text, image, and audio interactions",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.ai/news/grok-4",
        "documentType": "blog-post",
        "relevantSection": "Multimodal Capabilities",
        "lastVerified": "2025-07-24",
        "sourceHash": "c6d3e7bfa462aef2201bdff29ed7472fefb66eed1a8478ae51f05b63a54e3de3"
      }
    ],
    "knownLimitations": [
      "Cross-modal safety interactions are complex",
      "Limited multimodal safety evaluation data"
    ],
    "notes": "Addresses safety across multiple modalities in Grok-4",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-input-classification-005",
    "providerId": "x",
    "techniqueId": "tech-input-classification",
    "modelIds": [],
    "summary": "Pre-processing classification of user inputs to identify potential safety risks before processing by Grok-4",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://help.x.com/en/rules-and-policies",
        "documentType": "policy-documentation",
        "relevantSection": "Content Moderation",
        "lastVerified": "2025-07-24",
        "sourceHash": "b737b99b7dde781f17abe0db3c6129d63edce718f07dad841b9e15ffd47fef2a"
      }
    ],
    "knownLimitations": [
      "May block benign content",
      "Context-dependent risks challenging to detect"
    ],
    "notes": "Integrated with X platform content moderation",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-output-filtering-006",
    "providerId": "x",
    "techniqueId": "tech-output-filtering",
    "modelIds": [],
    "summary": "Post-generation filtering of Grok-4 outputs for safety violations before presentation to users",
    "rating": "medium-high",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://help.x.com/en/rules-and-policies",
        "documentType": "policy-documentation",
        "relevantSection": "AI Content Guidelines",
        "lastVerified": "2025-07-24",
        "sourceHash": "b737b99b7dde781f17abe0db3c6129d63edce718f07dad841b9e15ffd47fef2a"
      }
    ],
    "knownLimitations": [
      "May alter intended meaning",
      "Can be overly restrictive"
    ],
    "notes": "Aligned with X platform community guidelines",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-realtime-monitoring-007",
    "providerId": "x",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "summary": "Continuous monitoring of Grok-4 interactions for safety violations and emerging risk patterns",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.com/tos",
        "documentType": "terms-of-service",
        "relevantSection": "Monitoring and Enforcement",
        "lastVerified": "2025-11-12",
        "sourceHash": "bf9dea9dfaed6d97f5a02247e09cbe6fe165edd4fd73e119f45a389ebfd21ec3"
      }
    ],
    "knownLimitations": [
      "Latency impact on user experience",
      "May miss contextual nuances"
    ],
    "notes": "Integrated with X platform monitoring infrastructure",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-pii-detection-008",
    "providerId": "x",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [],
    "summary": "Real-time detection and redaction of personally identifiable information in Grok-4 interactions",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.com/privacy",
        "documentType": "privacy-policy",
        "relevantSection": "Personal Information Protection",
        "lastVerified": "2025-11-12",
        "sourceHash": "92a51bcc9ce1614bcb13161139ba9d46549d94add135e700ea0b4a03fce70886"
      }
    ],
    "knownLimitations": [
      "Context-dependent PII challenging to detect",
      "May miss novel PII patterns"
    ],
    "notes": "Complies with X platform privacy standards",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "GDPR",
      "CCPA"
    ],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-training-filtering-009",
    "providerId": "x",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [],
    "summary": "Systematic filtering of training data for Grok-4 to remove harmful, biased, or inappropriate content",
    "rating": "medium-low",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.ai/news/grok-4",
        "documentType": "blog-post",
        "relevantSection": "Data and Training",
        "lastVerified": "2025-07-24",
        "sourceHash": "c6d3e7bfa462aef2201bdff29ed7472fefb66eed1a8478ae51f05b63a54e3de3"
      }
    ],
    "knownLimitations": [
      "Limited transparency on filtering criteria",
      "May introduce demographic biases"
    ],
    "notes": "Standard pre-training data curation practices",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-audit-logging-010",
    "providerId": "x",
    "techniqueId": "tech-audit-logging",
    "modelIds": [],
    "summary": "Comprehensive logging of Grok-4 safety-relevant events and decisions for audit and improvement purposes",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.com/tos",
        "documentType": "terms-of-service",
        "relevantSection": "Data Retention and Logging",
        "lastVerified": "2025-11-12",
        "sourceHash": "9c6b32fb3734610a8b0ace93d4f6d546054fd3516e4ee77ad3529575a616c0a9"
      }
    ],
    "knownLimitations": [
      "Storage and privacy considerations",
      "Log completeness not specified"
    ],
    "notes": "Supports X platform compliance requirements",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "SOC2"
    ],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  }
]