[
  {
    "providerId": "anthropic",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Constitutional training data with filtered corpora designed to reduce harmful content and improve model alignment",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "policy",
        "lastVerified": "2025-10-17",
        "sourceHash": "6e5c5a512c7d1e9f7760a8c213590f76d159cf87d6d873ca5700b45c3e3df404",
        "relevantSection": "Safety and Security Standards"
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Specific filtering methods not detailed"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Part of Constitutional AI framework",
    "id": "ev-anthropic-0002"
  },
  {
    "providerId": "anthropic",
    "techniqueId": "tech-constitutional-ai",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Self-critique training using constitutional principles for helpful, harmless, honest behavior with scalable oversight",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2212.08073",
        "documentType": "research-paper",
        "lastVerified": "2025-10-17",
        "sourceHash": "9a456a07ad346e3372f9867d346f69f5b0f68b4c65f060aca0b8a13fa9d98e83",
        "relevantSection": "Section 3: Constitutional AI"
      }
    ],
    "implementationDate": "2022-12-15",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "evaluationMetrics": [
      {
        "metric": "human_preference_rate",
        "value": 76,
        "unit": "percent",
        "benchmarkContext": {
          "name": "Constitutional AI Eval",
          "version": "v1",
          "url": "https://arxiv.org/abs/2212.08073"
        }
      }
    ],
    "knownLimitations": [
      "May be overly conservative",
      "Principles require careful design"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Core safety innovation from Anthropic",
    "id": "ev-anthropic-0003"
  },
  {
    "providerId": "anthropic",
    "techniqueId": "tech-rlhf",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Constitutional AI approach combining self-critique with RLHF for scalable oversight and preference learning",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2212.08073",
        "documentType": "research-paper",
        "lastVerified": "2025-10-17",
        "sourceHash": "9a456a07ad346e3372f9867d346f69f5b0f68b4c65f060aca0b8a13fa9d98e83",
        "relevantSection": "Section 4: Training Process"
      }
    ],
    "implementationDate": "2022-12-15",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Subject to annotator biases",
      "Computationally expensive"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Combined with Constitutional AI for enhanced safety",
    "id": "ev-anthropic-0004"
  },
  {
    "providerId": "google",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Multi-lingual safety filtering and bias detection in training data preparation for Gemini models",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": "Training Data Safety"
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Specific methods not detailed"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "EU AI Act"
    ],
    "notes": "Focus on multilingual safety",
    "id": "ev-google-0005"
  },
  {
    "providerId": "google",
    "techniqueId": "tech-rlhf",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "B",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "RLHF with adversarial safety tuning datasets and Sparrow-style critiquing methodology",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2209.14375",
        "documentType": "research-paper",
        "lastVerified": "2025-10-17",
        "sourceHash": "e7df8fc1e41dfc3b47a781958fc53e6467f3b0ba3b0c10db5040f7924097709a",
        "relevantSection": "Section 3: Training Sparrow"
      }
    ],
    "implementationDate": "2022-09-29",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Limited to English initially"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Based on Sparrow research",
    "id": "ev-google-0006"
  },
  {
    "providerId": "meta",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Open training with safety benchmarks and Llama Guard integration for content filtering",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-10-17",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": "Section 4: Safety"
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Community-dependent verification"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Open source approach enables community verification",
    "id": "ev-meta-0007"
  },
  {
    "providerId": "meta",
    "techniqueId": "tech-rlhf",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Two-phase RLHF with community-driven safety feedback and open source evaluation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-10-17",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": "Section 3.3: Fine-tuning"
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Resource intensive",
      "Community feedback quality varies"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Two-phase approach with safety-specific rewards",
    "id": "ev-meta-0008"
  },
  {
    "providerId": "meta",
    "techniqueId": "tech-input-classification",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Llama Guard as separate safety classifier for input content with open source implementation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "research-paper",
        "lastVerified": "2025-10-17",
        "sourceHash": "be9eddf14053833d11f9ad08cab50455c40d9de42446a7d113703e65e69a0721",
        "relevantSection": "Section 2: Llama Guard"
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Requires separate model inference"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Open source safety classifier",
    "id": "ev-meta-0009"
  },
  {
    "providerId": "amazon",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "B",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Advanced PII detection and redaction through Bedrock Guardrails with enterprise-grade protection",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails-sensitive-filters.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "9fd1ff0e2bb20a0f1e824ed07fd340b3fd17371908558ac417185250d6b8f122",
        "relevantSection": "Sensitive Information Filters"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Language support varies",
      "Context-dependent PII challenging"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "HIPAA",
      "PCI-DSS"
    ],
    "notes": "Enterprise-grade PII protection",
    "id": "ev-amazon-0010"
  },
  {
    "providerId": "amazon",
    "techniqueId": "tech-input-classification",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Bedrock Guardrails input classification with customizable policies and enterprise integration",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": "Content Filters"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Requires configuration",
      "May have false positives"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Highly configurable for enterprise needs",
    "id": "ev-amazon-0011"
  },
  {
    "providerId": "amazon",
    "techniqueId": "tech-output-filtering",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Bedrock Guardrails output filtering with hallucination detection and content policy enforcement",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": "Output Moderation"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "May alter outputs",
      "Hallucination detection has limits"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Includes hallucination detection",
    "id": "ev-amazon-0012"
  },
  {
    "providerId": "anthropic",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "External red team engagement as part of responsible scaling policy and AI Safety Level assessments",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "policy",
        "lastVerified": "2025-10-17",
        "sourceHash": "702bd7c2f08355f0df83ae56c59e280461e49430a20c9da872802c297b8a0bd5",
        "relevantSection": "AI Safety Levels"
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [
      "Specific findings not always public"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Part of ASL framework",
    "id": "ev-anthropic-0013"
  },
  {
    "providerId": "anthropic",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Responsible scaling policy and constitutional AI research provide comprehensive safety framework documentation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "policy",
        "lastVerified": "2025-10-17",
        "sourceHash": "7b1ef63756c9e1d2bbfa67d74b334153185ab9c00bb5ae8defbbdd6cf236510a",
        "relevantSection": "Full Document"
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P12M",
    "reviewer": "initial-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Industry-leading transparency",
    "id": "ev-anthropic-0014"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-csam-detection",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Automated detection and removal of child sexual abuse material using specialized classifiers during pre-training data preparation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://openai.com/policies/usage-policies",
        "documentType": "policy",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "Prohibited Usage"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Detection rates not disclosed"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "NCMEC"
    ],
    "notes": "Part of comprehensive content filtering",
    "id": "ev-openai-0003"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-copyright-filtering",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Fingerprinting system to remove opted-out images from training data, building on DALL-E 3 opt-out mechanism",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-17",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Section 2.1"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Only for opted-out content"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "DMCA"
    ],
    "notes": "Extends DALL-E 3 opt-out system",
    "id": "ev-openai-0004"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-bias-detection-training",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Advanced data filtering processes to reduce biased content, though specific bias detection methods not fully detailed",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-17",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Safety Evaluations"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Specific methods not disclosed"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0005"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Advanced data filtering processes to reduce personal information from training data using automated detection systems",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-17",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Data Processing"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Cannot catch all PII"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "GDPR",
      "CCPA"
    ],
    "notes": "",
    "id": "ev-openai-0006"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-adversarial-training",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Red team data integration and adversarial testing during training, though specific methods not detailed",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-17",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Red Teaming"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Methods not fully disclosed"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0007"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-red-team-data",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "100+ external red teamers across 45 languages and 29 countries, data integrated into training process",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-17",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "External Red Teaming"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Extensive red team network",
    "id": "ev-openai-0008"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-input-classification",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Layered policy engine with system prompt \u2192 model \u2192 content filter pipeline, including specialized voice classifiers",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-17",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Safety Pipeline"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Multi-layer approach",
    "id": "ev-openai-0009"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-output-filtering",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Multi-stage content filtering with moderation API applied to both text and audio outputs",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-17",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Output Moderation"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Includes audio moderation",
    "id": "ev-openai-0010"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "System prompt protections and multi-layer filtering, though specific prompt injection defenses not detailed",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-17",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Safety Mitigations"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Specific defenses not disclosed"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0011"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Real-time monitoring and enforcement with product-level mitigations including streaming audio analysis",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-17",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Real-time Voice"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Includes voice monitoring",
    "id": "ev-openai-0012"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-contextual-safety",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Context-aware safety evaluation, particularly for voice interactions, though implementation not detailed",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-17",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Voice Safety"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Implementation details limited"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0013"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Comprehensive safety pipeline spanning pre-training, post-training, product development, and policy enforcement",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-17",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Safety Architecture"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "End-to-end approach",
    "id": "ev-openai-0014"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "PII detection capabilities integrated into content filtering systems for personal information protection",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://openai.com/policies/usage-policies",
        "documentType": "policy",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "Privacy"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Details not specified"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "GDPR",
      "CCPA"
    ],
    "notes": "",
    "id": "ev-openai-0015"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Usage policies and moderation tools provided to users, with transparency reports and configurable settings",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://openai.com/policies/usage-policies",
        "documentType": "policy",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "Usage Policies"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Limited configurability"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0016"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-audit-logging",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Usage monitoring and incident reporting systems for tracking and analyzing safety incidents",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-17",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Monitoring"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "SOC2"
    ],
    "notes": "",
    "id": "ev-openai-0017"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Preparedness Framework with pre-defined capability thresholds and deployment decisions based on risk assessments",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/openai-preparedness-framework-beta.pdf",
        "documentType": "policy",
        "lastVerified": "2025-10-17",
        "sourceHash": "c84e3a59c7dab251e45434e0b0d3e8abadcea7293f995cf92d32269e7d290398",
        "relevantSection": "Full Document"
      }
    ],
    "implementationDate": "2023-10-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Industry-leading framework",
    "id": "ev-openai-0018"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-safety-advisory",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Safety Advisory Group providing independent oversight and recommendations on deployment decisions",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-17",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Governance"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P12M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0019"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-incident-reporting",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": true
    },
    "summary": "Systematic incident reporting and analysis with internal tracking and external disclosure mechanisms",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-17",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Incident Response"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0020"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": true
    },
    "summary": "Comprehensive usage monitoring with analytics for detecting patterns of misuse and safety incidents",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-17",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Usage Analytics"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P3M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0021"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Compliance with voluntary White House commitments and development of internal governance frameworks",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://openai.com/index/our-approach-to-ai-safety",
        "documentType": "blog-post",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "Commitments"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "White House Commitments"
    ],
    "notes": "",
    "id": "ev-openai-0022"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Collaboration with academic institutions and independent research organizations for safety evaluation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-17",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "External Collaboration"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P12M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0023"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-model-cards",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Technical documentation including model architecture, training methodology, and safety evaluation results",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-17",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": "Full Document"
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P12M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Comprehensive system card",
    "id": "ev-openai-0024"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Regular publication of safety research, evaluation methodologies, and lessons learned from deployment",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://openai.com/research",
        "documentType": "research-paper",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "Safety Research"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P12M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0025"
  },
  {
    "providerId": "openai",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Comprehensive usage policies, terms of service, and compliance documentation publicly available",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://openai.com/policies",
        "documentType": "policy",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "All Policies"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-openai-0026"
  },
  {
    "providerId": "google",
    "techniqueId": "tech-watermarking",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": true
    },
    "summary": "SynthID watermarking technology for AI-generated image and audio content identification",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/science/synthid/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "6d067c776240a1988fac53b0f0198d094af15770d674ec119bd4a28bf2f07230",
        "relevantSection": "Technology Overview"
      }
    ],
    "implementationDate": "2023-08-29",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Limited to certain content types"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Industry-leading watermarking",
    "id": "ev-google-0003"
  },
  {
    "providerId": "google",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "EU AI Act compliance measures with transparency registers and regulatory reporting mechanisms",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://blog.google/technology/ai/google-ai-act-preparation/",
        "documentType": "blog-post",
        "lastVerified": "2024-12-19",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": "Compliance Measures"
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "EU AI Act"
    ],
    "notes": "Proactive compliance",
    "id": "ev-google-0004"
  },
  {
    "providerId": "google",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": true
    },
    "summary": "Multi-stage safety layers including toxicity detection, policy checks, and SynthID watermarking",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": "Safety Architecture"
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-google-0005"
  },
  {
    "providerId": "google",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Academic partnerships for AI safety research and independent evaluation of safety measures",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/research/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "e205ae7642725ed4f71fa3be19bd6386fe6df24ae4a980c30c71f388072f6cba",
        "relevantSection": "Collaborations"
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P12M",
    "reviewer": "initial-import",
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-google-0006"
  },
  {
    "providerId": "meta",
    "techniqueId": "tech-output-filtering",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Llama Guard output filtering with contextual moderation and open source validation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "research-paper",
        "lastVerified": "2025-10-17",
        "sourceHash": "0c3246d91cf658f086c17bffa92410fddf7bc14dd4c085540ddbeb8c877826b8",
        "relevantSection": "Output Moderation"
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Requires separate inference"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Open source implementation",
    "id": "ev-meta-0004"
  },
  {
    "providerId": "meta",
    "techniqueId": "tech-bias-detection-training",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "B",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Bias detection and mitigation with community-driven evaluation and open source validation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-10-17",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": "Section 5.2: Bias Evaluation"
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2024-12-19",
    "reviewFrequency": "P6M",
    "reviewer": "initial-import",
    "knownLimitations": [
      "Community-dependent validation"
    ],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "",
    "id": "ev-meta-0005"
  },
  {
    "id": "ev-openai-0027",
    "providerId": "openai",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Systematic evaluation protocols for dangerous capabilities including cybersecurity, CBRN, persuasion, and autonomy",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-17",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-openai-0028",
    "providerId": "openai",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Systematic red team exercises across multiple phases with diverse expert networks and real-world testing scenarios",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-17",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-openai-0031",
    "providerId": "openai",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "gpt-4o"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Detailed system cards providing comprehensive safety evaluations, methodologies, and results for each model release",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cdn.openai.com/gpt-4o-system-card.pdf",
        "documentType": "system-card",
        "lastVerified": "2025-10-17",
        "sourceHash": "e2579ecb185cbc13bac39f9dbf25e1917f78e1ea5a3a5023165c6614fb5db724",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-08-08",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-anthropic-0005",
    "providerId": "anthropic",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Personal information filtering as part of constitutional training data preparation",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/claude-3-model-card",
        "documentType": "system-card",
        "lastVerified": "2025-10-17",
        "sourceHash": "88ae851f53c3034d436816164ce49a876b333fa9b550fb7ef29838182b59ba7d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-03-04",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0006",
    "providerId": "anthropic",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Compliance with emerging AI regulations and industry standards through responsible scaling policy",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "9123e4f5a5c16224cf2679470d2ad2948b4c3d792e48c747a26bf4ae96d6a8c3",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0009",
    "providerId": "anthropic",
    "techniqueId": "tech-safety-reward-modeling",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Safety considerations integrated into reward modeling as part of constitutional AI framework",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2212.08073",
        "documentType": "research-paper",
        "lastVerified": "2025-10-17",
        "sourceHash": "9a456a07ad346e3372f9867d346f69f5b0f68b4c65f060aca0b8a13fa9d98e83",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2022-12-15",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0010",
    "providerId": "anthropic",
    "techniqueId": "tech-adversarial-training",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Adversarial testing integrated into constitutional AI training process for robustness",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2212.08073",
        "documentType": "research-paper",
        "lastVerified": "2025-10-17",
        "sourceHash": "9a456a07ad346e3372f9867d346f69f5b0f68b4c65f060aca0b8a13fa9d98e83",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2022-12-15",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBC"
  },
  {
    "id": "ev-anthropic-0011",
    "providerId": "anthropic",
    "techniqueId": "tech-red-team-data",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Red team exercises and data integration as part of responsible scaling policy and safety evaluation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "0e45632f715f3d9db9588e5036272af1d01e3097ca0a0e7294747997520672dc",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-anthropic-0012",
    "providerId": "anthropic",
    "techniqueId": "tech-input-classification",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Content classification systems for input filtering, though specific implementation details not public",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/claude-3-model-card",
        "documentType": "system-card",
        "lastVerified": "2025-10-17",
        "sourceHash": "88ae851f53c3034d436816164ce49a876b333fa9b550fb7ef29838182b59ba7d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-03-04",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0015",
    "providerId": "anthropic",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Safety monitoring systems in place, though specific real-time implementation details not disclosed",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/claude-3-model-card",
        "documentType": "system-card",
        "lastVerified": "2025-10-17",
        "sourceHash": "88ae851f53c3034d436816164ce49a876b333fa9b550fb7ef29838182b59ba7d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-03-04",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0016",
    "providerId": "anthropic",
    "techniqueId": "tech-contextual-safety",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Constitutional AI enables sophisticated contextual safety assessment through principle-based reasoning",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2212.08073",
        "documentType": "research-paper",
        "lastVerified": "2025-10-17",
        "sourceHash": "9a456a07ad346e3372f9867d346f69f5b0f68b4c65f060aca0b8a13fa9d98e83",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2022-12-15",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-anthropic-0017",
    "providerId": "anthropic",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive safety pipeline including constitutional training, RLHF, and responsible scaling evaluation",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "77f27b29ad936c2062276e16ba4cfa9035e2cb58805eb6f1af056c53b880bf89",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-anthropic-0018",
    "providerId": "anthropic",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "PII protection mechanisms integrated into constitutional AI framework",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/claude-3-model-card",
        "documentType": "system-card",
        "lastVerified": "2025-10-17",
        "sourceHash": "88ae851f53c3034d436816164ce49a876b333fa9b550fb7ef29838182b59ba7d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-03-04",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0019",
    "providerId": "anthropic",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Constitutional principles provide framework for configurable safety responses",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2212.08073",
        "documentType": "research-paper",
        "lastVerified": "2025-10-17",
        "sourceHash": "9a456a07ad346e3372f9867d346f69f5b0f68b4c65f060aca0b8a13fa9d98e83",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2022-12-15",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0020",
    "providerId": "anthropic",
    "techniqueId": "tech-audit-logging",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Audit and monitoring capabilities as part of responsible scaling policy framework",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "0d75d02abf0e5b9aa10b9ad907d9295145e5a8ffeeb1c2cb7cb240e5a8525e9b",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0021",
    "providerId": "anthropic",
    "techniqueId": "tech-watermarking",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "B",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Research into watermarking techniques for AI-generated content detection and provenance",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "c15ea68645930f5a8234fd8899b5fbe5545c2314898c6294262fef100f6e0397",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MRC"
  },
  {
    "id": "ev-anthropic-0023",
    "providerId": "anthropic",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "AI Safety Level (ASL) framework with clear classifications and deployment thresholds",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "0cef7cbc0500a0e71249927805abb9d4b60ca4f46068cc30c9593123c2ac53b2",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-anthropic-0024",
    "providerId": "anthropic",
    "techniqueId": "tech-safety-advisory",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Independent safety advisory structure as part of responsible scaling policy governance",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "691ec50346563d6aadac8005ebbc2390a496f6340940e6c08f70fc9e707ca780",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-anthropic-0025",
    "providerId": "anthropic",
    "techniqueId": "tech-incident-reporting",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Incident reporting and analysis systems integrated into responsible scaling framework",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "c7cfd0c0c167d64b67e4132149627d2fc018db932d1f3bcf753e8f68cb929b0e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-anthropic-0026",
    "providerId": "anthropic",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Usage monitoring capabilities for safety assessment and responsible scaling decisions",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "2fd32657adaab0536b9c82be7eb105e949ee726f1914500223c321586b2519ca",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-anthropic-0027",
    "providerId": "anthropic",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Systematic capability evaluation protocols as part of ASL framework and responsible scaling",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "eed2bda5951b77782f5d7a14f47655210ef0a6f49306ffe0629d01d809fbe055",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-anthropic-0028",
    "providerId": "anthropic",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive red team exercises for capability assessment and safety evaluation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "63ab16f8cb71c667c99ecd616248e122f0fe6abe8d6c06ff8fbdceb14a06b52d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-anthropic-0029",
    "providerId": "anthropic",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Proactive regulatory compliance through responsible scaling policy and industry engagement",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "05c12ae526bec83972616ef1075cbdf2b21877532d93d3126f9a8190cf210c53",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-anthropic-0030",
    "providerId": "anthropic",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Academic collaborations for safety research and constitutional AI development",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/research",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "06e22fb4559d566da514ebbe9e8d1092f8a01da1ba164d9a3f21608f2193e061",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-anthropic-0032",
    "providerId": "anthropic",
    "techniqueId": "tech-model-cards",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Model cards available for Claude models with technical specifications and safety information",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/claude-3-model-card",
        "documentType": "system-card",
        "lastVerified": "2025-10-17",
        "sourceHash": "88ae851f53c3034d436816164ce49a876b333fa9b550fb7ef29838182b59ba7d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-03-04",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-anthropic-0033",
    "providerId": "anthropic",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Extensive publication of constitutional AI research and safety methodologies",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/research",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "7899282dd5c20d9003e0df3092102a6cb8933c1a8769378f6143d204c82bb9fa",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-anthropic-0034",
    "providerId": "anthropic",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [
      "claude-3-opus",
      "claude-3-sonnet"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive policy documentation including responsible scaling policy and usage guidelines",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "9f2c3ea5fa4d2719b1fb9cef233bfc1e0e30eedc486f602ded399c9689438fa4",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-09-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-google-0002",
    "providerId": "google",
    "techniqueId": "tech-csam-detection",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "CSAM detection and removal systems implemented as part of standard content filtering pipeline",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0008",
    "providerId": "google",
    "techniqueId": "tech-constitutional-ai",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "B",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Research into constitutional AI principles and self-critique mechanisms for Gemini safety",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MRC"
  },
  {
    "id": "ev-google-0009",
    "providerId": "google",
    "techniqueId": "tech-safety-reward-modeling",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Safety considerations integrated into reward modeling for Gemini training optimization",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0010",
    "providerId": "google",
    "techniqueId": "tech-adversarial-training",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Adversarial safety tuning datasets used in RLHF process for robustness improvement",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2209.14375",
        "documentType": "research-paper",
        "lastVerified": "2025-10-17",
        "sourceHash": "e7df8fc1e41dfc3b47a781958fc53e6467f3b0ba3b0c10db5040f7924097709a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2022-09-29",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBC"
  },
  {
    "id": "ev-google-0011",
    "providerId": "google",
    "techniqueId": "tech-red-team-data",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Red team exercises and data integration for Gemini safety evaluation and improvement",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0012",
    "providerId": "google",
    "techniqueId": "tech-input-classification",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Multi-stage safety layer including toxicity and content classification for input processing",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0013",
    "providerId": "google",
    "techniqueId": "tech-output-filtering",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Output content filtering with toxicity classifiers and safety policy enforcement",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0014",
    "providerId": "google",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic prompt injection protection through input filtering and safety classifiers",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBC"
  },
  {
    "id": "ev-google-0015",
    "providerId": "google",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Real-time safety monitoring capabilities integrated into Gemini deployment infrastructure",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0016",
    "providerId": "google",
    "techniqueId": "tech-contextual-safety",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Contextual safety assessment capabilities, though specific implementation details not disclosed",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBC"
  },
  {
    "id": "ev-google-0018",
    "providerId": "google",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "PII detection and redaction capabilities integrated into safety pipeline",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0019",
    "providerId": "google",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Configurable safety policies and content filtering options for different deployment contexts",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0020",
    "providerId": "google",
    "techniqueId": "tech-audit-logging",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Audit logging capabilities for safety incident tracking and regulatory compliance",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://blog.google/technology/ai/google-ai-act-preparation/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0022",
    "providerId": "google",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "External red team engagement for Gemini safety evaluation and testing",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0023",
    "providerId": "google",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Internal safety classification system for model capabilities and deployment decisions",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0024",
    "providerId": "google",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Capability evaluation protocols for dangerous capabilities and safety assessment",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0025",
    "providerId": "google",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Red team exercises for capability discovery and safety evaluation across multiple domains",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "0ddea2af14c30a48cb3b185a13d9c8990ec89f5fac6db7081992a5330833601a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-google-0026",
    "providerId": "google",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive regulatory compliance frameworks including EU AI Act preparation and transparency measures",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://blog.google/technology/ai/google-ai-act-preparation/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPC"
  },
  {
    "id": "ev-google-0028",
    "providerId": "google",
    "techniqueId": "tech-model-cards",
    "modelIds": [
      "gemini-1.5-pro"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Model cards and technical documentation for Gemini models with safety information",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://deepmind.google/gemini/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "41226294bd499fce8505758df12a8a3d3c26b5b8c329ba19034fb0b188f2d8e6",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-02-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-meta-0002",
    "providerId": "meta",
    "techniqueId": "tech-csam-detection",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "CSAM detection and removal processes integrated into training data preparation",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "6e54182a2ae88a3f2f12637fbdfee43b7725093f25c1e5045da3b8e351796e50",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0003",
    "providerId": "meta",
    "techniqueId": "tech-copyright-filtering",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Copyright filtering mechanisms for training data with open source transparency",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-10-17",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0006",
    "providerId": "meta",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic regulatory compliance measures with limited international regulatory integration",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "1b24cd0b526d7c7ced29ff7da17c359ecc51d1a4625e76804527e45c8ea15a5c",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPC"
  },
  {
    "id": "ev-meta-0010",
    "providerId": "meta",
    "techniqueId": "tech-community-feedback",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community-driven safety feedback with open source evaluation harness and academic partnerships",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "85042874da0496f3cc4e16d6d049f694e464e806aba896b28860d01e0803869c",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPV"
  },
  {
    "id": "ev-meta-0013",
    "providerId": "meta",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic prompt injection protection through Llama Guard classification and community testing",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "5c1822d2b4419ddb625a16b934b2cd7a77ec2df950154c233dde3fc7021d42a8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBC"
  },
  {
    "id": "ev-meta-0014",
    "providerId": "meta",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Real-time safety monitoring capabilities through Llama Guard integration",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "544c14286eafdade18a65c0eddef6d66204df6113656781b8c0fdbaad23b5ee3",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0015",
    "providerId": "meta",
    "techniqueId": "tech-contextual-safety",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Contextual moderation capabilities through Llama Guard classification system",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "d8da3041c8b4b9ddd1bd14a23c6920f49f1cba8dfbd11f6d46414cff870e23c6",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBC"
  },
  {
    "id": "ev-meta-0016",
    "providerId": "meta",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Multi-stage safety pipeline with Llama Guard integration and community validation",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-10-17",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0017",
    "providerId": "meta",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "PII detection capabilities integrated into Llama Guard classification system",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "d49b1e388a72b4fb2aa4e868a4388f36a23cffb49f4f048d582ea5a871d017eb",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0018",
    "providerId": "meta",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Configurable safety policies through open source Llama Guard implementation",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "5cfdd3991da2214ab13103f001b0aa93f6a5769676e15788cb6ef90bcbe4d66c",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-12-07",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0019",
    "providerId": "meta",
    "techniqueId": "tech-audit-logging",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic audit logging capabilities with open source transparency and community oversight",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "5724ac7cd3095cb9706c5444ebc033d176eedcf6324951e2138eb8e7ee4aa5f8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0020",
    "providerId": "meta",
    "techniqueId": "tech-opensource-tools",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive open source safety tools including Llama Guard and evaluation frameworks",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://github.com/meta-llama",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "be5132ccc9b06a537d223e4fbf1d043695ff8f1f4ae6a59e303df21e3ef8123f",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-meta-0021",
    "providerId": "meta",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community-driven red team networks with academic partnerships and open evaluation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-10-17",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBV"
  },
  {
    "id": "ev-meta-0022",
    "providerId": "meta",
    "techniqueId": "tech-responsible-release",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Responsible release checklist with community evaluation and academic partnership validation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "9450250193592cff5eb41cba046785e5b65eb59c59ec8eef2b773be177c33e05",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-meta-0023",
    "providerId": "meta",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Extensive academic partnerships for safety evaluation and community-driven research",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "beefa169fbbefea0d0472a6d9e5d027f9eaf6843cd81cb3e11535450103099ec",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-meta-0024",
    "providerId": "meta",
    "techniqueId": "tech-safety-benchmarks",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Open safety benchmarks and evaluation metrics with community validation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-10-17",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-meta-0025",
    "providerId": "meta",
    "techniqueId": "tech-capability-monitoring",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community-driven capability evaluation protocols with open source validation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-10-17",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBV"
  },
  {
    "id": "ev-meta-0026",
    "providerId": "meta",
    "techniqueId": "tech-red-teaming",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "C",
    "ratingCriteria": {
      "publiclyDocumented": false,
      "independentlyVerified": true,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community-driven red team exercises with academic partnerships and open evaluation",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-10-17",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MBV"
  },
  {
    "id": "ev-meta-0027",
    "providerId": "meta",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic regulatory compliance frameworks with open source transparency",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "d4d185fd682c6353b662cea9ccf12ede4988699209d3781b42796032289fead4",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-meta-0028",
    "providerId": "meta",
    "techniqueId": "tech-community-governance",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": true,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Community governance model with open source development and academic oversight",
    "evidenceLevel": "primary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "da8d89cbcef025db1ca8990adce3e9d3ecb515cfb79b88b369c559075f7a122e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPV"
  },
  {
    "id": "ev-meta-0029",
    "providerId": "meta",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Open safety documentation with research papers and community evaluation results",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://arxiv.org/abs/2307.09288",
        "documentType": "research-paper",
        "lastVerified": "2025-10-17",
        "sourceHash": "1df284ce95f783002074bfe8f21d47c646b396ceb1736ea3ec0ea212fc070d91",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2023-07-18",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-meta-0030",
    "providerId": "meta",
    "techniqueId": "tech-model-cards",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Open model cards and technical specifications with community validation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "879c38238316ccf18e34f73ccfdc9baf7e5e53d15896d3f925d5175e6831fdb2",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-meta-0031",
    "providerId": "meta",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Extensive safety research publications with peer review and community validation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/research/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "388f214a80dff3bad4af40efa74262342c80f13cad24819160d421f65a75ef1f",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-meta-0032",
    "providerId": "meta",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Open policy and compliance documentation with community feedback integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "abde7a8f2aa8cac1ed5cd6ff8c00af881975fadae8d24d42e7ef9d5b92c04a82",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-meta-0033",
    "providerId": "meta",
    "techniqueId": "tech-community-evaluation",
    "modelIds": [
      "llama-3-70b"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Open community evaluation frameworks with academic partnerships and peer review",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://ai.meta.com/llama/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "300c634e93d43809808a672abd417b67c11c79c32b0ad39578be978f4836445b",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0001",
    "providerId": "amazon",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [
      "titan-express"
    ],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise-focused training data curation with customer data isolation and basic filtering",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "9efac3b7025e270277bf5a83d228de2c4326c5ee8216f5180b5c243d3582a659",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-amazon-0002",
    "providerId": "amazon",
    "techniqueId": "tech-csam-detection",
    "modelIds": [
      "titan-express"
    ],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Standard CSAM detection integrated into Bedrock platform with enterprise compliance",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-amazon-0003",
    "providerId": "amazon",
    "techniqueId": "tech-copyright-filtering",
    "modelIds": [
      "titan-express"
    ],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic copyright filtering with enterprise compliance and customer-configurable policies",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-amazon-0004",
    "providerId": "amazon",
    "techniqueId": "tech-bias-detection-training",
    "modelIds": [
      "titan-express"
    ],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited bias detection capabilities with enterprise compliance focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-amazon-0006",
    "providerId": "amazon",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise regulatory compliance frameworks with industry-specific guardrails",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://aws.amazon.com/compliance/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "633176575e7915cf5ab458b482a9223b73341521c3416b452f84a64f109edc88",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0007",
    "providerId": "amazon",
    "techniqueId": "tech-rlhf",
    "modelIds": [
      "titan-express"
    ],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic RLHF with customer fine-tuning options and domain-specific safety optimization",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "9efac3b7025e270277bf5a83d228de2c4326c5ee8216f5180b5c243d3582a659",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-amazon-0008",
    "providerId": "amazon",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Customer fine-tuning options with domain-specific safety configurations and enterprise controls",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/custom-models.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "301087a714a78598071f99b28724305dd5e13615552c20cd0db8eebd52422e32",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0013",
    "providerId": "amazon",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Multi-stage safety pipeline with Bedrock Guardrails and AWS security integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0014",
    "providerId": "amazon",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [
      "titan-express"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Advanced PII detection and redaction with enterprise-grade sensitive information filters",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails-sensitive-filters.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "9fd1ff0e2bb20a0f1e824ed07fd340b3fd17371908558ac417185250d6b8f122",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0015",
    "providerId": "amazon",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [
      "titan-express"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Highly configurable safety policies through Bedrock Guardrails with customer customization",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0016",
    "providerId": "amazon",
    "techniqueId": "tech-audit-logging",
    "modelIds": [
      "titan-express"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive audit logging through AWS CloudTrail with enterprise compliance tracking",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/logging-monitoring.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "e287c7b44ce23e4a471bebf2532b8c016fe17840bd35f1c048360118f99a599e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0017",
    "providerId": "amazon",
    "techniqueId": "tech-enterprise-integration",
    "modelIds": [
      "titan-express"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Deep enterprise security integration with AWS IAM, VPC, and compliance frameworks",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/security.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "3e82ddd78f2de438f7b597e4418a6287c23eff16d0bb89d37d7138cf6c11c247",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0018",
    "providerId": "amazon",
    "techniqueId": "tech-sovereignty-options",
    "modelIds": [
      "titan-express"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Data sovereignty options with AWS regions and customer-controlled encryption keys",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://aws.amazon.com/compliance/data-privacy/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "d49d5cbc2c82035e40ef2537dc546b4cf0883516722951815a1909f6b6b2ccc5",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0019",
    "providerId": "amazon",
    "techniqueId": "tech-incident-reporting",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise incident reporting through AWS support and compliance frameworks",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/logging-monitoring.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "e287c7b44ce23e4a471bebf2532b8c016fe17840bd35f1c048360118f99a599e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0020",
    "providerId": "amazon",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [
      "titan-express"
    ],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive usage monitoring through AWS CloudWatch with enterprise analytics",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/logging-monitoring.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "e287c7b44ce23e4a471bebf2532b8c016fe17840bd35f1c048360118f99a599e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-amazon-0021",
    "providerId": "amazon",
    "techniqueId": "tech-government-oversight",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise regulatory compliance with AWS compliance certifications and industry standards",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://aws.amazon.com/compliance/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "2e842872f127b0eb98e2d85d50a409740fcc0ad49209db8da93a5d227b9aeea2",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0022",
    "providerId": "amazon",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise-focused safety documentation with AWS service documentation and compliance guides",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "32a2364a54f944a4c728daf5c8d5df94575eb8f54e1a7395f2d96d65c3abfa2d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0023",
    "providerId": "amazon",
    "techniqueId": "tech-model-cards",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "AWS AI Service Cards with model specifications and enterprise integration documentation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://aws.amazon.com/machine-learning/ai-service-cards/",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-amazon-0024",
    "providerId": "amazon",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [
      "titan-express"
    ],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Comprehensive enterprise policy and compliance documentation with AWS security frameworks",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://aws.amazon.com/compliance/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "997dfab769ce7d52d13ecb6ef761dc4ebb47d8bb611ebe83ad137cbf28f34239",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0001",
    "providerId": "cohere",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise document focus with bias metrics during training for business use cases",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "77b4f99a02b01d729f45cd93f29835d403bff8658f9472ce4d5751d11b895af1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0002",
    "providerId": "cohere",
    "techniqueId": "tech-csam-detection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic CSAM detection as part of enterprise content filtering systems",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "77b4f99a02b01d729f45cd93f29835d403bff8658f9472ce4d5751d11b895af1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0003",
    "providerId": "cohere",
    "techniqueId": "tech-copyright-filtering",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Copyright filtering mechanisms for enterprise compliance and content policies",
    "evidenceLevel": "claimed",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "77b4f99a02b01d729f45cd93f29835d403bff8658f9472ce4d5751d11b895af1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPC"
  },
  {
    "id": "ev-cohere-0004",
    "providerId": "cohere",
    "techniqueId": "tech-bias-detection-training",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Bias metrics published during training with focus on enterprise fairness requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "77b4f99a02b01d729f45cd93f29835d403bff8658f9472ce4d5751d11b895af1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0005",
    "providerId": "cohere",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic PII reduction capabilities for enterprise data protection requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "77b4f99a02b01d729f45cd93f29835d403bff8658f9472ce4d5751d11b895af1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0006",
    "providerId": "cohere",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise compliance filtering with focus on business regulatory requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "77b4f99a02b01d729f45cd93f29835d403bff8658f9472ce4d5751d11b895af1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0007",
    "providerId": "cohere",
    "techniqueId": "tech-rlhf",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "RLHF for business use cases with enterprise-focused training optimization",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "77b4f99a02b01d729f45cd93f29835d403bff8658f9472ce4d5751d11b895af1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0008",
    "providerId": "cohere",
    "techniqueId": "tech-community-feedback",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited community feedback integration focused on enterprise customer requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "77b4f99a02b01d729f45cd93f29835d403bff8658f9472ce4d5751d11b895af1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0009",
    "providerId": "cohere",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Domain-specific fine-tuning for enterprise safety requirements and business use cases",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/fine-tuning",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "67a7a7e2fa5233021959123b0271f75d2c8cb091531e4141be7285d5d783070a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0010",
    "providerId": "cohere",
    "techniqueId": "tech-input-classification",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic input content classification with dual safety modes (strict/contextual)",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "77b4f99a02b01d729f45cd93f29835d403bff8658f9472ce4d5751d11b895af1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0011",
    "providerId": "cohere",
    "techniqueId": "tech-output-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Output filtering through dual safety modes with enterprise logging capabilities",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "77b4f99a02b01d729f45cd93f29835d403bff8658f9472ce4d5751d11b895af1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0012",
    "providerId": "cohere",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic prompt injection protection through safety mode filtering",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "77b4f99a02b01d729f45cd93f29835d403bff8658f9472ce4d5751d11b895af1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0013",
    "providerId": "cohere",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited real-time monitoring capabilities through safety mode enforcement",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "77b4f99a02b01d729f45cd93f29835d403bff8658f9472ce4d5751d11b895af1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0014",
    "providerId": "cohere",
    "techniqueId": "tech-contextual-safety",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Contextual safety assessment through CONTEXTUAL safety mode allowing nuanced moderation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "77b4f99a02b01d729f45cd93f29835d403bff8658f9472ce4d5751d11b895af1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0015",
    "providerId": "cohere",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic multi-stage pipeline with dual safety modes and enterprise integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "77b4f99a02b01d729f45cd93f29835d403bff8658f9472ce4d5751d11b895af1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0016",
    "providerId": "cohere",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Configurable safety policies through STRICT and CONTEXTUAL mode selection",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "77b4f99a02b01d729f45cd93f29835d403bff8658f9472ce4d5751d11b895af1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0017",
    "providerId": "cohere",
    "techniqueId": "tech-audit-logging",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise audit logging for disallowed prompts and safety mode enforcement",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "77b4f99a02b01d729f45cd93f29835d403bff8658f9472ce4d5751d11b895af1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0018",
    "providerId": "cohere",
    "techniqueId": "tech-enterprise-integration",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise security integration with on-premises deployment options",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cohere.com/enterprise",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0019",
    "providerId": "cohere",
    "techniqueId": "tech-sovereignty-options",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "On-premises deployment options for data sovereignty and enterprise control",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cohere.com/enterprise",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0020",
    "providerId": "cohere",
    "techniqueId": "tech-incident-reporting",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic incident reporting through enterprise support channels",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "77b4f99a02b01d729f45cd93f29835d403bff8658f9472ce4d5751d11b895af1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0021",
    "providerId": "cohere",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Usage monitoring and analytics for enterprise safety and compliance tracking",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "77b4f99a02b01d729f45cd93f29835d403bff8658f9472ce4d5751d11b895af1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0022",
    "providerId": "cohere",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise regulatory compliance frameworks with industry-specific requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cohere.com/enterprise",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0023",
    "providerId": "cohere",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited academic partnerships with focus on enterprise applications",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cohere.com/research",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "45ad4faaddb9d373531d17201f41ccdbd7ce723affe17eb9037bfbdf433039cf",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0024",
    "providerId": "cohere",
    "techniqueId": "tech-community-governance",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited community governance with enterprise customer feedback integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "77b4f99a02b01d729f45cd93f29835d403bff8658f9472ce4d5751d11b895af1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-cohere-0025",
    "providerId": "cohere",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic safety documentation focused on safety modes and enterprise implementation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "77b4f99a02b01d729f45cd93f29835d403bff8658f9472ce4d5751d11b895af1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0026",
    "providerId": "cohere",
    "techniqueId": "tech-model-cards",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited model cards and technical specifications with enterprise focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "942adb684a78c79b6e9cd8955c81c855e82e6479139f4f26e598a76ba67550f7",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0027",
    "providerId": "cohere",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited safety research publications with focus on enterprise applications",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://cohere.com/research",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "45ad4faaddb9d373531d17201f41ccdbd7ce723affe17eb9037bfbdf433039cf",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-cohere-0028",
    "providerId": "cohere",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise policy and compliance documentation with safety mode implementation guides",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.cohere.com/docs/safety-modes",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "77b4f99a02b01d729f45cd93f29835d403bff8658f9472ce4d5751d11b895af1",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-mistral-0001",
    "providerId": "mistral",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Lightweight filtering with community-driven approach and European data focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "f9a647b340d9d99b29355dea31ec3d114ab24922862ec2975c5c932a7d8adb60",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0002",
    "providerId": "mistral",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "European AI sovereignty focus with EU regulatory compliance measures",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "f9a647b340d9d99b29355dea31ec3d114ab24922862ec2975c5c932a7d8adb60",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-mistral-0003",
    "providerId": "mistral",
    "techniqueId": "tech-rlhf",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Minimal RLHF implementation with community feedback integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "f9a647b340d9d99b29355dea31ec3d114ab24922862ec2975c5c932a7d8adb60",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0004",
    "providerId": "mistral",
    "techniqueId": "tech-community-feedback",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community feedback integration for model improvement and safety enhancement",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "f9a647b340d9d99b29355dea31ec3d114ab24922862ec2975c5c932a7d8adb60",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0005",
    "providerId": "mistral",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Domain-specific fine-tuning capabilities with European regulatory focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.mistral.ai/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "c832508d68aaac27ca3cd9404bbbbd37446a673557605a2166bfcfd7df36c792",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-mistral-0006",
    "providerId": "mistral",
    "techniqueId": "tech-input-classification",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Moderation API for input content classification with lightweight approach",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "f9a647b340d9d99b29355dea31ec3d114ab24922862ec2975c5c932a7d8adb60",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0007",
    "providerId": "mistral",
    "techniqueId": "tech-output-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Content classification and filtering through Moderation API",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "f9a647b340d9d99b29355dea31ec3d114ab24922862ec2975c5c932a7d8adb60",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0008",
    "providerId": "mistral",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic prompt injection protection through content classification",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "f9a647b340d9d99b29355dea31ec3d114ab24922862ec2975c5c932a7d8adb60",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0009",
    "providerId": "mistral",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Lightweight safety pipeline with moderation API and content classification",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "f9a647b340d9d99b29355dea31ec3d114ab24922862ec2975c5c932a7d8adb60",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0010",
    "providerId": "mistral",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic configurable policies through moderation API categories",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "f9a647b340d9d99b29355dea31ec3d114ab24922862ec2975c5c932a7d8adb60",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0011",
    "providerId": "mistral",
    "techniqueId": "tech-community-governance",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Community governance model with European AI sovereignty principles",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "f9a647b340d9d99b29355dea31ec3d114ab24922862ec2975c5c932a7d8adb60",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0012",
    "providerId": "mistral",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "EU-focused regulatory compliance with European AI sovereignty emphasis",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "f9a647b340d9d99b29355dea31ec3d114ab24922862ec2975c5c932a7d8adb60",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-mistral-0013",
    "providerId": "mistral",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited academic partnerships with European research institutions",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/research",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0014",
    "providerId": "mistral",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic safety documentation with moderation API specifications",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "f9a647b340d9d99b29355dea31ec3d114ab24922862ec2975c5c932a7d8adb60",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0015",
    "providerId": "mistral",
    "techniqueId": "tech-model-cards",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited model cards and technical documentation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://docs.mistral.ai/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "c832508d68aaac27ca3cd9404bbbbd37446a673557605a2166bfcfd7df36c792",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0016",
    "providerId": "mistral",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Minimal safety research publications with focus on efficiency",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/research",
        "documentType": "documentation",
        "lastVerified": "2025-07-10",
        "sourceHash": "0000000000000000000000000000000000000000000000000000000000000000",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-mistral-0017",
    "providerId": "mistral",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic policy documentation with EU regulatory compliance focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://mistral.ai/news/mistral-moderation",
        "documentType": "blog-post",
        "lastVerified": "2025-10-17",
        "sourceHash": "f9a647b340d9d99b29355dea31ec3d114ab24922862ec2975c5c932a7d8adb60",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-11-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0001",
    "providerId": "baidu",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Chinese regulatory compliance with government-approved content filtering",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "ba003434d50bf363629b1552c68f3658852aecac875a83c713b6570b2881d50a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0002",
    "providerId": "baidu",
    "techniqueId": "tech-csam-detection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "CSAM detection in compliance with Chinese internet regulations",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "ba003434d50bf363629b1552c68f3658852aecac875a83c713b6570b2881d50a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0003",
    "providerId": "baidu",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive Chinese regulatory compliance with government oversight integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "ba003434d50bf363629b1552c68f3658852aecac875a83c713b6570b2881d50a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-baidu-0004",
    "providerId": "baidu",
    "techniqueId": "tech-rlhf",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "RLHF with alignment to Chinese values and regulatory requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "ba003434d50bf363629b1552c68f3658852aecac875a83c713b6570b2881d50a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0005",
    "providerId": "baidu",
    "techniqueId": "tech-input-classification",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Real-time censorship and political content filtering for input classification",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "ba003434d50bf363629b1552c68f3658852aecac875a83c713b6570b2881d50a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0006",
    "providerId": "baidu",
    "techniqueId": "tech-output-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Political content filtering and real-time censorship for output content",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "ba003434d50bf363629b1552c68f3658852aecac875a83c713b6570b2881d50a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0007",
    "providerId": "baidu",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic prompt injection protection through content filtering and government oversight",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "ba003434d50bf363629b1552c68f3658852aecac875a83c713b6570b2881d50a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0008",
    "providerId": "baidu",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Real-time monitoring with government oversight and regulatory compliance",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "ba003434d50bf363629b1552c68f3658852aecac875a83c713b6570b2881d50a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0009",
    "providerId": "baidu",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Multi-stage pipeline with government oversight and political content filtering",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "ba003434d50bf363629b1552c68f3658852aecac875a83c713b6570b2881d50a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0010",
    "providerId": "baidu",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Government-configured safety policies with Chinese regulatory compliance",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "ba003434d50bf363629b1552c68f3658852aecac875a83c713b6570b2881d50a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0011",
    "providerId": "baidu",
    "techniqueId": "tech-audit-logging",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Government audit logging and compliance tracking for regulatory oversight",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "ba003434d50bf363629b1552c68f3658852aecac875a83c713b6570b2881d50a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0012",
    "providerId": "baidu",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Direct government oversight and regulatory compliance with Chinese authorities",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "ba003434d50bf363629b1552c68f3658852aecac875a83c713b6570b2881d50a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-baidu-0013",
    "providerId": "baidu",
    "techniqueId": "tech-incident-reporting",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Government incident reporting with regulatory compliance tracking",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "ba003434d50bf363629b1552c68f3658852aecac875a83c713b6570b2881d50a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0014",
    "providerId": "baidu",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Usage monitoring with government oversight and regulatory compliance",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "ba003434d50bf363629b1552c68f3658852aecac875a83c713b6570b2881d50a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0015",
    "providerId": "baidu",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Comprehensive Chinese regulatory compliance with government framework integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "ba003434d50bf363629b1552c68f3658852aecac875a83c713b6570b2881d50a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-baidu-0016",
    "providerId": "baidu",
    "techniqueId": "tech-stakeholder-engagement",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited academic partnerships with Chinese research institutions",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "ba003434d50bf363629b1552c68f3658852aecac875a83c713b6570b2881d50a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0017",
    "providerId": "baidu",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited international transparency with Chinese regulatory documentation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "ba003434d50bf363629b1552c68f3658852aecac875a83c713b6570b2881d50a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0018",
    "providerId": "baidu",
    "techniqueId": "tech-model-cards",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic model cards with Chinese regulatory compliance information",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "ba003434d50bf363629b1552c68f3658852aecac875a83c713b6570b2881d50a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0019",
    "providerId": "baidu",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Limited international safety research publications with regulatory focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://research.baidu.com/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "0129a6649f7b95098cc2b812c5293740889775136b8738106035d05363431f8d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-baidu-0020",
    "providerId": "baidu",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Chinese regulatory documentation with limited international transparency",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://wenxin.baidu.com/wenxin/docs",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "ba003434d50bf363629b1552c68f3658852aecac875a83c713b6570b2881d50a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0001",
    "providerId": "alibaba",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Commercial focus with regulatory compliance and business-oriented filtering",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "f802145586f847f90b5e3c9819e75c71dbb93118c7a091e69bd9dfa1b1211cd8",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0002",
    "providerId": "alibaba",
    "techniqueId": "tech-csam-detection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "CSAM detection for Chinese regulatory compliance and commercial deployment",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "0a80bd361c787c272065118b2d440d2b4e4106eaabdc5579d7e1cc74c3f92645",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0003",
    "providerId": "alibaba",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Chinese regulatory compliance with commercial focus and efficiency optimization",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "12e914531803cbf769517aa786fc0acf6323fa2dbebc9b89b7fd3fab4c4cb4ac",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0004",
    "providerId": "alibaba",
    "techniqueId": "tech-rlhf",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Business-oriented RLHF with efficiency focus and commercial optimization",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "a8517e28cb348b4fbc429061b9a49195ad758657fff5b76332f21a7de0bbc53d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0005",
    "providerId": "alibaba",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Domain-specific fine-tuning for business process automation and commercial safety",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "63a3c2d1c6b0a8f207006cb1af65deab06f6d71f31b2693e3f05d5cb06b4629a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0006",
    "providerId": "alibaba",
    "techniqueId": "tech-input-classification",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise content filtering with customer customization for business use cases",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "dde151ef4cf278c7f1a092880b040d5dc79b62d1507e31edc4c60a733cc30de7",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0007",
    "providerId": "alibaba",
    "techniqueId": "tech-output-filtering",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Customer-customizable output filtering for enterprise and commercial applications",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "976e2a6f8bdfdeb30b06867224d71ee4c5bddfdf98f9526dfff1bcdec5a3541a",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0008",
    "providerId": "alibaba",
    "techniqueId": "tech-prompt-injection-protection",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic prompt injection protection through enterprise content filtering",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "bd67940c0aa9d13ab762e67072dbeca5176179af57641241dc3676c3ce7e8234",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0009",
    "providerId": "alibaba",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Real-time monitoring for commercial applications with business process integration",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "13eeb0a4b99087a7ff6e1d89c6b3e2cbbe3b6d137ed6562325b799f63ea51dce",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0010",
    "providerId": "alibaba",
    "techniqueId": "tech-multistage-pipeline",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Multi-stage pipeline with cloud integration and business process automation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "50b07883d6a4d037c6e90a6552f6a9753e11584a80f1189bd3fcc28baea8bafb",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0011",
    "providerId": "alibaba",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic PII detection for enterprise data protection and commercial compliance",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "c65c9184e84b82b99a3caa9ac25fb07584d85f7af6b33833cde0affd21ab6a36",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0012",
    "providerId": "alibaba",
    "techniqueId": "tech-configurable-policies",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Customer-configurable safety policies for enterprise deployment and business needs",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "11c9eea2cd9413953524afc9fe10d14355066bc5548d787e27ad45e162094acb",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0013",
    "providerId": "alibaba",
    "techniqueId": "tech-audit-logging",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise audit logging for business compliance and commercial accountability",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "c0cf38779af2fd249824e4120db42afb3534669944210e64660e3a933b0e5a25",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0014",
    "providerId": "alibaba",
    "techniqueId": "tech-enterprise-integration",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Cloud integration with Alibaba Cloud security and business process automation",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "caa79f10c5bb7bf9a0808236adb654f548e1ef7bdeb672d8bcb5fcafbe07491e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0015",
    "providerId": "alibaba",
    "techniqueId": "tech-sovereignty-options",
    "modelIds": [],
    "rating": "high",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": true,
      "automatedTest": false
    },
    "summary": "Data sovereignty options through Alibaba Cloud with regional deployment flexibility",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "e6a1d784c615538b59001492faa9c1858586ff6061fbc5b2a4132d061c0a159d",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P6M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: HPU"
  },
  {
    "id": "ev-alibaba-0016",
    "providerId": "alibaba",
    "techniqueId": "tech-incident-reporting",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic incident reporting through enterprise support and commercial channels",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "5ce7961fb964aadb9d241c7ffcc2da0ca30ce580bffc2509bfd532ed1018d768",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0017",
    "providerId": "alibaba",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Enterprise usage monitoring with business analytics and commercial optimization",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "92b9d61ea05b99e243dc817f023b8cdd7b394aeeb3747fa2113f532750a2bdbe",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0018",
    "providerId": "alibaba",
    "techniqueId": "tech-government-oversight",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Chinese regulatory compliance frameworks with commercial focus and enterprise requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "ca4c81752470526c3b4352ab15c4a96af1a2dca02c0706b6daf4d3c857dba77f",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-alibaba-0019",
    "providerId": "alibaba",
    "techniqueId": "tech-safety-documentation",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Business documentation with limited research disclosure and commercial focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "0ffde0955971d0c9d9d6ed96b653cdb258e2ddac76488dd0aea7fe90b992286e",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0020",
    "providerId": "alibaba",
    "techniqueId": "tech-model-cards",
    "modelIds": [],
    "rating": "low",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Basic model cards with commercial specifications and business application focus",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "4e91009b26ccceb00ec229320ef055a009c5a73ce8b37d150390fc70046eb4ee",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: LPU"
  },
  {
    "id": "ev-alibaba-0021",
    "providerId": "alibaba",
    "techniqueId": "tech-policy-documentation",
    "modelIds": [],
    "rating": "medium",
    "severityBand": "P",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "summary": "Business policy documentation with enterprise compliance and commercial requirements",
    "evidenceLevel": "secondary",
    "sourceUrls": [
      {
        "url": "https://tongyi.aliyun.com/qianwen/",
        "documentType": "documentation",
        "lastVerified": "2025-10-17",
        "sourceHash": "a8382848e10ae948d5a604ecb3a5f09d97fc9ba91fe2ca7bc30435a1dcc39275",
        "relevantSection": ""
      }
    ],
    "implementationDate": "2024-01-01",
    "lastReviewed": "2025-07-10",
    "reviewFrequency": "P12M",
    "reviewer": "dataset-import",
    "evaluationMetrics": [],
    "knownLimitations": [],
    "deploymentScope": "all-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "notes": "Imported from original dataset with rating code: MPU"
  },
  {
    "id": "ev-x-constitutional-ai-001",
    "providerId": "x",
    "techniqueId": "tech-constitutional-ai",
    "modelIds": [],
    "summary": "Constitutional AI training methodology implemented in Grok-4 to align model behavior with human values and safety principles",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.ai/news/grok-4",
        "documentType": "blog-post",
        "relevantSection": "Training and Safety",
        "lastVerified": "2025-07-24",
        "sourceHash": "c6d3e7bfa462aef2201bdff29ed7472fefb66eed1a8478ae51f05b63a54e3de3"
      }
    ],
    "knownLimitations": [
      "Limited public details on specific constitutional principles",
      "No published effectiveness metrics"
    ],
    "notes": "Grok-4 implements constitutional AI for value alignment",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-realtime-fact-check-002",
    "providerId": "x",
    "techniqueId": "tech-realtime-fact-checking",
    "modelIds": [],
    "summary": "Integration with X platform's real-time information feed to fact-check claims and provide current information verification",
    "rating": "medium-high",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.ai/news/grok-4",
        "documentType": "blog-post",
        "relevantSection": "Real-time Information Access",
        "lastVerified": "2025-07-24",
        "sourceHash": "c6d3e7bfa462aef2201bdff29ed7472fefb66eed1a8478ae51f05b63a54e3de3"
      }
    ],
    "knownLimitations": [
      "Dependent on X platform data quality",
      "May amplify trending misinformation"
    ],
    "notes": "Unique capability leveraging X's real-time data stream",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "premium-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-platform-context-003",
    "providerId": "x",
    "techniqueId": "tech-contextual-safety",
    "modelIds": [],
    "summary": "Safety measures that consider broader X platform context, user interaction history, and social graph for contextual risk assessment",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.com/privacy",
        "documentType": "privacy-policy",
        "relevantSection": "Data Usage for AI Services",
        "lastVerified": "2025-10-17",
        "sourceHash": "525e82e5d772081f3eff4f8ee2ff90a51dae95a66b8d9af1c142badc05370900"
      }
    ],
    "knownLimitations": [
      "Privacy implications of using social context",
      "Potential for social bias amplification"
    ],
    "notes": "Leverages X platform social context for safety",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-multimodal-safety-004",
    "providerId": "x",
    "techniqueId": "tech-multimodal-safety-alignment",
    "modelIds": [],
    "summary": "Cross-modal safety alignment for Grok-4's multimodal capabilities, ensuring safety across text, image, and audio interactions",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.ai/news/grok-4",
        "documentType": "blog-post",
        "relevantSection": "Multimodal Capabilities",
        "lastVerified": "2025-07-24",
        "sourceHash": "c6d3e7bfa462aef2201bdff29ed7472fefb66eed1a8478ae51f05b63a54e3de3"
      }
    ],
    "knownLimitations": [
      "Cross-modal safety interactions are complex",
      "Limited multimodal safety evaluation data"
    ],
    "notes": "Addresses safety across multiple modalities in Grok-4",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-input-classification-005",
    "providerId": "x",
    "techniqueId": "tech-input-classification",
    "modelIds": [],
    "summary": "Pre-processing classification of user inputs to identify potential safety risks before processing by Grok-4",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://help.x.com/en/rules-and-policies",
        "documentType": "policy-documentation",
        "relevantSection": "Content Moderation",
        "lastVerified": "2025-07-24",
        "sourceHash": "b737b99b7dde781f17abe0db3c6129d63edce718f07dad841b9e15ffd47fef2a"
      }
    ],
    "knownLimitations": [
      "May block benign content",
      "Context-dependent risks challenging to detect"
    ],
    "notes": "Integrated with X platform content moderation",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-output-filtering-006",
    "providerId": "x",
    "techniqueId": "tech-output-filtering",
    "modelIds": [],
    "summary": "Post-generation filtering of Grok-4 outputs for safety violations before presentation to users",
    "rating": "medium-high",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://help.x.com/en/rules-and-policies",
        "documentType": "policy-documentation",
        "relevantSection": "AI Content Guidelines",
        "lastVerified": "2025-07-24",
        "sourceHash": "b737b99b7dde781f17abe0db3c6129d63edce718f07dad841b9e15ffd47fef2a"
      }
    ],
    "knownLimitations": [
      "May alter intended meaning",
      "Can be overly restrictive"
    ],
    "notes": "Aligned with X platform community guidelines",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-realtime-monitoring-007",
    "providerId": "x",
    "techniqueId": "tech-realtime-monitoring",
    "modelIds": [],
    "summary": "Continuous monitoring of Grok-4 interactions for safety violations and emerging risk patterns",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.com/tos",
        "documentType": "terms-of-service",
        "relevantSection": "Monitoring and Enforcement",
        "lastVerified": "2025-10-17",
        "sourceHash": "a0ad0f1b98467d88516205429b74919e1df3e85c007877f3fabfdba2e17e6f25"
      }
    ],
    "knownLimitations": [
      "Latency impact on user experience",
      "May miss contextual nuances"
    ],
    "notes": "Integrated with X platform monitoring infrastructure",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-pii-detection-008",
    "providerId": "x",
    "techniqueId": "tech-pii-detection-inference",
    "modelIds": [],
    "summary": "Real-time detection and redaction of personally identifiable information in Grok-4 interactions",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.com/privacy",
        "documentType": "privacy-policy",
        "relevantSection": "Personal Information Protection",
        "lastVerified": "2025-10-17",
        "sourceHash": "d94563a78ecab12f4682c2a81036bb246353dc0854b7d15a4e0f9a4e0e7bda77"
      }
    ],
    "knownLimitations": [
      "Context-dependent PII challenging to detect",
      "May miss novel PII patterns"
    ],
    "notes": "Complies with X platform privacy standards",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "GDPR",
      "CCPA"
    ],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-training-filtering-009",
    "providerId": "x",
    "techniqueId": "tech-training-data-filtering",
    "modelIds": [],
    "summary": "Systematic filtering of training data for Grok-4 to remove harmful, biased, or inappropriate content",
    "rating": "medium-low",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.ai/news/grok-4",
        "documentType": "blog-post",
        "relevantSection": "Data and Training",
        "lastVerified": "2025-07-24",
        "sourceHash": "c6d3e7bfa462aef2201bdff29ed7472fefb66eed1a8478ae51f05b63a54e3de3"
      }
    ],
    "knownLimitations": [
      "Limited transparency on filtering criteria",
      "May introduce demographic biases"
    ],
    "notes": "Standard pre-training data curation practices",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  },
  {
    "id": "ev-x-audit-logging-010",
    "providerId": "x",
    "techniqueId": "tech-audit-logging",
    "modelIds": [],
    "summary": "Comprehensive logging of Grok-4 safety-relevant events and decisions for audit and improvement purposes",
    "rating": "medium",
    "implementationDate": "2024-12-12",
    "lastReviewed": "2025-07-24",
    "evidenceLevel": "primary",
    "ratingCriteria": {
      "publiclyDocumented": true,
      "independentlyVerified": false,
      "quantitativeMetrics": false,
      "automatedTest": false
    },
    "sourceUrls": [
      {
        "url": "https://x.com/tos",
        "documentType": "terms-of-service",
        "relevantSection": "Data Retention and Logging",
        "lastVerified": "2025-10-17",
        "sourceHash": "3b20c3a7177ec66a74d46f321b0e833c54d12ea265f8461f313fde72c3fec7a0"
      }
    ],
    "knownLimitations": [
      "Storage and privacy considerations",
      "Log completeness not specified"
    ],
    "notes": "Supports X platform compliance requirements",
    "reviewer": "evidence-extractor-script",
    "deploymentScope": "limited-users",
    "geographicRestrictions": [],
    "complianceStandards": [
      "SOC2"
    ],
    "reviewFrequency": "P3M",
    "severityBand": "P",
    "evaluationMetrics": []
  }
]