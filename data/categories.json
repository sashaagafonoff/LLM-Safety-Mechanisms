[
  {
    "id": "cat-pre-training-safety",
    "name": "Pre-training Data Safety",
    "description": "Measures applied during data collection and curation, including bias auditing, copyright filtering, and CSAM detection",
    "color": "#2E7D32"
  },
  {
    "id": "cat-alignment",
    "name": "Alignment & Fine-Tuning",
    "description": "Techniques to align model behavior with human intent, including RLHF, Direct Preference Optimization (DPO), and Constitutional AI",
    "color": "#1976D2"
  },
  {
    "id": "cat-runtime-safety",
    "name": "Runtime Guardrails & Monitoring",
    "description": "Active mechanisms operating during inference, including input/output filtering, hallucination checks, and circuit breakers",
    "color": "#7B1FA2"
  },
  {
    "id": "cat-evaluation",
    "name": "Evaluation & Red Teaming",
    "description": "Processes for stress-testing models, including automated adversarial attacks, safety benchmarking, and human red teaming",
    "color": "#D32F2F"
  },
  {
    "id": "cat-transparency",
    "name": "Transparency & Documentation",
    "description": "Standardized artifacts for disclosing capabilities, limitations, and safety properties (e.g., Model Cards, System Cards)",
    "color": "#F57C00"
  },
  {
    "id": "cat-governance",
    "name": "Governance & Oversight",
    "description": "Organizational structures and participatory processes for safety oversight, release management, and stakeholder engagement",
    "color": "#455A64"
  },
  {
    "id": "cat-privacy-security",
    "name": "Privacy, Security & IP",
    "description": "Mechanisms for data protection, machine unlearning, PII redaction, and defense against privacy attacks",
    "color": "#795548"
  }
]