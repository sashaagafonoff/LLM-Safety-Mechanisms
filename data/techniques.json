[
  {
    "id": "tech-training-data-filtering",
    "name": "Training Data Filtering",
    "categoryId": "cat-pre-training-safety",
    "description": "Systematic removal of harmful content from training datasets",
    "implementationMethods": [
      "RuleBased",
      "EmbeddedClassifier"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "May introduce demographic biases"
    ],
    "aliases": [
      "Data Curation",
      "Dataset Cleaning"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      6
    ]
  },
  {
    "id": "tech-csam-detection",
    "name": "CSAM Detection & Removal",
    "categoryId": "cat-pre-training-safety",
    "description": "Automated detection and removal of child sexual abuse material",
    "implementationMethods": [
      "EmbeddedClassifier",
      "ExternalSafetyService"
    ],
    "governingStandards": [
      "NCMEC"
    ],
    "licence": null,
    "knownLimitations": [
      "False positive rates not disclosed"
    ],
    "aliases": [
      "CSAM Filtering"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1
    ]
  },
  {
    "id": "tech-rlhf",
    "name": "Reinforcement Learning from Human Feedback",
    "categoryId": "cat-alignment",
    "description": "Training models to align with human preferences through feedback",
    "implementationMethods": [
      "HumanModeration",
      "EmbeddedClassifier"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Subject to annotator biases",
      "Expensive to scale"
    ],
    "aliases": [
      "RLHF"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      5
    ]
  },
  {
    "id": "tech-csam-detection",
    "name": "CSAM Detection & Removal",
    "categoryId": "cat-pre-training-safety",
    "description": "Automated detection and removal of child sexual abuse material",
    "implementationMethods": [
      "EmbeddedClassifier",
      "ExternalSafetyService"
    ],
    "governingStandards": [
      "NCMEC"
    ],
    "licence": null,
    "knownLimitations": [
      "False positive rates not disclosed"
    ],
    "aliases": [
      "CSAM Filtering"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1
    ]
  },
  {
    "id": "tech-rlhf",
    "name": "Reinforcement Learning from Human Feedback",
    "categoryId": "cat-alignment",
    "description": "Training models to align with human preferences through feedback",
    "implementationMethods": [
      "HumanModeration",
      "EmbeddedClassifier"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Subject to annotator biases",
      "Expensive to scale"
    ],
    "aliases": [
      "RLHF"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      5
    ]
  },
  {
    "id": "tech-copyright-filtering",
    "name": "Copyright Content Filtering",
    "categoryId": "cat-pre-training-safety",
    "description": "Detection and removal of copyrighted content from training datasets",
    "implementationMethods": [
      "RuleBased",
      "EmbeddedClassifier"
    ],
    "governingStandards": [
      "DMCA"
    ],
    "licence": null,
    "knownLimitations": [
      "Difficult to detect all copyrighted content",
      "May remove fair use content"
    ],
    "aliases": [
      "Copyright Protection"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      6
    ]
  },
  {
    "id": "tech-bias-detection-training",
    "name": "Bias Detection in Training Data",
    "categoryId": "cat-pre-training-safety",
    "description": "Detection and mitigation of demographic and cultural biases in training data",
    "implementationMethods": [
      "EmbeddedClassifier",
      "RuleBased"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Cannot detect all forms of bias",
      "Definitions of bias vary culturally"
    ],
    "aliases": [
      "Training Data Debiasing"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      2
    ]
  },
  {
    "id": "tech-pii-reduction",
    "name": "PII Reduction",
    "categoryId": "cat-pre-training-safety",
    "description": "Detection and removal of personal information from training data",
    "implementationMethods": [
      "RuleBased",
      "EmbeddedClassifier"
    ],
    "governingStandards": [
      "GDPR",
      "CCPA"
    ],
    "licence": null,
    "knownLimitations": [
      "Cannot catch all PII",
      "Context-dependent PII is challenging"
    ],
    "aliases": [
      "PII Filtering",
      "Personal Data Removal"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      3
    ]
  },
  {
    "id": "tech-constitutional-ai",
    "name": "Constitutional AI / Self-Critique",
    "categoryId": "cat-alignment",
    "description": "Training models to critique and revise their own outputs based on constitutional principles",
    "implementationMethods": [
      "EmbeddedClassifier",
      "RetrievalAugmentation"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Requires careful principle design",
      "May be overly conservative"
    ],
    "aliases": [
      "CAI",
      "Constitutional AI"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      5,
      10
    ]
  },
  {
    "id": "tech-safety-reward-modeling",
    "name": "Safety Reward Modeling",
    "categoryId": "cat-alignment",
    "description": "Separate reward models specifically optimized for safety outcomes",
    "implementationMethods": [
      "EmbeddedClassifier",
      "HumanModeration"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "May conflict with capability objectives",
      "Hard to balance multiple safety goals"
    ],
    "aliases": [
      "Safety RM"
    ],
    "requiredTechniqueIds": [
      "tech-rlhf"
    ],
    "riskAreaIds": [
      1,
      2,
      5
    ]
  },
  {
    "id": "tech-input-classification",
    "name": "Input Content Classification",
    "categoryId": "cat-inference-safeguards",
    "description": "Classification of input prompts for safety risks before processing",
    "implementationMethods": [
      "EmbeddedClassifier",
      "ExternalSafetyService"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "May block benign content",
      "Context-dependent risks hard to catch"
    ],
    "aliases": [
      "Input Filtering",
      "Prompt Classification"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      4,
      5
    ]
  },
  {
    "id": "tech-output-filtering",
    "name": "Output Content Filtering",
    "categoryId": "cat-inference-safeguards",
    "description": "Post-generation filtering of model outputs for safety violations",
    "implementationMethods": [
      "EmbeddedClassifier",
      "ExternalSafetyService",
      "RuleBased"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "May alter intended meaning",
      "Can be overly restrictive"
    ],
    "aliases": [
      "Output Moderation"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      3,
      5,
      6
    ]
  },
  {
    "id": "tech-prompt-injection-protection",
    "name": "Prompt Injection Protection",
    "categoryId": "cat-inference-safeguards",
    "description": "Detection and prevention of prompt injection attacks",
    "implementationMethods": [
      "RuleBased",
      "EmbeddedClassifier"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Evolving attack vectors",
      "May restrict legitimate use cases"
    ],
    "aliases": [
      "Injection Defense"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      4
    ]
  },
  {
    "id": "tech-red-teaming",
    "name": "Red Team Exercises",
    "categoryId": "cat-governance",
    "description": "Systematic adversarial testing by security experts",
    "implementationMethods": [
      "HumanModeration",
      "AdversarialRedTeam"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Limited by red team expertise",
      "Cannot test all scenarios"
    ],
    "aliases": [
      "Adversarial Testing",
      "Red Teaming"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      3,
      4,
      5,
      6,
      9,
      10
    ]
  },
  {
    "id": "tech-capability-monitoring",
    "name": "Capability Threshold Monitoring",
    "categoryId": "cat-governance",
    "description": "Monitoring model capabilities against predefined safety thresholds",
    "implementationMethods": [
      "Other"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Thresholds may be arbitrary",
      "Capabilities hard to measure precisely"
    ],
    "aliases": [
      "Capability Evaluation"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      9,
      10
    ]
  },
  {
    "id": "tech-safety-documentation",
    "name": "Comprehensive Safety Documentation",
    "categoryId": "cat-transparency",
    "description": "Detailed public documentation of safety measures and evaluations",
    "implementationMethods": [
      "Other"
    ],
    "governingStandards": [
      "ISO 26000"
    ],
    "licence": null,
    "knownLimitations": [
      "May not cover proprietary methods",
      "Can become outdated"
    ],
    "aliases": [
      "Safety Cards",
      "System Cards"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      7
    ]
  },
  {
    "id": "tech-adversarial-training",
    "name": "Adversarial Training",
    "categoryId": "cat-alignment",
    "description": "Training with adversarial examples to improve robustness",
    "implementationMethods": [
      "AdversarialRedTeam"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Cannot cover all attack vectors"
    ],
    "aliases": [
      "Adversarial Robustness Training"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      4
    ]
  },
  {
    "id": "tech-red-team-data",
    "name": "Red Team Data Integration",
    "categoryId": "cat-alignment",
    "description": "Incorporating red team findings into training data",
    "implementationMethods": [
      "AdversarialRedTeam",
      "HumanModeration"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Limited by red team scope"
    ],
    "aliases": [],
    "requiredTechniqueIds": [
      "tech-red-teaming"
    ],
    "riskAreaIds": [
      1,
      2,
      4,
      5
    ]
  },
  {
    "id": "tech-realtime-monitoring",
    "name": "Real-time Safety Monitoring",
    "categoryId": "cat-inference-safeguards",
    "description": "Live monitoring of model outputs for safety violations",
    "implementationMethods": [
      "ExternalSafetyService",
      "EmbeddedClassifier"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Latency impact",
      "May miss context"
    ],
    "aliases": [
      "Live Safety Monitoring"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      3,
      4,
      5
    ]
  },
  {
    "id": "tech-contextual-safety",
    "name": "Contextual Safety Assessment",
    "categoryId": "cat-inference-safeguards",
    "description": "Context-aware safety evaluation considering conversation history",
    "implementationMethods": [
      "EmbeddedClassifier",
      "RetrievalAugmentation"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Complex contexts challenging"
    ],
    "aliases": [],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      5
    ]
  },
  {
    "id": "tech-multistage-pipeline",
    "name": "Multi-stage Safety Pipeline",
    "categoryId": "cat-inference-safeguards",
    "description": "Multiple layers of safety checks at different stages",
    "implementationMethods": [
      "Other"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Increased complexity",
      "Potential for conflicts"
    ],
    "aliases": [],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      3,
      4,
      5
    ]
  },
  {
    "id": "tech-pii-detection-inference",
    "name": "PII Detection & Redaction",
    "categoryId": "cat-inference-safeguards",
    "description": "Real-time detection and redaction of personal information",
    "implementationMethods": [
      "RuleBased",
      "EmbeddedClassifier"
    ],
    "governingStandards": [
      "GDPR",
      "CCPA"
    ],
    "licence": null,
    "knownLimitations": [
      "Context-dependent PII hard to catch"
    ],
    "aliases": [
      "PII Redaction"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      3
    ]
  },
  {
    "id": "tech-configurable-policies",
    "name": "Configurable Safety Policies",
    "categoryId": "cat-inference-safeguards",
    "description": "User or admin configurable safety thresholds and policies",
    "implementationMethods": [
      "Other"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Requires user expertise"
    ],
    "aliases": [],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      3,
      4,
      5
    ]
  },
  {
    "id": "tech-audit-logging",
    "name": "Audit Logging",
    "categoryId": "cat-inference-safeguards",
    "description": "Comprehensive logging of safety-relevant events",
    "implementationMethods": [
      "Other"
    ],
    "governingStandards": [
      "SOC2",
      "ISO27001"
    ],
    "licence": null,
    "knownLimitations": [
      "Storage requirements",
      "Privacy concerns"
    ],
    "aliases": [
      "Safety Audit Trail"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      7
    ]
  },
  {
    "id": "tech-safety-advisory",
    "name": "Independent Safety Advisory",
    "categoryId": "cat-governance",
    "description": "External advisory board for safety oversight",
    "implementationMethods": [
      "Other"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Advisory only, not binding"
    ],
    "aliases": [
      "Safety Board"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10
    ]
  },
  {
    "id": "tech-incident-reporting",
    "name": "Incident Reporting Systems",
    "categoryId": "cat-governance",
    "description": "Formal systems for reporting and tracking safety incidents",
    "implementationMethods": [
      "Other"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Depends on reporting culture"
    ],
    "aliases": [],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      3,
      4,
      5
    ]
  },
  {
    "id": "tech-usage-monitoring",
    "name": "Usage Monitoring & Analytics",
    "categoryId": "cat-governance",
    "description": "Monitoring usage patterns for safety insights",
    "implementationMethods": [
      "Other"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Privacy considerations"
    ],
    "aliases": [],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      3,
      4,
      5
    ]
  },
  {
    "id": "tech-regulatory-compliance",
    "name": "Regulatory Compliance Frameworks",
    "categoryId": "cat-governance",
    "description": "Frameworks for compliance with AI regulations",
    "implementationMethods": [
      "Other"
    ],
    "governingStandards": [
      "EU AI Act",
      "NIST AI RMF"
    ],
    "licence": null,
    "knownLimitations": [
      "Varies by jurisdiction"
    ],
    "aliases": [],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10
    ]
  },
  {
    "id": "tech-academic-partnerships",
    "name": "Academic Partnerships",
    "categoryId": "cat-governance",
    "description": "Collaborations with academic institutions for safety research",
    "implementationMethods": [
      "Other"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Research timeline constraints"
    ],
    "aliases": [
      "University Collaborations"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10
    ]
  },
  {
    "id": "tech-model-cards",
    "name": "Model Cards & Technical Specs",
    "categoryId": "cat-transparency",
    "description": "Standardized documentation of model capabilities and limitations",
    "implementationMethods": [
      "Other"
    ],
    "governingStandards": [
      "Model Cards Framework"
    ],
    "licence": null,
    "knownLimitations": [
      "May not cover all aspects"
    ],
    "aliases": [
      "Model Documentation"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      7
    ]
  },
  {
    "id": "tech-safety-research",
    "name": "Safety Research Publications",
    "categoryId": "cat-transparency",
    "description": "Publishing safety research and methodologies",
    "implementationMethods": [
      "Other"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "May not include proprietary methods"
    ],
    "aliases": [],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      7
    ]
  },
  {
    "id": "tech-policy-documentation",
    "name": "Policy & Compliance Documentation",
    "categoryId": "cat-transparency",
    "description": "Public documentation of safety policies and compliance measures",
    "implementationMethods": [
      "Other"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "May be high-level"
    ],
    "aliases": [],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      7
    ]
  },
  {
    "id": "tech-watermarking",
    "name": "Watermarking Technology",
    "categoryId": "cat-novel-features",
    "description": "Embedding detectable patterns in AI-generated content",
    "implementationMethods": [
      "Other"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Can be removed or spoofed"
    ],
    "aliases": [
      "AI Watermarking",
      "SynthID"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      5,
      7
    ]
  },
  {
    "id": "tech-realtime-fact-checking",
    "name": "Real-time Fact Checking",
    "categoryId": "cat-inference-safeguards",
    "description": "Live fact-checking against real-time information sources during inference",
    "implementationMethods": [
      "RetrievalAugmentation",
      "ExternalSafetyService"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Dependent on source reliability",
      "May introduce latency"
    ],
    "aliases": [
      "Live Fact Verification"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      5
    ]
  },
  {
    "id": "tech-platform-context-safety",
    "name": "Platform Context Safety",
    "categoryId": "cat-inference-safeguards",
    "description": "Safety measures that consider broader platform context and user interactions",
    "implementationMethods": [
      "EmbeddedClassifier",
      "RetrievalAugmentation"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Privacy considerations with user data",
      "Complex context interpretation"
    ],
    "aliases": [
      "Social Context Safety"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      3,
      4
    ]
  },
  {
    "id": "tech-multimodal-safety-alignment",
    "name": "Multimodal Safety Alignment",
    "categoryId": "cat-alignment",
    "description": "Safety alignment techniques specifically for multimodal (text, image, audio) models",
    "implementationMethods": [
      "EmbeddedClassifier",
      "HumanModeration"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Cross-modal safety interactions complex",
      "Limited multimodal safety datasets"
    ],
    "aliases": [
      "Cross-modal Safety"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      5,
      6
    ]
  },
  {
    "id": "tech-dynamic-policy-adaptation",
    "name": "Dynamic Policy Adaptation",
    "categoryId": "cat-inference-safeguards",
    "description": "Real-time adaptation of safety policies based on context and emerging threats",
    "implementationMethods": [
      "EmbeddedClassifier",
      "Other"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "May be unpredictable",
      "Requires constant monitoring"
    ],
    "aliases": [
      "Adaptive Safety Policies"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      4,
      5,
      9
    ]
  },
  {
    "id": "tech-fine-tuning-safety",
    "name": "Fine-tuning Safety Controls",
    "categoryId": "cat-alignment",
    "description": "Safety controls and guidelines for model fine-tuning processes",
    "implementationMethods": [
      "HumanModeration",
      "EmbeddedClassifier"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Depends on base model safety",
      "Limited by fine-tuning data quality"
    ],
    "aliases": [
      "Custom Training Safety"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      5
    ]
  }
]