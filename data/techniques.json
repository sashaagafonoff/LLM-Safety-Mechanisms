[
  {
    "id": "tech-academic-partnerships",
    "name": "Academic Partnerships",
    "categoryId": "cat-governance",
    "description": "Collaborations with academic institutions for safety research",
    "implementationMethods": [
      "Other"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Research timeline constraints"
    ],
    "aliases": [
      "University Collaborations"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10
    ]
  },
  {
    "id": "tech-adversarial-training",
    "name": "Adversarial Training",
    "categoryId": "cat-alignment",
    "description": "Training with adversarial examples to improve robustness",
    "implementationMethods": [
      "AdversarialRedTeam"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Cannot cover all attack vectors"
    ],
    "aliases": [
      "Adversarial Robustness Training"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      4
    ]
  },
  {
    "id": "tech-audit-logging",
    "name": "Audit Logging",
    "categoryId": "cat-runtime-safety",
    "description": "Comprehensive logging of safety-relevant events",
    "implementationMethods": [
      "Other"
    ],
    "governingStandards": [
      "SOC2",
      "ISO27001"
    ],
    "licence": null,
    "knownLimitations": [
      "Storage requirements",
      "Privacy concerns"
    ],
    "aliases": [
      "Safety Audit Trail"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      7
    ]
  },
  {
    "id": "tech-bias-detection-training",
    "name": "Bias Detection in Training Data",
    "categoryId": "cat-pre-training-safety",
    "description": "Detection and mitigation of demographic and cultural biases in training data",
    "implementationMethods": [
      "EmbeddedClassifier",
      "RuleBased"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Cannot detect all forms of bias",
      "Definitions of bias vary culturally"
    ],
    "aliases": [
      "Training Data Debiasing"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      2
    ]
  },
  {
    "id": "tech-csam-detection",
    "name": "CSAM Detection & Removal",
    "categoryId": "cat-pre-training-safety",
    "description": "Automated detection and removal of child sexual abuse material",
    "implementationMethods": [
      "EmbeddedClassifier",
      "ExternalSafetyService"
    ],
    "governingStandards": [
      "NCMEC"
    ],
    "licence": null,
    "knownLimitations": [
      "False positive rates not disclosed"
    ],
    "aliases": [
      "CSAM Filtering"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1
    ]
  },
  {
    "id": "tech-capability-monitoring",
    "name": "Capability Threshold Monitoring",
    "categoryId": "cat-governance",
    "description": "Monitoring model capabilities against predefined safety thresholds",
    "implementationMethods": [
      "Other"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Thresholds may be arbitrary",
      "Capabilities hard to measure precisely"
    ],
    "aliases": [
      "Capability Evaluation"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      9,
      10
    ]
  },
  {
    "id": "tech-community-feedback",
    "name": "Community Feedback Systems",
    "categoryId": "cat-governance",
    "description": "Mechanisms for collecting, analyzing, and incorporating feedback from user communities and stakeholders to improve safety and alignment",
    "riskAreaIds": [
      1,
      2,
      4
    ],
    "aliases": [
      "User Feedback",
      "Stakeholder Input",
      "Community Engagement"
    ]
  },
  {
    "id": "tech-community-governance",
    "name": "Community Governance Models",
    "categoryId": "cat-governance",
    "description": "Governance structures involving community participation in safety oversight, policy development, and incident response",
    "riskAreaIds": [
      4
    ],
    "aliases": [
      "Participatory Governance",
      "Community Oversight",
      "Distributed Governance"
    ]
  },
  {
    "id": "tech-community-evaluation",
    "name": "Community-Based Evaluation",
    "categoryId": "cat-evaluation",
    "description": "Evaluation processes that leverage community expertise and distributed testing for comprehensive safety assessment",
    "riskAreaIds": [
      2
    ],
    "aliases": [
      "Crowdsourced Testing",
      "Community Assessment",
      "Distributed Evaluation"
    ]
  },
  {
    "id": "tech-safety-documentation",
    "name": "Comprehensive Safety Documentation",
    "categoryId": "cat-transparency",
    "description": "Detailed public documentation of safety measures and evaluations",
    "implementationMethods": [
      "Other"
    ],
    "governingStandards": [
      "ISO 26000"
    ],
    "licence": null,
    "knownLimitations": [
      "May not cover proprietary methods",
      "Can become outdated"
    ],
    "aliases": [
      "Safety Cards",
      "System Cards"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      7
    ]
  },
  {
    "id": "tech-configurable-policies",
    "name": "Configurable Safety Policies",
    "categoryId": "cat-runtime-safety",
    "description": "User or admin configurable safety thresholds and policies",
    "implementationMethods": [
      "Other"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Requires user expertise"
    ],
    "aliases": [],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      3,
      4,
      5
    ]
  },
  {
    "id": "tech-constitutional-ai",
    "name": "Constitutional AI / Self-Critique",
    "categoryId": "cat-alignment",
    "description": "Training models to critique and revise their own outputs based on constitutional principles",
    "implementationMethods": [
      "EmbeddedClassifier",
      "RetrievalAugmentation"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Requires careful principle design",
      "May be overly conservative"
    ],
    "aliases": [
      "CAI",
      "Constitutional AI"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      5,
      10
    ]
  },
  {
    "id": "tech-contextual-safety",
    "name": "Contextual Safety Assessment",
    "categoryId": "cat-runtime-safety",
    "description": "Context-aware safety evaluation considering conversation history",
    "implementationMethods": [
      "EmbeddedClassifier",
      "RetrievalAugmentation"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Complex contexts challenging"
    ],
    "aliases": [],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      5
    ]
  },
  {
    "id": "tech-copyright-filtering",
    "name": "Copyright Content Filtering",
    "categoryId": "cat-pre-training-safety",
    "description": "Detection and removal of copyrighted content from training datasets",
    "implementationMethods": [
      "RuleBased",
      "EmbeddedClassifier"
    ],
    "governingStandards": [
      "DMCA"
    ],
    "licence": null,
    "knownLimitations": [
      "Difficult to detect all copyrighted content",
      "May remove fair use content"
    ],
    "aliases": [
      "Copyright Protection"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      6
    ]
  },
  {
    "id": "tech-sovereignty-options",
    "name": "Data Sovereignty Controls",
    "categoryId": "cat-governance",
    "description": "Technical and policy controls ensuring data processing and model deployment comply with regional sovereignty requirements",
    "riskAreaIds": [
      3
    ],
    "aliases": [
      "Regional Compliance",
      "Data Localization",
      "Jurisdictional Controls"
    ]
  },
  {
    "id": "tech-enterprise-integration",
    "name": "Enterprise Integration Safety",
    "categoryId": "cat-governance",
    "description": "Safety mechanisms and protocols specifically designed for enterprise deployment environments and integration workflows",
    "riskAreaIds": [
      4
    ],
    "aliases": [
      "Business Integration",
      "Enterprise Safety",
      "Corporate Deployment"
    ]
  },
  {
    "id": "tech-fine-tuning-safety",
    "name": "Fine-tuning Safety Controls",
    "categoryId": "cat-alignment",
    "description": "Safety controls and guidelines for model fine-tuning processes",
    "implementationMethods": [
      "HumanModeration",
      "EmbeddedClassifier"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Depends on base model safety",
      "Limited by fine-tuning data quality"
    ],
    "aliases": [
      "Custom Training Safety"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      5
    ]
  },
  {
    "id": "tech-government-oversight",
    "name": "Government Regulatory Compliance",
    "categoryId": "cat-governance",
    "description": "Compliance mechanisms and reporting structures for meeting government regulatory requirements and oversight",
    "riskAreaIds": [
      4
    ],
    "aliases": [
      "Regulatory Compliance",
      "Government Reporting",
      "Official Oversight"
    ]
  },
  {
    "id": "tech-incident-reporting",
    "name": "Incident Reporting Systems",
    "categoryId": "cat-governance",
    "description": "Formal systems for reporting and tracking safety incidents",
    "implementationMethods": [
      "Other"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Depends on reporting culture"
    ],
    "aliases": [],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      3,
      4,
      5
    ]
  },
  {
    "id": "tech-safety-advisory",
    "name": "Independent Safety Advisory",
    "categoryId": "cat-governance",
    "description": "External advisory board for safety oversight",
    "implementationMethods": [
      "Other"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Advisory only, not binding"
    ],
    "aliases": [
      "Safety Board"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10
    ]
  },
  {
    "id": "tech-input-classification",
    "name": "Input Content Classification",
    "categoryId": "cat-runtime-safety",
    "description": "Classification of input prompts for safety risks before processing",
    "implementationMethods": [
      "EmbeddedClassifier",
      "ExternalSafetyService"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "May block benign content",
      "Context-dependent risks hard to catch"
    ],
    "aliases": [
      "Input Filtering",
      "Prompt Classification"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      4,
      5
    ]
  },
  {
    "id": "tech-model-cards",
    "name": "Model Cards & Technical Specs",
    "categoryId": "cat-transparency",
    "description": "Standardized documentation of model capabilities and limitations",
    "implementationMethods": [
      "Other"
    ],
    "governingStandards": [
      "Model Cards Framework"
    ],
    "licence": null,
    "knownLimitations": [
      "May not cover all aspects"
    ],
    "aliases": [
      "Model Documentation"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      7
    ]
  },
  {
    "id": "tech-multistage-pipeline",
    "name": "Multi-stage Safety Pipeline",
    "categoryId": "cat-runtime-safety",
    "description": "Multiple layers of safety checks at different stages",
    "implementationMethods": [
      "Other"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Increased complexity",
      "Potential for conflicts"
    ],
    "aliases": [],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      3,
      4,
      5
    ]
  },
  {
    "id": "tech-multimodal-safety-alignment",
    "name": "Multimodal Safety Alignment",
    "categoryId": "cat-alignment",
    "description": "Safety alignment techniques specifically designed for multimodal models handling text, images, audio, and video content",
    "riskAreaIds": [
      1,
      2
    ],
    "aliases": [
      "Cross-Modal Safety",
      "Multimodal Alignment",
      "Multi-Input Safety"
    ]
  },
  {
    "id": "tech-opensource-tools",
    "name": "Open Source Safety Tools",
    "categoryId": "cat-transparency",
    "description": "Development and provision of open-source tools, libraries, and frameworks for safety evaluation and implementation",
    "riskAreaIds": [
      7
    ],
    "aliases": [
      "Open Source Libraries",
      "Community Tools",
      "Public Safety Resources"
    ]
  },
  {
    "id": "tech-output-filtering",
    "name": "Output Content Filtering",
    "categoryId": "cat-runtime-safety",
    "description": "Post-generation filtering of model outputs for safety violations",
    "implementationMethods": [
      "EmbeddedClassifier",
      "ExternalSafetyService",
      "RuleBased"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "May alter intended meaning",
      "Can be overly restrictive"
    ],
    "aliases": [
      "Output Moderation"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      3,
      5,
      6
    ]
  },
  {
    "id": "tech-pii-detection-inference",
    "name": "PII Detection & Redaction",
    "categoryId": "cat-privacy-security",
    "description": "Real-time detection and redaction of personal information",
    "implementationMethods": [
      "RuleBased",
      "EmbeddedClassifier"
    ],
    "governingStandards": [
      "GDPR",
      "CCPA"
    ],
    "licence": null,
    "knownLimitations": [
      "Context-dependent PII hard to catch"
    ],
    "aliases": [
      "PII Redaction"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      3
    ]
  },
  {
    "id": "tech-pii-reduction",
    "name": "PII Reduction",
    "categoryId": "cat-privacy-security",
    "description": "Detection and removal of personal information from training data",
    "implementationMethods": [
      "RuleBased",
      "EmbeddedClassifier"
    ],
    "governingStandards": [
      "GDPR",
      "CCPA"
    ],
    "licence": null,
    "knownLimitations": [
      "Cannot catch all PII",
      "Context-dependent PII is challenging"
    ],
    "aliases": [
      "PII Filtering",
      "Personal Data Removal"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      3
    ]
  },
  {
    "id": "tech-platform-context-safety",
    "name": "Platform Context Safety",
    "categoryId": "cat-runtime-safety",
    "description": "Safety mechanisms that adapt behavior based on platform-specific context, user demographics, and usage patterns",
    "riskAreaIds": [
      1,
      2
    ],
    "aliases": [
      "Contextual Safety",
      "Platform-Aware Safety",
      "Adaptive Safety Controls"
    ]
  },
  {
    "id": "tech-policy-documentation",
    "name": "Policy & Compliance Documentation",
    "categoryId": "cat-transparency",
    "description": "Public documentation of safety policies and compliance measures",
    "implementationMethods": [
      "Other"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "May be high-level"
    ],
    "aliases": [],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      7
    ]
  },
  {
    "id": "tech-prompt-injection-protection",
    "name": "Prompt Injection Protection",
    "categoryId": "cat-runtime-safety",
    "description": "Detection and prevention of prompt injection attacks",
    "implementationMethods": [
      "RuleBased",
      "EmbeddedClassifier"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Evolving attack vectors",
      "May restrict legitimate use cases"
    ],
    "aliases": [
      "Injection Defense"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      4
    ]
  },
  {
    "id": "tech-realtime-fact-checking",
    "name": "Real-time Fact Checking",
    "categoryId": "cat-runtime-safety",
    "description": "Dynamic fact-checking systems that verify information accuracy in real-time during model inference",
    "riskAreaIds": [
      5,
      1
    ],
    "aliases": [
      "Live Fact Verification",
      "Dynamic Truth Checking",
      "Real-time Verification"
    ]
  },
  {
    "id": "tech-realtime-monitoring",
    "name": "Real-time Safety Monitoring",
    "categoryId": "cat-runtime-safety",
    "description": "Live monitoring of model outputs for safety violations",
    "implementationMethods": [
      "ExternalSafetyService",
      "EmbeddedClassifier"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Latency impact",
      "May miss context"
    ],
    "aliases": [
      "Live Safety Monitoring"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      3,
      4,
      5
    ]
  },
  {
    "id": "tech-red-team-data",
    "name": "Red Team Data Integration",
    "categoryId": "cat-alignment",
    "description": "Incorporating red team findings into training data",
    "implementationMethods": [
      "AdversarialRedTeam",
      "HumanModeration"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Limited by red team scope"
    ],
    "aliases": [],
    "requiredTechniqueIds": [
      "tech-red-teaming"
    ],
    "riskAreaIds": [
      1,
      2,
      4,
      5
    ]
  },
  {
    "id": "tech-red-teaming",
    "name": "Red Team Exercises",
    "categoryId": "cat-governance",
    "description": "Systematic adversarial testing by security experts",
    "implementationMethods": [
      "HumanModeration",
      "AdversarialRedTeam"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Limited by red team expertise",
      "Cannot test all scenarios"
    ],
    "aliases": [
      "Adversarial Testing",
      "Red Teaming"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      3,
      4,
      5,
      6,
      9,
      10
    ]
  },
  {
    "id": "tech-regulatory-compliance",
    "name": "Regulatory Compliance Frameworks",
    "categoryId": "cat-governance",
    "description": "Frameworks for compliance with AI regulations",
    "implementationMethods": [
      "Other"
    ],
    "governingStandards": [
      "EU AI Act",
      "NIST AI RMF"
    ],
    "licence": null,
    "knownLimitations": [
      "Varies by jurisdiction"
    ],
    "aliases": [],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10
    ]
  },
  {
    "id": "tech-rlhf",
    "name": "Reinforcement Learning from Human Feedback",
    "categoryId": "cat-alignment",
    "description": "Training models to align with human preferences through feedback",
    "implementationMethods": [
      "HumanModeration",
      "EmbeddedClassifier"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Subject to annotator biases",
      "Expensive to scale"
    ],
    "aliases": [
      "RLHF"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      5
    ]
  },
  {
    "id": "tech-responsible-release",
    "name": "Responsible Release Protocols",
    "categoryId": "cat-governance",
    "description": "Structured processes for staged, monitored release of AI systems with safety checkpoints and rollback capabilities",
    "riskAreaIds": [
      4
    ],
    "aliases": [
      "Staged Release",
      "Phased Deployment",
      "Controlled Rollout"
    ]
  },
  {
    "id": "tech-safety-benchmarks",
    "name": "Safety Benchmarking",
    "categoryId": "cat-evaluation",
    "description": "Standardized benchmarks and evaluation suites for measuring and comparing safety performance across models",
    "riskAreaIds": [
      1
    ],
    "aliases": [
      "Safety Evaluation",
      "Security Benchmarks",
      "Safety Testing Suites"
    ]
  },
  {
    "id": "tech-safety-research",
    "name": "Safety Research Publications",
    "categoryId": "cat-transparency",
    "description": "Publishing safety research and methodologies",
    "implementationMethods": [
      "Other"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "May not include proprietary methods"
    ],
    "aliases": [],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      7
    ]
  },
  {
    "id": "tech-safety-reward-modeling",
    "name": "Safety Reward Modeling",
    "categoryId": "cat-alignment",
    "description": "Separate reward models specifically optimized for safety outcomes",
    "implementationMethods": [
      "EmbeddedClassifier",
      "HumanModeration"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "May conflict with capability objectives",
      "Hard to balance multiple safety goals"
    ],
    "aliases": [
      "Safety RM"
    ],
    "requiredTechniqueIds": [
      "tech-rlhf"
    ],
    "riskAreaIds": [
      1,
      2,
      5
    ]
  },
  {
    "id": "tech-training-data-filtering",
    "name": "Training Data Filtering",
    "categoryId": "cat-pre-training-safety",
    "description": "Systematic removal of harmful content from training datasets",
    "implementationMethods": [
      "RuleBased",
      "EmbeddedClassifier"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "May introduce demographic biases"
    ],
    "aliases": [
      "Data Curation",
      "Dataset Cleaning"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      6
    ]
  },
  {
    "id": "tech-usage-monitoring",
    "name": "Usage Monitoring & Analytics",
    "categoryId": "cat-governance",
    "description": "Monitoring usage patterns for safety insights",
    "implementationMethods": [
      "Other"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Privacy considerations"
    ],
    "aliases": [],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      1,
      2,
      3,
      4,
      5
    ]
  },
  {
    "id": "tech-watermarking",
    "name": "Watermarking Technology",
    "categoryId": "cat-runtime-safety",
    "description": "Embedding detectable patterns in AI-generated content",
    "implementationMethods": [
      "Other"
    ],
    "governingStandards": [],
    "licence": null,
    "knownLimitations": [
      "Can be removed or spoofed"
    ],
    "aliases": [
      "AI Watermarking",
      "SynthID"
    ],
    "requiredTechniqueIds": [],
    "riskAreaIds": [
      5,
      7
    ]
  },
  {
    "id": "tech-training-data-disclosure",
    "name": "Training Data Source Disclosure",
    "categoryId": "cat-transparency",
    "description": "Comprehensive disclosure of training data sources, collection methods, licensing, and composition details",
    "riskAreaIds": [
      "risk-transparency",
      "risk-bias-fairness"
    ],
    "aliases": [
      "Data Source Documentation",
      "Training Data Transparency",
      "Dataset Disclosure"
    ]
  },
  {
    "id": "tech-compute-documentation",
    "name": "Compute Resource Documentation",
    "categoryId": "cat-transparency",
    "description": "Documentation of computational resources used for model training including hardware, energy consumption, and environmental impact",
    "riskAreaIds": [
      "risk-transparency"
    ],
    "aliases": [
      "Compute Transparency",
      "Resource Documentation",
      "Infrastructure Disclosure"
    ]
  },
  {
    "id": "tech-performance-disclosure",
    "name": "Model Performance Disclosure",
    "categoryId": "cat-transparency",
    "description": "Public disclosure of model performance metrics, benchmarks results, and capability assessments",
    "riskAreaIds": [
      "risk-transparency",
      "risk-capability-evaluation"
    ],
    "aliases": [
      "Performance Transparency",
      "Capability Disclosure",
      "Benchmark Results Publication"
    ]
  },
  {
    "id": "tech-safety-evaluation-publication",
    "name": "Safety Evaluation Results Publication",
    "categoryId": "cat-evaluation",
    "description": "Publication of comprehensive safety evaluation results, methodologies, and findings",
    "riskAreaIds": [
      "risk-harmful-content",
      "risk-capability-evaluation"
    ],
    "aliases": [
      "Safety Results Disclosure",
      "Safety Testing Publication",
      "Safety Assessment Reports"
    ]
  },
  {
    "id": "tech-access-control-documentation",
    "name": "Access Control Documentation",
    "categoryId": "cat-governance",
    "description": "Documentation of access control policies, authentication methods, and usage restrictions",
    "riskAreaIds": [
      "risk-security-misuse",
      "risk-governance"
    ],
    "aliases": [
      "Access Policy Documentation",
      "Usage Control Disclosure",
      "Authentication Documentation"
    ]
  },
  {
    "id": "tech-data-retention-policies",
    "name": "Data Retention Policies",
    "categoryId": "cat-privacy-security",
    "description": "Policies and procedures for data retention, deletion, and lifecycle management",
    "riskAreaIds": [
      "risk-privacy-pii",
      "risk-governance"
    ],
    "aliases": [
      "Data Lifecycle Management",
      "Retention Policies",
      "Data Deletion Procedures"
    ]
  },
  {
    "id": "tech-model-versioning",
    "name": "Model Update & Versioning Protocols",
    "categoryId": "cat-governance",
    "description": "Systematic protocols for model updates, versioning, and change management",
    "riskAreaIds": [
      "risk-governance",
      "risk-capability-evaluation"
    ],
    "aliases": [
      "Version Control",
      "Model Update Management",
      "Change Control Protocols"
    ]
  },
  {
    "id": "tech-stakeholder-engagement",
    "name": "Stakeholder Engagement Processes",
    "categoryId": "cat-governance",
    "description": "Formal processes for engaging with stakeholders, communities, and affected parties in safety decisions",
    "riskAreaIds": [
      "risk-governance",
      "risk-bias-fairness"
    ],
    "aliases": [
      "Community Engagement",
      "Stakeholder Consultation",
      "Public Participation"
    ]
  },
  {
    "id": "tech-external-audit-coordination",
    "name": "External Audit Coordination",
    "categoryId": "cat-governance",
    "description": "Coordination and facilitation of external audits, assessments, and independent reviews",
    "riskAreaIds": [
      "risk-governance",
      "risk-capability-evaluation"
    ],
    "aliases": [
      "Third-party Audit Management",
      "Independent Review Coordination",
      "External Assessment"
    ]
  },
  {
    "id": "tech-privacy-impact-assessment",
    "name": "Privacy Impact Assessments",
    "categoryId": "cat-privacy-security",
    "description": "Systematic assessment of privacy risks and impacts throughout the model lifecycle",
    "riskAreaIds": [
      "risk-privacy-pii",
      "risk-governance"
    ],
    "aliases": [
      "Privacy Risk Assessment",
      "PIA",
      "Privacy Evaluation"
    ]
  },
  {
    "id": "tech-algorithmic-impact-assessment",
    "name": "Algorithmic Impact Assessments",
    "categoryId": "cat-evaluation",
    "description": "Assessment of broader societal and ethical impacts of algorithmic systems",
    "riskAreaIds": [
      "risk-bias-fairness",
      "risk-governance",
      "risk-harmful-content"
    ],
    "aliases": [
      "AIA",
      "Societal Impact Assessment",
      "Ethical Impact Evaluation"
    ]
  },
  {
    "id": "tech-dynamic-risk-assessment",
    "name": "Dynamic Risk Assessment",
    "categoryId": "cat-runtime-safety",
    "description": "Real-time risk assessment that adapts to changing contexts and usage patterns",
    "riskAreaIds": [
      "risk-harmful-content",
      "risk-security-misuse"
    ],
    "aliases": [
      "Adaptive Risk Assessment",
      "Context-Aware Risk Evaluation",
      "Dynamic Safety Assessment"
    ]
  }
]