[
  {
    "id": "tech-adversarial-training",
    "name": "Adversarial Training",
    "categoryId": "cat-alignment",
    "description": "Training with adversarial examples to improve robustness",
    "implementationMethods": [
      "AdversarialRedTeam"
    ],
    "knownLimitations": [
      "Cannot cover all attack vectors"
    ],
    "aliases": [
      "Adversarial Robustness Training"
    ],
    "riskAreaIds": [
      "harmful_content",
      "security_and_misuse"
    ]
  },
  {
    "id": "tech-audit-logging",
    "name": "Audit Logging",
    "categoryId": "cat-runtime-safety",
    "description": "Comprehensive logging of safety-relevant events",
    "implementationMethods": [
      "Other"
    ],
    "knownLimitations": [
      "Storage requirements",
      "Privacy concerns"
    ],
    "aliases": [
      "Safety Audit Trail"
    ],
    "riskAreaIds": [
      "transparency"
    ]
  },
  {
    "id": "tech-bias-detection-training",
    "name": "Bias Detection in Training Data",
    "categoryId": "cat-pre-training-safety",
    "description": "Detection and mitigation of demographic and cultural biases in training data",
    "implementationMethods": [
      "EmbeddedClassifier",
      "RuleBased"
    ],
    "knownLimitations": [
      "Cannot detect all forms of bias",
      "Definitions of bias vary culturally"
    ],
    "aliases": [
      "Training Data Debiasing"
    ],
    "riskAreaIds": [
      "bias_and_fairness"
    ]
  },
  {
    "id": "tech-csam-detection",
    "name": "CSAM Detection & Removal",
    "categoryId": "cat-pre-training-safety",
    "description": "Automated detection and removal of child sexual abuse material",
    "implementationMethods": [
      "EmbeddedClassifier",
      "ExternalSafetyService"
    ],
    "knownLimitations": [
      "False positive rates not disclosed"
    ],
    "aliases": [
      "CSAM Filtering"
    ],
    "riskAreaIds": [
      "harmful_content"
    ]
  },
  {
    "id": "tech-capability-monitoring",
    "name": "Capability Threshold Monitoring",
    "categoryId": "cat-governance",
    "description": "Monitoring model capabilities against predefined safety thresholds",
    "implementationMethods": [
      "Other"
    ],
    "knownLimitations": [
      "Thresholds may be arbitrary",
      "Capabilities hard to measure precisely"
    ],
    "aliases": [
      "Capability Evaluation"
    ],
    "riskAreaIds": [
      "autonomy_and_control",
      "dual_use"
    ]
  },
  {
    "id": "tech-community-feedback",
    "name": "Community Feedback Systems",
    "categoryId": "cat-governance",
    "description": "Mechanisms for collecting, analyzing, and incorporating feedback from user communities and stakeholders to improve safety and alignment",
    "riskAreaIds": [
      "harmful_content",
      "bias_and_fairness",
      "security_and_misuse"
    ],
    "aliases": [
      "User Feedback",
      "Stakeholder Input",
      "Community Engagement"
    ]
  },
  {
    "id": "tech-community-governance",
    "name": "Community Governance Models",
    "categoryId": "cat-governance",
    "description": "Governance structures involving community participation in safety oversight, policy development, and incident response",
    "riskAreaIds": [
      "security_and_misuse"
    ],
    "aliases": [
      "Participatory Governance",
      "Community Oversight",
      "Distributed Governance"
    ]
  },
  {
    "id": "tech-community-evaluation",
    "name": "Community-Based Evaluation",
    "categoryId": "cat-evaluation",
    "description": "Evaluation processes that leverage community expertise and distributed testing for comprehensive safety assessment",
    "riskAreaIds": [
      "bias_and_fairness"
    ],
    "aliases": [
      "Crowdsourced Testing",
      "Community Assessment",
      "Distributed Evaluation"
    ]
  },
  {
    "id": "tech-safety-documentation",
    "name": "Comprehensive Safety Documentation",
    "categoryId": "cat-transparency",
    "description": "Comprehensive public documentation of safety measures, evaluations, research publications, and safety evaluation results to ensure transparency and knowledge sharing",
    "implementationMethods": [
      "Other"
    ],
    "knownLimitations": [
      "May not cover proprietary methods",
      "Can become outdated"
    ],
    "aliases": [
      "Safety Assessment Reports",
      "Safety Cards",
      "Safety Results Disclosure",
      "Safety Testing Publication",
      "System Cards"
    ],
    "riskAreaIds": [
      "transparency",
      "harmful_content",
      "bias_and_fairness",
      "security_and_misuse",
      "misinformation"
    ]
  },
  {
    "id": "tech-configurable-policies",
    "name": "Configurable Safety Policies",
    "categoryId": "cat-runtime-safety",
    "description": "User or admin configurable safety thresholds, policies, and fine-tuning safety controls that can be adapted to different use cases and requirements",
    "implementationMethods": [
      "Other"
    ],
    "knownLimitations": [
      "Requires user expertise"
    ],
    "aliases": [
      "Custom Training Safety"
    ],
    "riskAreaIds": [
      "harmful_content",
      "bias_and_fairness",
      "privacy_and_pii",
      "security_and_misuse",
      "misinformation"
    ]
  },
  {
    "id": "tech-constitutional-ai",
    "name": "Constitutional AI / Self-Critique",
    "categoryId": "cat-alignment",
    "description": "Training models to critique and revise their own outputs based on constitutional principles",
    "implementationMethods": [
      "EmbeddedClassifier",
      "RetrievalAugmentation"
    ],
    "knownLimitations": [
      "Requires careful principle design",
      "May be overly conservative"
    ],
    "aliases": [
      "CAI",
      "Constitutional AI"
    ],
    "riskAreaIds": [
      "harmful_content",
      "bias_and_fairness",
      "transparency"
    ]
  },
  {
    "id": "tech-contextual-safety",
    "name": "Contextual Safety Assessment",
    "categoryId": "cat-runtime-safety",
    "description": "Context-aware safety evaluation and platform-specific safety mechanisms that consider conversation history, user demographics, platform context, and usage patterns",
    "implementationMethods": [
      "EmbeddedClassifier",
      "RetrievalAugmentation"
    ],
    "knownLimitations": [
      "Complex contexts challenging"
    ],
    "aliases": [
      "Adaptive Safety Controls",
      "Contextual Safety",
      "Platform-Aware Safety"
    ],
    "riskAreaIds": [
      "harmful_content",
      "bias_and_fairness",
      "misinformation"
    ]
  },
  {
    "id": "tech-copyright-filtering",
    "name": "Copyright Content Filtering",
    "categoryId": "cat-pre-training-safety",
    "description": "Detection and removal of copyrighted content from training datasets",
    "implementationMethods": [
      "RuleBased",
      "EmbeddedClassifier"
    ],
    "knownLimitations": [
      "Difficult to detect all copyrighted content",
      "May remove fair use content"
    ],
    "aliases": [
      "Copyright Protection"
    ],
    "riskAreaIds": [
      "copyright_and_ip"
    ]
  },
  {
    "id": "tech-sovereignty-options",
    "name": "Data Sovereignty Controls",
    "categoryId": "cat-governance",
    "description": "Technical and policy controls ensuring data processing and model deployment comply with regional sovereignty requirements",
    "riskAreaIds": [
      "privacy_and_pii"
    ],
    "aliases": [
      "Regional Compliance",
      "Data Localization",
      "Jurisdictional Controls"
    ]
  },
  {
    "id": "tech-enterprise-integration",
    "name": "Enterprise Integration Safety",
    "categoryId": "cat-governance",
    "description": "Safety mechanisms and protocols specifically designed for enterprise deployment environments and integration workflows",
    "riskAreaIds": [
      "security_and_misuse"
    ],
    "aliases": [
      "Business Integration",
      "Enterprise Safety",
      "Corporate Deployment"
    ]
  },
  {
    "id": "tech-government-oversight",
    "name": "Government Regulatory Compliance",
    "categoryId": "cat-governance",
    "description": "Comprehensive compliance mechanisms and reporting structures for meeting government regulatory requirements, regulatory frameworks, and official oversight across all applicable jurisdictions",
    "riskAreaIds": [
      "harmful_content",
      "autonomy_and_control",
      "bias_and_fairness",
      "privacy_and_pii",
      "security_and_misuse",
      "misinformation",
      "copyright_and_ip",
      "transparency",
      "environmental",
      "dual_use"
    ],
    "aliases": [
      "Government Reporting",
      "Official Oversight",
      "Regulatory Compliance"
    ]
  },
  {
    "id": "tech-incident-reporting",
    "name": "Incident Reporting Systems",
    "categoryId": "cat-governance",
    "description": "Comprehensive systems for reporting, tracking, and coordinating response to safety incidents including external audit coordination and independent oversight",
    "implementationMethods": [
      "Other"
    ],
    "knownLimitations": [
      "Depends on reporting culture"
    ],
    "aliases": [
      "External Assessment",
      "Independent Review Coordination",
      "Third-party Audit Management"
    ],
    "riskAreaIds": [
      "harmful_content",
      "bias_and_fairness",
      "privacy_and_pii",
      "security_and_misuse",
      "misinformation",
      "transparency"
    ]
  },
  {
    "id": "tech-safety-advisory",
    "name": "Independent Safety Advisory",
    "categoryId": "cat-governance",
    "description": "External advisory board for safety oversight",
    "implementationMethods": [
      "Other"
    ],
    "knownLimitations": [
      "Advisory only, not binding"
    ],
    "aliases": [
      "Safety Board"
    ],
    "riskAreaIds": [
      "harmful_content",
      "autonomy_and_control",
      "bias_and_fairness",
      "privacy_and_pii",
      "security_and_misuse",
      "misinformation",
      "copyright_and_ip",
      "transparency",
      "environmental",
      "dual_use"
    ]
  },
  {
    "id": "tech-input-classification",
    "name": "Input Content Classification",
    "categoryId": "cat-runtime-safety",
    "description": "Classification of input prompts for safety risks before processing",
    "implementationMethods": [
      "EmbeddedClassifier",
      "ExternalSafetyService"
    ],
    "knownLimitations": [
      "May block benign content",
      "Context-dependent risks hard to catch"
    ],
    "aliases": [
      "Input Filtering",
      "Prompt Classification"
    ],
    "riskAreaIds": [
      "harmful_content",
      "security_and_misuse",
      "misinformation"
    ]
  },
  {
    "id": "tech-model-cards",
    "name": "Model Cards & Technical Specs",
    "categoryId": "cat-transparency",
    "description": "Comprehensive standardized documentation including model capabilities, limitations, technical specifications, training data sources, and performance metrics disclosure",
    "implementationMethods": [
      "Other"
    ],
    "knownLimitations": [
      "May not cover all aspects"
    ],
    "aliases": [
      "Benchmark Results Publication",
      "Capability Disclosure",
      "Data Source Documentation",
      "Dataset Disclosure",
      "Model Documentation",
      "Performance Transparency",
      "Training Data Transparency"
    ],
    "riskAreaIds": [
      "transparency",
      "bias_and_fairness",
      "security_and_misuse"
    ]
  },
  {
    "id": "tech-multistage-pipeline",
    "name": "Multi-stage Safety Pipeline",
    "categoryId": "cat-runtime-safety",
    "description": "Multiple layers of safety checks at different stages",
    "implementationMethods": [
      "Other"
    ],
    "knownLimitations": [
      "Increased complexity",
      "Potential for conflicts"
    ],
    "aliases": [],
    "riskAreaIds": [
      "harmful_content",
      "bias_and_fairness",
      "privacy_and_pii",
      "security_and_misuse",
      "misinformation"
    ]
  },
  {
    "id": "tech-multimodal-safety-alignment",
    "name": "Multimodal Safety Alignment",
    "categoryId": "cat-alignment",
    "description": "Safety alignment techniques specifically designed for multimodal models handling text, images, audio, and video content",
    "riskAreaIds": [
      "harmful_content",
      "bias_and_fairness"
    ],
    "aliases": [
      "Cross-Modal Safety",
      "Multimodal Alignment",
      "Multi-Input Safety"
    ]
  },
  {
    "id": "tech-opensource-tools",
    "name": "Open Source Safety Tools",
    "categoryId": "cat-transparency",
    "description": "Development and provision of open-source tools, libraries, and frameworks for safety evaluation and implementation",
    "riskAreaIds": [
      "transparency"
    ],
    "aliases": [
      "Open Source Libraries",
      "Community Tools",
      "Public Safety Resources"
    ]
  },
  {
    "id": "tech-output-filtering",
    "name": "Output Content Filtering",
    "categoryId": "cat-runtime-safety",
    "description": "Post-generation filtering of model outputs for safety violations",
    "implementationMethods": [
      "EmbeddedClassifier",
      "ExternalSafetyService",
      "RuleBased"
    ],
    "knownLimitations": [
      "May alter intended meaning",
      "Can be overly restrictive"
    ],
    "aliases": [
      "Output Moderation"
    ],
    "riskAreaIds": [
      "harmful_content",
      "misinformation",
      "bias_and_fairness"
    ]
  },
  {
    "id": "tech-pii-detection-inference",
    "name": "PII Detection & Redaction",
    "categoryId": "cat-privacy-security",
    "description": "Comprehensive detection, redaction, and reduction of personal information both during training data preparation and real-time inference",
    "implementationMethods": [
      "RuleBased",
      "EmbeddedClassifier"
    ],
    "knownLimitations": [
      "Context-dependent PII hard to catch"
    ],
    "aliases": [
      "PII Filtering",
      "PII Redaction",
      "Personal Data Removal"
    ],
    "riskAreaIds": [
      "privacy_and_pii"
    ]
  },
  {
    "id": "tech-policy-documentation",
    "name": "Policy & Compliance Documentation",
    "categoryId": "cat-transparency",
    "description": "Public documentation of safety policies and compliance measures",
    "implementationMethods": [
      "Other"
    ],
    "knownLimitations": [
      "May be high-level"
    ],
    "aliases": [],
    "riskAreaIds": [
      "transparency"
    ]
  },
  {
    "id": "tech-prompt-injection-protection",
    "name": "Prompt Injection Protection",
    "categoryId": "cat-runtime-safety",
    "description": "Detection and prevention of prompt injection attacks",
    "implementationMethods": [
      "RuleBased",
      "EmbeddedClassifier"
    ],
    "knownLimitations": [
      "Evolving attack vectors",
      "May restrict legitimate use cases"
    ],
    "aliases": [
      "Injection Defense"
    ],
    "riskAreaIds": [
      "security_and_misuse"
    ]
  },
  {
    "id": "tech-realtime-fact-checking",
    "name": "Real-time Fact Checking",
    "categoryId": "cat-runtime-safety",
    "description": "Dynamic fact-checking systems that verify information accuracy in real-time during model inference",
    "riskAreaIds": [
      "harmful_content",
      "misinformation"
    ],
    "aliases": [
      "Live Fact Verification",
      "Dynamic Truth Checking",
      "Real-time Verification"
    ]
  },
  {
    "id": "tech-realtime-monitoring",
    "name": "Real-time Safety Monitoring",
    "categoryId": "cat-runtime-safety",
    "description": "Real-time monitoring and analytics of model outputs, usage patterns, and safety violations with comprehensive usage monitoring and analytics",
    "implementationMethods": [
      "ExternalSafetyService",
      "EmbeddedClassifier"
    ],
    "knownLimitations": [
      "Latency impact",
      "May miss context"
    ],
    "aliases": [
      "Live Safety Monitoring"
    ],
    "riskAreaIds": [
      "harmful_content",
      "bias_and_fairness",
      "privacy_and_pii",
      "security_and_misuse",
      "misinformation"
    ]
  },
  {
    "id": "tech-red-team-data",
    "name": "Red Team Data Integration",
    "categoryId": "cat-alignment",
    "description": "Incorporating red team findings into training data",
    "implementationMethods": [
      "AdversarialRedTeam",
      "HumanModeration"
    ],
    "knownLimitations": [
      "Limited by red team scope"
    ],
    "aliases": [],
    "riskAreaIds": [
      "harmful_content",
      "bias_and_fairness",
      "security_and_misuse",
      "misinformation"
    ]
  },
  {
    "id": "tech-red-teaming",
    "name": "Red Team Exercises",
    "categoryId": "cat-governance",
    "description": "Systematic adversarial testing by security experts",
    "implementationMethods": [
      "HumanModeration",
      "AdversarialRedTeam"
    ],
    "knownLimitations": [
      "Limited by red team expertise",
      "Cannot test all scenarios"
    ],
    "aliases": [
      "Adversarial Testing",
      "Red Teaming"
    ],
    "riskAreaIds": [
      "harmful_content",
      "security_and_misuse",
      "bias_and_fairness",
      "misinformation"
    ]
  },
  {
    "id": "tech-rlhf",
    "name": "Reinforcement Learning from Human Feedback",
    "categoryId": "cat-alignment",
    "description": "Training models to align with human preferences through feedback",
    "implementationMethods": [
      "HumanModeration",
      "EmbeddedClassifier"
    ],
    "knownLimitations": [
      "Subject to annotator biases",
      "Expensive to scale"
    ],
    "aliases": [
      "RLHF"
    ],
    "riskAreaIds": [
      "harmful_content",
      "bias_and_fairness",
      "misinformation"
    ]
  },
  {
    "id": "tech-responsible-release",
    "name": "Responsible Release Protocols",
    "categoryId": "cat-governance",
    "description": "Structured processes for staged, monitored release of AI systems with safety checkpoints and rollback capabilities",
    "riskAreaIds": [
      "security_and_misuse"
    ],
    "aliases": [
      "Staged Release",
      "Phased Deployment",
      "Controlled Rollout"
    ]
  },
  {
    "id": "tech-safety-benchmarks",
    "name": "Safety Benchmarking",
    "categoryId": "cat-evaluation",
    "description": "Standardized benchmarks and evaluation suites for measuring and comparing safety performance across models",
    "riskAreaIds": [
      "harmful_content"
    ],
    "aliases": [
      "Safety Evaluation",
      "Security Benchmarks",
      "Safety Testing Suites"
    ]
  },
  {
    "id": "tech-safety-reward-modeling",
    "name": "Safety Reward Modeling",
    "categoryId": "cat-alignment",
    "description": "Separate reward models specifically optimized for safety outcomes",
    "implementationMethods": [
      "EmbeddedClassifier",
      "HumanModeration"
    ],
    "knownLimitations": [
      "May conflict with capability objectives",
      "Hard to balance multiple safety goals"
    ],
    "aliases": [
      "Safety RM"
    ],
    "riskAreaIds": [
      "harmful_content",
      "bias_and_fairness",
      "misinformation"
    ]
  },
  {
    "id": "tech-training-data-filtering",
    "name": "Training Data Filtering",
    "categoryId": "cat-pre-training-safety",
    "description": "Systematic removal of harmful content from training datasets",
    "implementationMethods": [
      "RuleBased",
      "EmbeddedClassifier"
    ],
    "knownLimitations": [
      "May introduce demographic biases"
    ],
    "aliases": [
      "Data Curation",
      "Dataset Cleaning"
    ],
    "riskAreaIds": [
      "harmful_content",
      "bias_and_fairness",
      "copyright_and_ip"
    ]
  },
  {
    "id": "tech-watermarking",
    "name": "Watermarking Technology",
    "categoryId": "cat-runtime-safety",
    "description": "Embedding detectable patterns in AI-generated content",
    "implementationMethods": [
      "Other"
    ],
    "knownLimitations": [
      "Can be removed or spoofed"
    ],
    "aliases": [
      "AI Watermarking",
      "SynthID"
    ],
    "riskAreaIds": [
      "misinformation",
      "transparency"
    ]
  },
  {
    "id": "tech-compute-documentation",
    "name": "Compute Resource Documentation",
    "categoryId": "cat-transparency",
    "description": "Documentation of computational resources used for model training including hardware, energy consumption, and environmental impact",
    "riskAreaIds": [
      "transparency"
    ],
    "aliases": [
      "Compute Transparency",
      "Resource Documentation",
      "Infrastructure Disclosure"
    ]
  },
  {
    "id": "tech-access-control-documentation",
    "name": "Access Control Documentation",
    "categoryId": "cat-governance",
    "description": "Documentation of access control policies, authentication methods, and usage restrictions",
    "riskAreaIds": [
      "transparency",
      "security_and_misuse"
    ],
    "aliases": [
      "Access Policy Documentation",
      "Usage Control Disclosure",
      "Authentication Documentation"
    ]
  },
  {
    "id": "tech-data-retention-policies",
    "name": "Data Retention Policies",
    "categoryId": "cat-privacy-security",
    "description": "Policies and procedures for data retention, deletion, and lifecycle management",
    "riskAreaIds": [
      "transparency",
      "privacy_and_pii"
    ],
    "aliases": [
      "Data Lifecycle Management",
      "Retention Policies",
      "Data Deletion Procedures"
    ]
  },
  {
    "id": "tech-model-versioning",
    "name": "Model Update & Versioning Protocols",
    "categoryId": "cat-governance",
    "description": "Systematic protocols for model updates, versioning, and change management",
    "riskAreaIds": [
      "security_and_misuse",
      "transparency"
    ],
    "aliases": [
      "Version Control",
      "Model Update Management",
      "Change Control Protocols"
    ]
  },
  {
    "id": "tech-stakeholder-engagement",
    "name": "Stakeholder Engagement Processes",
    "categoryId": "cat-governance",
    "description": "Formal processes for engaging with stakeholders, communities, academic institutions, and affected parties in safety decisions and research collaborations",
    "riskAreaIds": [
      "harmful_content",
      "autonomy_and_control",
      "bias_and_fairness",
      "privacy_and_pii",
      "security_and_misuse",
      "misinformation",
      "copyright_and_ip",
      "transparency",
      "environmental",
      "dual_use"
    ],
    "aliases": [
      "Community Engagement",
      "Public Participation",
      "Stakeholder Consultation",
      "University Collaborations"
    ]
  },
  {
    "id": "tech-privacy-impact-assessment",
    "name": "Privacy Impact Assessments",
    "categoryId": "cat-privacy-security",
    "description": "Systematic assessment of privacy risks and impacts throughout the model lifecycle",
    "riskAreaIds": [
      "transparency",
      "privacy_and_pii"
    ],
    "aliases": [
      "Privacy Risk Assessment",
      "PIA",
      "Privacy Evaluation"
    ]
  },
  {
    "id": "tech-algorithmic-impact-assessment",
    "name": "Algorithmic Impact Assessments",
    "categoryId": "cat-evaluation",
    "description": "Assessment of broader societal and ethical impacts of algorithmic systems",
    "riskAreaIds": [
      "bias_and_fairness",
      "transparency",
      "harmful_content"
    ],
    "aliases": [
      "AIA",
      "Societal Impact Assessment",
      "Ethical Impact Evaluation"
    ]
  },
  {
    "id": "tech-dynamic-risk-assessment",
    "name": "Dynamic Risk Assessment",
    "categoryId": "cat-runtime-safety",
    "description": "Real-time risk assessment that adapts to changing contexts and usage patterns",
    "riskAreaIds": [
      "harmful_content",
      "security_and_misuse"
    ],
    "aliases": [
      "Adaptive Risk Assessment",
      "Context-Aware Risk Evaluation",
      "Dynamic Safety Assessment"
    ]
  }
]