{
  "models": [
    {
      "id": "nova-pro",
      "name": "Nova",
      "provider": "amazon",
      "status": "active",
      "version": "Nova Pro",
      "notes": "Highly-capable multimodal model with the best combination of accuracy, speed, and cost for a wide range of tasks"
    },
    {
      "id": "nova-lite",
      "name": "Nova",
      "provider": "amazon",
      "status": "active",
      "version": "Nova Lite",
      "notes": "Low-cost multimodal model that is lightning fast for processing images, video, documents, and text"
    },
    {
      "id": "nova-micro",
      "name": "Nova",
      "provider": "amazon",
      "status": "active",
      "version": "Nova Micro",
      "notes": "Text-only model that delivers the lowest-latency responses at very low cost"
    },
    {
      "id": "gpt-5.2",
      "name": "GPT",
      "provider": "openai",
      "status": "active",
      "version": "GPT-5.2",
      "notes": "<n/a>"
    },
    {
      "id": "o3-pro",
      "name": "o",
      "provider": "openai",
      "status": "active",
      "version": "o3-pro",
      "notes": "<n/a>"
    },
    {
      "id": "o3",
      "name": "o",
      "provider": "openai",
      "status": "active",
      "version": "o3",
      "notes": "Reasoning model that excels at solving complex math, coding, and scientific challenges"
    },
    {
      "id": "gpt-5-mini",
      "name": "GPT",
      "provider": "openai",
      "status": "active",
      "version": "GPT-5 mini",
      "notes": "<n/a>"
    },
    {
      "id": "o4-mini",
      "name": "o",
      "provider": "openai",
      "status": "active",
      "version": "o4-mini",
      "notes": "Combines state-of-the-art reasoning with full tool capabilities, including web browsing and python analysis"
    },
    {
      "id": "gpt-oss-120b",
      "name": "GPT",
      "provider": "openai",
      "status": "active",
      "version": "GPT-oss-120b",
      "notes": "<n/a>"
    },
    {
      "id": "claude-opus-4.5",
      "name": "Claude",
      "provider": "anthropic",
      "status": "active",
      "version": "Claude Opus 4.5",
      "notes": "Flagship, high-logic model built for enterprise research, advanced coding, agent chains, and massive context workloads"
    },
    {
      "id": "claude-sonnet-4.5",
      "name": "Claude",
      "provider": "anthropic",
      "status": "active",
      "version": "Claude Sonnet 4.5",
      "notes": "Balances reasoning depth and cost, excelling at structured analysis, coding, and extended chat"
    },
    {
      "id": "claude-haiku-4.5",
      "name": "Claude",
      "provider": "anthropic",
      "status": "active",
      "version": "Claude Haiku 4.5",
      "notes": "Delivers near-frontier results at minimal latency and low price for everyday chat and document tasks"
    },
    {
      "id": "gemini-3-pro",
      "name": "Gemini",
      "provider": "google",
      "status": "active",
      "version": "Gemini 3 Pro",
      "notes": "Intelligent model with state-of-the-art reasoning, advanced multimodal understanding, and exceptional coding capabilities"
    },
    {
      "id": "gemini-3-deep-think",
      "name": "Gemini",
      "provider": "google",
      "status": "active",
      "version": "Gemini 3 Deep Think",
      "notes": "Uses an internal thinking process to significantly improve reasoning and multi-step planning abilities"
    },
    {
      "id": "gemini-3-flash",
      "name": "Gemini",
      "provider": "google",
      "status": "active",
      "version": "Gemini 3 Flash",
      "notes": "Minimizes latency for chat or high throughput applications while maintaining strong reasoning capabilities"
    },
    {
      "id": "gemini-2.5-flash-lite",
      "name": "Gemini",
      "provider": "google",
      "status": "active",
      "version": "Gemini 2.5 Flash-Lite",
      "notes": "Cost-effective model optimized for speed and efficiency, suitable for high-volume tasks"
    },
    {
      "id": "llama-4-maverick",
      "name": "Llama",
      "provider": "meta",
      "status": "active",
      "version": "Llama 4 Maverick",
      "notes": "Natively multimodal model featuring 128 experts, excelling in versatile assistant and chat applications"
    },
    {
      "id": "llama-4-scout",
      "name": "Llama",
      "provider": "meta",
      "status": "active",
      "version": "Llama 4 Scout",
      "notes": "General-purpose multimodal model with 16 experts, delivering superior performance for its size"
    },
    {
      "id": "llama-4-8b",
      "name": "Llama",
      "provider": "meta",
      "status": "active",
      "version": "Llama 4 8B",
      "notes": "<n/a>"
    },
    {
      "id": "llama-4-17b",
      "name": "Llama",
      "provider": "meta",
      "status": "active",
      "version": "Llama 4 17B",
      "notes": "<n/a>"
    },
    {
      "id": "mistral-large-3",
      "name": "Mistral",
      "provider": "mistral",
      "status": "active",
      "version": "Mistral Large 3",
      "notes": "Flagship multimodal and multilingual model with 41B active parameters and agentic capabilities"
    },
    {
      "id": "magistral-medium-1.2",
      "name": "Magistral",
      "provider": "mistral",
      "status": "active",
      "version": "Magistral Medium 1.2",
      "notes": "Specialized in transparent and multilingual reasoning with complex thinking capabilities"
    },
    {
      "id": "ministral-3",
      "name": "Ministral",
      "provider": "mistral",
      "status": "active",
      "version": "Ministral 3",
      "notes": "Combines compact efficiency with multimodal and multilingual capability for edge and self-hosted systems"
    },
    {
      "id": "pixtral",
      "name": "Pixtral",
      "provider": "mistral",
      "status": "active",
      "version": "Pixtral",
      "notes": "Vision pioneer that combines text, image, and structured data understanding in a single model"
    },
    {
      "id": "deepseek-v3.2",
      "name": "DeepSeek",
      "provider": "deepseek",
      "status": "active",
      "version": "DeepSeek-V3.2",
      "notes": "Mixture-of-Experts model using sparse attention to improve long-context efficiency"
    },
    {
      "id": "deepseek-r1",
      "name": "DeepSeek",
      "provider": "deepseek",
      "status": "active",
      "version": "DeepSeek-R1",
      "notes": "Reasoning model that generates a step-by-step chain of thought for complex problem-solving"
    },
    {
      "id": "deepseek-r1-distill",
      "name": "DeepSeek",
      "provider": "deepseek",
      "status": "active",
      "version": "DeepSeek-R1-Distill",
      "notes": "<n/a>"
    },
    {
      "id": "deepseek-v3-lite",
      "name": "DeepSeek",
      "provider": "deepseek",
      "status": "active",
      "version": "DeepSeek-V3-Lite",
      "notes": "<n/a>"
    },
    {
      "id": "qwen3-max",
      "name": "Qwen",
      "provider": "alibaba",
      "status": "active",
      "version": "Qwen3-Max",
      "notes": "Delivers major improvements in reasoning, instruction following, and multilingual support across 100+ languages"
    },
    {
      "id": "qwen3-thinking",
      "name": "Qwen",
      "provider": "alibaba",
      "status": "active",
      "version": "Qwen3-Thinking",
      "notes": "<n/a>"
    },
    {
      "id": "qwen3-turbo",
      "name": "Qwen",
      "provider": "alibaba",
      "status": "active",
      "version": "Qwen3-Turbo",
      "notes": "<n/a>"
    },
    {
      "id": "grok-4",
      "name": "Grok",
      "provider": "xai",
      "status": "active",
      "version": "Grok 4",
      "notes": "Intelligent model featuring native tool use, real-time search integration, and refined reasoning"
    },
    {
      "id": "grok-4-thinking",
      "name": "Grok",
      "provider": "xai",
      "status": "active",
      "version": "Grok 4 Thinking",
      "notes": "<n/a>"
    },
    {
      "id": "grok-4-fast",
      "name": "Grok",
      "provider": "xai",
      "status": "active",
      "version": "Grok 4 Fast",
      "notes": "<n/a>"
    },
    {
      "id": "phi-5",
      "name": "Phi",
      "provider": "microsoft",
      "status": "active",
      "version": "Phi-5",
      "notes": "<n/a>"
    },
    {
      "id": "phi-4",
      "name": "Phi",
      "provider": "microsoft",
      "status": "active",
      "version": "Phi-4",
      "notes": "Powerful open model leveraging language, vision, and speech research for broad commercial and research use"
    },
    {
      "id": "phi-4-multimodal",
      "name": "Phi",
      "provider": "microsoft",
      "status": "active",
      "version": "Phi-4-multimodal",
      "notes": "Lightweight foundation model processing text, image, and audio inputs with strong instruction adherence"
    },
    {
      "id": "command-a",
      "name": "Command",
      "provider": "cohere",
      "status": "active",
      "version": "Command A",
      "notes": "<n/a>"
    },
    {
      "id": "command-r-plus",
      "name": "Command",
      "provider": "cohere",
      "status": "active",
      "version": "Command R+",
      "notes": "Optimized for long-context tasks, RAG, and tool use to automate sophisticated enterprise workflows"
    },
    {
      "id": "nemotron-4",
      "name": "Nemotron",
      "provider": "nvidia",
      "status": "active",
      "version": "Nemotron-4",
      "notes": "<n/a>"
    },
    {
      "id": "llama-3.1-nemotron",
      "name": "Nemotron",
      "provider": "nvidia",
      "status": "active",
      "version": "Llama-3.1-Nemotron",
      "notes": "Derivative reasoning model post-trained for math, code, and tool calling capabilities"
    },
    {
      "id": "falcon-3",
      "name": "Falcon",
      "provider": "tii",
      "status": "active",
      "version": "Falcon 3",
      "notes": "<n/a>"
    },
    {
      "id": "falcon-180b",
      "name": "Falcon",
      "provider": "tii",
      "status": "active",
      "version": "Falcon 180B",
      "notes": "Large-scale open model with 180 billion parameters, optimized for reasoning and knowledge tasks"
    },
    {
      "id": "hunyuan-large",
      "name": "Hunyuan",
      "provider": "tencent",
      "status": "active",
      "version": "Hunyuan-Large (MoE 389B)",
      "notes": "Flagship MoE model, competes with Llama 3.1 405B"
    },
    {
      "id": "hunyuan-7b-instruct",
      "name": "Hunyuan",
      "provider": "tencent",
      "status": "active",
      "version": "Hunyuan-7B-Instruct",
      "notes": "Standard dense model for efficient local deployment"
    }
  ]
}