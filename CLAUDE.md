# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

This is a Python-based dataset and analysis tool for tracking safety mechanisms implemented by LLM providers (OpenAI, Anthropic, Google, Meta, Amazon). The project maintains structured JSON data about providers, models, safety techniques, categories, risk areas, and evidence records, then generates visualizations and reports.

The dataset is published as an interactive dashboard at https://sashaagafonoff.github.io/LLM-Safety-Mechanisms/

## Core Architecture

### Data Model

The data model is centered around these key JSON files in [data/](data/):

- [evidence.json](data/evidence.json) - Core dataset containing evidence records that link providers to safety techniques they implement. Each record includes:
  - `providerId` and `techniqueId` references
  - `rating` (high/medium/low) indicating implementation maturity
  - `severityBand` (P/B/C/V/U) indicating evidence quality (Primary/Benchmarked/Claimed/Volunteered/Unverified)
  - `sources` array with URLs and metadata about where evidence was found
  - Optional `implementationDate` for timeline tracking

- [techniques.json](data/techniques.json) - Defines safety techniques (e.g., "RLHF", "Constitutional AI", "Input Filtering"). Each technique includes:
  - `categoryId` reference
  - `riskAreaIds` array
  - `nlu_profile` for semantic analysis (used by analyze_nlu.py)

- [providers.json](data/providers.json) - Provider metadata (name, type, website)
- [models.json](data/models.json) - Model metadata linked to providers
- [categories.json](data/categories.json) - Technique categories (e.g., "Alignment Methods", "Inference Safeguards")
- [risk_areas.json](data/risk_areas.json) - Risk area taxonomy
- [model_technique_map.json](data/model_technique_map.json) - Generated by NLU analysis, maps source documents to detected techniques

### Data Processing Pipeline

The typical workflow for updating the dataset:

1. **Ingest**: Download and convert source documents to flat text
   ```bash
   python scripts/ingest_universal.py
   # Or target a specific document:
   python scripts/ingest_universal.py --id <document-id>
   ```
   - Fetches PDFs, HTML pages, or other documents from URLs in evidence.json sources
   - Converts to clean text using MarkItDown and BeautifulSoup
   - Saves to [data/flat_text/](data/flat_text/)

2. **Analyze**: Run NLU models to extract technique mentions
   ```bash
   python scripts/analyze_nlu.py
   ```
   - Uses a two-stage semantic analysis pipeline:
     - Stage 1: `all-mpnet-base-v2` retrieval model for candidate chunks
     - Stage 2: `cross-encoder/nli-deberta-v3-small` for entailment verification
   - Outputs to [data/model_technique_map.json](data/model_technique_map.json)
   - This is computationally expensive and requires sentence-transformers

3. **Generate**: Create reports and dashboard
   ```bash
   python scripts/generate_report.py    # Creates SUMMARY.md and data/stats.json
   python scripts/generate_dashboard.py  # Creates docs/index.html
   ```

### Key Scripts

- [scripts/ingest_universal.py](scripts/ingest_universal.py) - Universal document ingestion supporting PDFs, HTML, GitHub raw files. Handles various content types and converts to flat text.

- [scripts/analyze_nlu.py](scripts/analyze_nlu.py) - NLU-based technique extraction using semantic embeddings and cross-encoder verification. Includes quality filters to avoid false positives from glossaries or "future work" mentions.

- [scripts/generate_dashboard.py](scripts/generate_dashboard.py) - Creates interactive HTML dashboard with Plotly visualizations:
  - Coverage heatmap (provider × technique matrix)
  - Implementation timeline
  - Rating distribution charts
  - Evidence quality breakdown
  - Risk area coverage

- [scripts/generate_report.py](scripts/generate_report.py) - Generates markdown summary reports with tables and statistics.

- [scripts/semantic_retriever.py](scripts/semantic_retriever.py) - Utility for semantic search across flat text documents.

## Development Commands

### Environment Setup
```bash
# Install dependencies
pip install -r requirements.txt

# For NLU analysis, you'll need sentence-transformers (large download):
# pip install sentence-transformers
```

### Testing
```bash
# Run tests (if test files exist in tests/ directory)
pytest

# Run with coverage
pytest --cov=scripts
```

### Code Quality
```bash
# Format code
black scripts/

# Lint code
flake8 scripts/
```

### Common Tasks

**Regenerate dashboard after data changes:**
```bash
python scripts/generate_report.py && python scripts/generate_dashboard.py
```

**Add a new source document:**
1. Add source entry to `evidence.json` under the `sources` array
2. Run `python scripts/ingest_universal.py --id <new-id>`
3. Optionally run `python scripts/analyze_nlu.py` to auto-detect techniques

**Validate data integrity:**
```bash
# Check that all IDs are valid and relationships are intact
python -c "import json; from pathlib import Path; [json.load(open(f)) for f in Path('data').glob('*.json')]"
```

## Data Editing Guidelines

When manually editing JSON data files:

- **Always maintain referential integrity**: `providerId`, `techniqueId`, `categoryId`, etc. must reference existing entities
- **Use consistent IDs**: IDs should be lowercase, hyphen-separated (e.g., `constitutional-ai`, `rlhf`)
- **Evidence quality bands**: Use P (Primary) for official documentation, B (Benchmarked) for quantitative evidence, C (Claimed) for unverified claims
- **Ratings**: Use "high" for mature implementations, "medium" for partial/limited implementations, "low" for minimal implementations
- **Source URLs**: Always prefer stable, primary source URLs (official docs, research papers) over blog posts or news articles

## CI/CD Automation

GitHub Actions workflows in [.github/workflows/](.github/workflows/):

- **dashboard-deploy.yml** - Auto-deploys dashboard to GitHub Pages when data or scripts change
- **validate.yml** - Validates JSON schema (currently empty, placeholder for future validation)
- **weekly-verification.yml** - Weekly automated checks
- **daily-automation.yml** - Daily automated tasks

## Notable Implementation Details

### NLU Analysis Quality Filters

The [scripts/analyze_nlu.py](scripts/analyze_nlu.py) includes specific heuristics to avoid false positives:
- Filters out glossary definitions (not actual implementations)
- Ignores "future work" or "planned" mentions
- Distinguishes "Access Control" from "Refusal" based on context
- Uses two-stage verification with configurable thresholds

### Document Ingestion Robustness

[scripts/ingest_universal.py](scripts/ingest_universal.py) handles various edge cases:
- Automatically converts GitHub blob URLs to raw content URLs
- Uses realistic browser headers to bypass bot detection
- Supports PDF, HTML, JSON, and plain text with automatic type detection
- Extracts clean text from HTML by removing scripts, navigation, footers

### Dashboard Visualization

The dashboard uses Plotly for interactive charts with:
- Custom color scales for rating levels (gray → yellow → orange → teal)
- Responsive Bootstrap layout
- Hover tooltips with detailed information
- Static export capability via Kaleido

## File Structure Reference

```
data/
├── evidence.json          # Main dataset
├── techniques.json        # Safety technique definitions
├── providers.json         # Provider metadata
├── models.json           # Model metadata
├── categories.json       # Technique categories
├── risk_areas.json       # Risk taxonomy
├── model_technique_map.json  # Generated NLU mapping
└── flat_text/           # Processed source documents

scripts/
├── ingest_universal.py   # Document ingestion
├── analyze_nlu.py        # NLU technique extraction
├── generate_dashboard.py # Dashboard generation
├── generate_report.py    # Report generation
└── semantic_retriever.py # Semantic search utility

docs/                     # Generated dashboard (GitHub Pages)
schema/                   # JSON schema definitions
reports/                  # Generated reports
observable/              # Observable notebook code
```
