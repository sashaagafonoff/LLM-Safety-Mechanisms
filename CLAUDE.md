# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

This is a Python-based dataset and analysis tool for tracking safety mechanisms implemented by LLM providers (OpenAI, Anthropic, Google, Meta, Amazon). The project maintains structured JSON data about providers, models, safety techniques, categories, risk areas, and evidence records, then generates visualizations and reports.

The dataset is published as an interactive dashboard at https://sashaagafonoff.github.io/LLM-Safety-Mechanisms/

## Core Architecture

### Data Model

The data model is centered around these key JSON files in [data/](data/):

- [evidence.json](data/evidence.json) - Core dataset containing evidence records that link providers to safety techniques they implement. Each record includes:
  - `providerId` and `techniqueId` references
  - `rating` (high/medium/low) indicating implementation maturity
  - `severityBand` (P/B/C/V/U) indicating evidence quality (Primary/Benchmarked/Claimed/Volunteered/Unverified)
  - `sources` array with URLs and metadata about where evidence was found
  - Optional `implementationDate` for timeline tracking

- [techniques.json](data/techniques.json) - Defines safety techniques (e.g., "RLHF", "Constitutional AI", "Input Filtering"). Each technique includes:
  - `categoryId` reference
  - `riskAreaIds` array
  - `nlu_profile` for semantic analysis (used by analyze_nlu.py)

- [providers.json](data/providers.json) - Provider metadata (name, type, website)
- [models.json](data/models.json) - Model metadata linked to providers
- [categories.json](data/categories.json) - Technique categories (e.g., "Alignment Methods", "Inference Safeguards")
- [risk_areas.json](data/risk_areas.json) - Risk area taxonomy
- [model_technique_map.json](data/model_technique_map.json) - Generated by NLU analysis, maps source documents to detected techniques

- [standards.json](data/standards.json) - External framework definitions (NIST AI RMF, NIST AI 600-1, OWASP LLM Top 10, MITRE ATLAS, EU AI Act, ISO 42001, Weidinger taxonomy). Each framework has an id, version, URL, and hierarchical structure of codes.

- [standards_mapping.json](data/standards_mapping.json) - Many-to-many mapping of techniques to standard controls. Each entry links a `techniqueId` to a `frameworkId` with specific `codes[]`, a `relationship` type (mitigates/addresses/supports/defends), and optional notes.

- [commentary.json](data/commentary.json) - Third-party references (academic papers, audits, blog posts) discussing technique effectiveness. Links to techniques via `techniqueIds[]`.

- [incidents.json](data/incidents.json) - Safety incident register. Each incident links to `providerIds[]`, `modelIds[]`, optional `techniqueIds[]` (which techniques failed), `riskAreaIds[]`, and external `sources[]`.

### RAG Architecture

The extraction pipeline implements a **Retrieval-Augmented Generation (RAG)** pattern at two levels:

#### Macro RAG: NLU Retrieval → LLM Generation (document-level)

```
┌─────────────┐    ┌──────────────────┐    ┌──────────────────┐
│  Flat Text   │───▶│  NLU Pipeline    │───▶│  LLM Pipeline    │
│  Documents   │    │  (Retrieval +    │    │  (Augmented      │
│              │    │   Verification)  │    │   Generation)    │
└─────────────┘    └──────────────────┘    └──────────────────┘
                    Stage 1: bge-large       Pass 1: Claude
                    bi-encoder retrieves     classifies document
                    candidate chunks         against taxonomy

                    Stage 2: nli-deberta     Pass 2: Review index
                    cross-encoder verifies   provides technique-
                    entailment               specific examples
```

- **R (Retrieval)**: `analyze_nlu.py` — Bi-encoder (BAAI/bge-large-en-v1.5) embeds document chunks and technique descriptions into a shared vector space. Cosine similarity retrieves candidate chunks above `RETRIEVAL_THRESHOLD`. Cross-encoder (nli-deberta-v3-large) verifies entailment above `VERIFICATION_THRESHOLD`.
- **A (Augmentation)**: `llm_assisted_extraction.py` — NLU results augment the LLM prompt as prior context. After initial extraction, the review index injects technique-specific confirmed/rejected examples from human reviews.
- **G (Generation)**: Claude produces structured technique classifications, then verifies each against review history.

#### Micro RAG: Review Index → Verification (technique-level)

After the LLM's initial classification (Pass 1), each proposed technique triggers a lookup into the **review index** — the cumulative history of human review decisions stored in `model_technique_map.json`:

- **Positives**: Entries that are `active: true` in manually reviewed documents (confirmed implementations)
- **Negatives**: Entries explicitly deleted by reviewers (confirmed false positives)

Only the relevant technique's examples are retrieved and fed to Claude for a focused verification pass (Pass 2). This avoids flooding the prompt with unrelated examples and ensures the verification signal is authoritative and current.

#### Pipeline Orchestration

`run_extraction_pipeline.py` orchestrates the full RAG pipeline: NLU pass → LLM pass → merge → optional report regeneration.

### Data Processing Pipeline

The typical workflow for updating the dataset:

1. **Ingest**: Download and convert source documents to flat text
   ```bash
   python scripts/ingest_universal.py
   # Or target a specific document:
   python scripts/ingest_universal.py --id <document-id>
   ```
   - Fetches PDFs, HTML pages, or other documents from URLs in evidence.json sources
   - Converts to clean text using MarkItDown and BeautifulSoup
   - Saves to [data/flat_text/](data/flat_text/)

2. **Analyze**: Run the full extraction pipeline (or individual stages)
   ```bash
   # Full RAG pipeline (NLU + LLM + merge)
   python scripts/run_extraction_pipeline.py

   # NLU stage only (retrieval + verification, no API key needed)
   python scripts/analyze_nlu.py

   # LLM stage only (requires ANTHROPIC_API_KEY)
   python scripts/llm_assisted_extraction.py
   ```
   - NLU stage: `BAAI/bge-large-en-v1.5` retrieval + `cross-encoder/nli-deberta-v3-large` verification
   - LLM stage: Two-pass extraction with review-index-augmented verification
   - Outputs to [data/model_technique_map.json](data/model_technique_map.json)

3. **Generate**: Create reports and dashboard
   ```bash
   python scripts/generate_report.py    # Creates SUMMARY.md and data/stats.json
   python scripts/generate_dashboard.py  # Creates docs/index.html
   ```

### Key Scripts

- [scripts/ingest_universal.py](scripts/ingest_universal.py) - Universal document ingestion supporting PDFs, HTML, GitHub raw files. Handles various content types and converts to flat text.

- [scripts/analyze_nlu.py](scripts/analyze_nlu.py) - RAG retrieval + verification stage. Bi-encoder retrieval (bge-large-en-v1.5) finds candidate chunks, cross-encoder (nli-deberta-v3-large) verifies entailment. Includes quality filters and metadata-aware document skipping.

- [scripts/llm_assisted_extraction.py](scripts/llm_assisted_extraction.py) - RAG augmented generation stage. Two-pass architecture: Pass 1 extracts technique candidates using Claude; Pass 2 verifies each against the per-technique review index of confirmed/rejected human decisions.

- [scripts/run_extraction_pipeline.py](scripts/run_extraction_pipeline.py) - RAG pipeline orchestrator. Runs NLU → LLM → merge, preserving manual annotations. Supports single-document and full-collection modes.

- [scripts/evaluate_nlu.py](scripts/evaluate_nlu.py) - Evaluation harness. Runs NLU pipeline against ground truth from manually reviewed documents. Computes precision/recall/F1 per document and aggregate. Respects `no_safety_content` flags.

- [scripts/generate_dashboard.py](scripts/generate_dashboard.py) - Creates interactive HTML dashboard with Plotly visualizations:
  - Coverage heatmap (provider × technique matrix)
  - Implementation timeline
  - Rating distribution charts
  - Evidence quality breakdown
  - Risk area coverage

- [scripts/generate_report.py](scripts/generate_report.py) - Generates markdown summary reports with tables and statistics.

- [scripts/semantic_retriever.py](scripts/semantic_retriever.py) - Utility for semantic search across flat text documents.

## Development Commands

### Environment Setup
```bash
# Install dependencies
pip install -r requirements.txt

# For NLU analysis, you'll need sentence-transformers (large download):
# pip install sentence-transformers
```

### Testing
```bash
# Run tests (if test files exist in tests/ directory)
pytest

# Run with coverage
pytest --cov=scripts
```

### Code Quality
```bash
# Format code
black scripts/

# Lint code
flake8 scripts/
```

### Common Tasks

**Regenerate dashboard after data changes:**
```bash
python scripts/generate_report.py && python scripts/generate_dashboard.py
```

**Add a new source document:**
1. Add source entry to `evidence.json` under the `sources` array
2. Run `python scripts/ingest_universal.py --id <new-id>`
3. Optionally run `python scripts/analyze_nlu.py` to auto-detect techniques

**Validate data integrity:**
```bash
# Check that all IDs are valid and relationships are intact
python -c "import json; from pathlib import Path; [json.load(open(f)) for f in Path('data').glob('*.json')]"
```

## Data Editing Guidelines

When manually editing JSON data files:

- **Always maintain referential integrity**: `providerId`, `techniqueId`, `categoryId`, etc. must reference existing entities
- **Use consistent IDs**: IDs should be lowercase, hyphen-separated (e.g., `constitutional-ai`, `rlhf`)
- **Evidence quality bands**: Use P (Primary) for official documentation, B (Benchmarked) for quantitative evidence, C (Claimed) for unverified claims
- **Ratings**: Use "high" for mature implementations, "medium" for partial/limited implementations, "low" for minimal implementations
- **Source URLs**: Always prefer stable, primary source URLs (official docs, research papers) over blog posts or news articles

## CI/CD Automation

GitHub Actions workflows in [.github/workflows/](.github/workflows/):

- **dashboard-deploy.yml** - Auto-deploys `docs/` to GitHub Pages when docs or data files change (no build step)
- **process-review.yml** - Processes approved community tag submissions: parses structured JSON from GitHub issues, updates `model_technique_map.json`, and creates a PR
- **validate.yml** - Validates JSON schema (currently empty, placeholder for future validation)
- **weekly-verification.yml** - Weekly automated checks
- **daily-automation.yml** - Daily automated tasks

## Notable Implementation Details

### NLU Analysis Quality Filters

The [scripts/analyze_nlu.py](scripts/analyze_nlu.py) includes specific heuristics to avoid false positives:
- Filters out glossary definitions (not actual implementations)
- Ignores "future work" or "planned" mentions
- Distinguishes "Access Control" from "Refusal" based on context
- Uses two-stage verification with configurable thresholds (RETRIEVAL_THRESHOLD=0.40, VERIFICATION_THRESHOLD=0.85)
- Skips documents flagged as `no_safety_content` in evidence.json content_metadata
- NLU profiles in techniques.json define per-technique: `primary_concept`, `semantic_anchors`, `entailment_hypothesis`, `excluded_terms`

### Document Ingestion Robustness

[scripts/ingest_universal.py](scripts/ingest_universal.py) handles various edge cases:
- Automatically converts GitHub blob URLs to raw content URLs
- Uses realistic browser headers to bypass bot detection
- Supports PDF, HTML, JSON, and plain text with automatic type detection
- Extracts clean text from HTML by removing scripts, navigation, footers

### Dashboard Visualization

The interactive dashboard at `docs/` is a plain static HTML site (no build step) deployed to GitHub Pages. It uses D3.js and htl loaded via ES module import maps from esm.sh CDN. All chart components are vanilla ES modules in `docs/components/`. The dashboard deploys automatically when `docs/**` or `data/**.json` files change on main.

## File Structure Reference

```
data/
├── evidence.json              # Main dataset (sources, metadata)
├── techniques.json            # Safety technique definitions (50 techniques)
├── providers.json             # Provider metadata
├── models.json                # Model metadata
├── categories.json            # Technique categories
├── risk_areas.json            # Risk taxonomy
├── model_technique_map.json   # Generated NLU/LLM mapping
├── standards.json             # External framework definitions (7 frameworks)
├── standards_mapping.json     # Technique-to-standard mappings
├── commentary.json            # Third-party analysis references
├── incidents.json             # Safety incident register
└── flat_text/                 # Processed source documents

scripts/
├── ingest_universal.py        # Document ingestion
├── analyze_nlu.py             # RAG retrieval + verification stage
├── llm_assisted_extraction.py # RAG augmented generation stage
├── run_extraction_pipeline.py # Full RAG pipeline orchestrator
├── evaluate_nlu.py            # NLU evaluation harness
├── generate_dashboard.py      # Dashboard generation
├── generate_report.py         # Report generation
└── semantic_retriever.py      # Semantic search utility

docs/                          # Interactive dashboard (GitHub Pages, plain static HTML)
├── index.html                 # Main explorer dashboard
├── tag.html                   # Community tag & review tool
├── components/                # D3/htl ES module components
│   ├── data-pipeline.js       # Data loading and enrichment
│   ├── standards-view.js      # Standards alignment matrix
│   ├── commentary-view.js     # Commentary reference list
│   ├── incidents-view.js      # Incident register table
│   └── ...                    # Chart components
└── data/                      # Static layout data

schema/                        # JSON schema definitions
reports/                       # Generated reports
```
